<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[配置不同ssh-key访问不同git仓库]]></title>
      <url>http://czero000.github.io/2016/10/20/git-different-sshkey.html</url>
      <content type="text"><![CDATA[Git 是通过 ssh方式访问，例如 GitHub，当用户访问 Github 上的仓库时，用户会将本地的 ~/.ssh/id_rsa 与上传到 GitHub 的公钥进行验证。但是在实际情况，很多会有自己的内部 git 仓库，或者是私人创建的仓库，当要求每个 git 仓库要使用不同 ssh-key 时，应该如何配置呢。 生成 ssh-key 12ssh-keygen -t rsa -C &apos;user@mail.com&apos; -f id_rsa_github1ssh-keygen -t rsa -C &apos;user@mail.com&apos; -f id_rsa_github2 创建 config 配置文件 该文件可以定义不同 ssh-key 访问不同 git仓库12345678910cat ~/.ssh/configHost github1.com \\ 别名 hostname github.com \\ 仓库地址 IdentityFile ~/.ssh/id_rsa.github \\ ssh-key user github1 \\ 登录用户Host github2.com hostname github.com IdentityFile ~/.ssh/id_rsa.github2 user github2 连接远程仓库 123git clone git@github1.com:github1/test.gitgit clone git@github2.com:github2/test.git 这样就可以使用不同 ssh-key 来访问不同 GitHub 仓库。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IPsec和L2TP搭建VPN]]></title>
      <url>http://czero000.github.io/2016/10/20/l2tp-vpn.html</url>
      <content type="text"><![CDATA[利用 IPsec 和 L2TP 搭建 VPN安装 EPEL 源1yum install epel-release -y 安装 软件包Openswan 是 linux 下 VPN 协议 IPSec的一种实现，CentOS7安装源中有它的开源社区版，叫做 libreswan，先在来安装1yum install libreswan xl2tpd ppp lsof -y 设置内核参数123456echo &quot;net.ipv4.ip_forward = 1&quot; | tee -a /etc/sysctl.confecho &quot;net.ipv4.conf.all.accept_redirects = 0&quot; | tee -a /etc/sysctl.confecho &quot;net.ipv4.conf.all.send_redirects = 0&quot; | tee -a /etc/sysctl.conffor vpn in /proc/sys/net/ipv4/conf/*; do echo 0 &gt; $vpn/accept_redirects; echo 0 &gt; $vpn/send_redirects; donefor i in /proc/sys/net/ipv4/conf/*;do echo 0 &gt; $i/rp_filter;donesysctl -p 添加 rc.local 文件12for vpn in /proc/sys/net/ipv4/conf/*; do echo 0 &gt; $vpn/accept_redirects; echo 0 &gt; $vpn/send_redirects; donefor i in /proc/sys/net/ipv4/conf/*;do echo 0 &gt; $i/rp_filter;done 修改IPsec配置文件 在 /etc/ipsec.d/ 目录下，新建配置文件 l2tp.conf，并添加如下内容 12345678910111213141516171819#conn %default# Forceencaps=yesconn L2TP-PSK-NAT rightsubnet=vhost:%priv also=L2TP-PSK-noNATconn L2TP-PSK-noNAT authby=secret pfs=no auto=add type=transport keyingtries=3 rekey=no ikelifetime=8h salifetime=1h left=serverIP leftprotoport=17/1701 right=%any rightprotoport=17/%any 设置共享秘钥 12cat /etc/ipsec.d/l2tp.secrets59.151.49.125 %any: PSK &quot;linekong&quot; 启动 IPSec12systemctl start ipsecsystemctl enable ipsec 验证 IPSec 是否正常1234567891011121314151617181920212223ipsrc verifyVerifying installed system and configuration filesVersion check and ipsec on-path [OK]Libreswan 3.15 (netkey) on 3.10.0-229.el7.x86_64Checking for IPsec support in kernel [OK] NETKEY: Testing XFRM related proc values ICMP default/send_redirects [OK]▽ ICMP default/accept_redirects [OK] XFRM larval drop [OK]Pluto ipsec.conf syntax [OK]Hardware random device [N/A]Two or more interfaces found, checking IP forwarding [OK]Checking rp_filter [OK]Checking that pluto is running [OK] Pluto listening for IKE on udp 500 [OK] Pluto listening for IKE/NAT-T on udp 4500 [OK] Pluto ipsec.secret syntax [OK]Checking &apos;ip&apos; command [OK]Checking &apos;iptables&apos; command [OK]Checking &apos;prelink&apos; command does not interfere with FIPSChecking for obsolete ipsec.conf options [OK]Opportunistic Encryption// 可以根据提示信息，修改相应配置，多数是内核参数 配置 xl2tpd编辑配置文件123456789101112131415161718vim /etc/xl2tpd/xl2tpd.conf[global]listen-addr = serverIPauth file = /etc/ppp/chap-secretsipsec saref = yes; force userspace = yes; debug tunnel = yes[lns default]ip range = 10.0.2.128-10.0.2.254local ip = 1.1.1.1require chap = yesrefuse pap = yesrequire authentication = yesname = LinuxVPNserverppp debug = yespppoptfile = /etc/ppp/options.xl2tpdlength bit = yes 配置 PPP编辑配置文件/etc/ppp/options.xl2tpd1234567891011121314require-mschap-v2ms-dns 8.8.8.8ms-dns 8.8.4.4asyncmap 0authcrtsctslockhide-passwordmodemdebugname l2tpdproxyarplcp-echo-interval 30lcp-echo-failure 4 添加测试用户12345vim chap-secrets## Secrets for authentication using CHAP# client server secret IP addressestest l2tpd 123456 10.0.12.100 启动 IPSec12systemctl start xl2tpdsystemctl enable xl2tpd 利用 iptable 配置转发规则 gw.sh 1234567#!/bin/bash/sbin/iptables -t nat -F/sbin/iptables -t nat -A POSTROUTING -s 10.0.12.0/24 -d 172.16.0.0/16 -o eth1 -j SNAT --to-source 172.16.1.125/sbin/iptables -t nat -A POSTROUTING -s 10.0.12.0/24 ! -d 10.0.12.0/24 -o eth0 -j SNAT --to-source 59.151.49.125/sbin/iptables -t nat -A POSTROUTING -s 10.0.12.0/24 ! -d 172.16.0.0/16 -o eth0 -j SNAT --to-source 59.151.49.125 forward.sh 1234567891011// 172.16.3.100 为办公电脑IP#!/bin/bash/sbin/iptables -F FORWARD##[test]/sbin/iptables -A FORWARD -s 10.0.12.100 -p tcp -d 172.16.3.100 -j ACCEPT##[default]/sbin/iptables -A FORWARD -s 10.0.12.0/24 -d 172.16.0.0/255.255.0.0 -j DROP#/sbin/iptables -A FORWARD -s 10.0.12.0/24 -d 59.151.39.0/255.255.255.0 -j DROP#/sbin/iptables -A FORWARD -s 10.0.12.0/24 -d 59.151.49.0/255.255.255.0 -j DROP]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[通过jinja2生成虚拟主机配置]]></title>
      <url>http://czero000.github.io/2016/10/20/ansible-dynamic-create-vhost.html</url>
      <content type="text"><![CDATA[在 ansibleplaybook 中，可以通过 JinJa2 可以生成多虚拟主机配置 目标配置在实际使用中，需要通过 jinja2 模板生成多虚拟主机配置，希望最后可以生成下面配置 apache 1234567891011121314&lt;VirtualHost *:80&gt; ServerAdmin admin@czero000.com DocumentRoot &quot;/data/htdocs/www.czero000.com ServerName www.czero000.com ErrorLog &quot;logs/www.czero000.com-error_log&quot; CustomLog &quot;|/usr/local/apache/bin/rotatelogs -l /usr/local/apache/logs/www.czero000.com-access_%Y%m%d_log 86400&quot; combined&lt;Directory &quot;/data/htdocs/www.czero000.com&quot;&gt; DirectoryIndex index.html index.php Options FollowSymLinks AllowOverride None Order allow,deny Allow from all&lt;/Directory&gt;&lt;/VirtualHost&gt; nginx 1234567891011121314151617181920212223server &#123; listen 80 default_server; server_name www.czero000.com root /home/website/www.czero000.com; index index.html; location / &#123; try_files $uri $uri/ /index.php?$args; &#125; location ~ .*\.(php)?$ &#123; expires 1s; try_files $uri = 404; fastcgi_split_path_info ^(.+\.php)(/.+)$; include fastcgi_params; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_pass 127.0.0.1:9000; &#125; access_log logs/www.czero000.com_access.log access; error_log logs/www.czero000.com_error.log;&#125; 初始化 role通过 ansible-galaxy 生成playbook目录 Apache 添加变量 12345# VhostVhostDomain: - domain: &apos;www.czero000.com&apos; ServerName: &apos;www.czero000.com&apos; DocumentRoot: &apos;/home/website/www.czero000.com&apos; 编写 jinja2 模板 12345678910111213141516&#123;% for vhost in VhostDomain %&#125;&lt;VirtualHost *:80&gt; ServerAdmin admin.czero000.com DocumentRoot &#123;&#123; vhost.DocumentRoot &#125;&#125; ServerName &#123;&#123; vhost.ServerName &#125;&#125; ErrorLog &quot;logs/&#123;&#123; vhost.ServerName &#125;&#125;-error_log&quot; CustomLog &quot;|/usr/local/apache/bin/rotatelogs -l /usr/local/apache/logs/&#123;&#123; vhost.ServerName &#125;&#125;_%Y%m%d_log 86400&quot; combined&lt;Directory &quot;&#123;&#123; vhost.DocumentRoot &#125;&#125;&quot;&gt; DirectoryIndex index.html index.php Options FollowSymLinks AllowOverride None Order allow,deny Allow from all&lt;/Directory&gt;&lt;/VirtualHost&gt;&#123;% endfor %&#125; 编写 task 文件 12345---- name: Copy Vhost Config Files template: src=vhost.conf.j2 dest=/usr/local/apache/conf/vhost/&#123;&#123; item.domain &#125;&#125;.conf owner=root group=root mode=0644 with_items: &quot;&#123;&#123; VhostDomain &#125;&#125;&quot; #notify: Restart Apache.Service 编写总调度文件，执行 playbook 123456789cat apache_conf.yml- name: Dynamic Create Vhost Conf hosts: localhost gather_facts: no roles: - apache_conf// 执行 playbook 生成配置文件ansible-playbook apache_conf.yml Nginx 添加变量 在 default/main.yml 中添加变量12345678910111213141516171819202122# VhostVhostDomain: - domain: &apos;www.czero000.com&apos; listen: &apos;80 default_server&apos; root: &apos;/home/website/www.czero000.com&apos; server_name: &apos;www.czero000.com&apos; index: &apos;index.html&apos;Vhost_Location: | location / &#123; try_files $uri $uri/ /index.php?$args; &#125; location ~ .*\.(php)?$ &#123; expires 1s; try_files $uri = 404; fastcgi_split_path_info ^(.+\.php)(/.+)$; include fastcgi_params; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_pass 127.0.0.1:9000; &#125; 编写 jinja2 模板 12345678910111213141516171819202122&#123;% for vhost in VhostDomain %&#125;server &#123; listen &#123;&#123; vhost.listen | default(&apos;80 default_server&apos;) &#125;&#125;;&#123;% if vhost.server_name is defined %&#125; server_name &#123;&#123; vhost.server_name &#125;&#125;&#123;% endif %&#125;&#123;% if vhost.root is defined %&#125; root &#123;&#123; vhost.root &#125;&#125;;&#123;% endif %&#125;&#123;% if vhost.index is defined %&#125; index &#123;&#123; vhost.index &#125;&#125;;&#123;% endif%&#125;&#123;% if Vhost_Location is defined %&#125; &#123;&#123; Vhost_Location&#125;&#125;&#123;% endif%&#125;&#123;% if vhost.server_name is defined %&#125; access_log logs/&#123;&#123; vhost.server_name &#125;&#125;_access.log access; error_log logs/&#123;&#123; vhost.server_name &#125;&#125;_error.log;&#123;% endif %&#125;&#125;&#123;% endfor %&#125; 编写 task 文件 12345---- name: Copy Vhost Config Files template: src=vhost.conf.j2 dest=/usr/local/nginx/conf/vhost/&#123;&#123; item.domain &#125;&#125;.conf owner=root group=root mode=0644 with_items: &quot;&#123;&#123; VhostDomain &#125;&#125;&quot; #notify: Restart Nginx.Service 编写总调度文件，执行 playbook123456789cat ngingx_conf.yml- name: Dynamic Create Vhost Conf hosts: localhost gather_facts: no roles: - nginx_conf// 执行 playbook 生成配置文件ansible-playbook ngingx_conf.yml]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Dockerfile创建blog]]></title>
      <url>http://czero000.github.io/2016/10/20/docker-blog.html</url>
      <content type="text"><![CDATA[Docker 是一个有趣的技术，在过去的两年已经从一个想法变成了全世界的机构都在采用来部署应用的技术。下面会通过 docker 来创建一个blog。 什么是 DockerDocker 是一个操作系统容器管理工具，通过将应用打包到操作系统容器里面，从而让你能轻松管理和部署应用。 容器 vs 虚拟机容器可能不如虚拟机一样为人所熟知，但是它们是另外的一种提供操作系统虚拟化的方法。然而，他们与标准的虚拟机有很大的差异。 标准的虚拟机通常包含一个完整的操作系统，OS 软件包，最后包含一两个应用。它是通过一个向虚拟机提供了硬件虚拟化的 Hypervisor 来实现的，允许单个服务器运行很多独立的被当做虚拟游客（virtual guest）的操作系统。 而容器与虚拟机的类似之处在于它们允许单个服务器运行多个操作环境（operating environment），然而这些环境不却是完整的操作系统。容器通常只包含必要的 OS 软件包和应用。他们通常不包含一个完整的操作系统或者硬件虚拟化。这也意味着比之虚拟机，容器的额外开销（overhead）更小。 容器和虚拟机通常被视为不能共生的技术，然而这通常是一个误解。虚拟机面向物理服务器，提供可以能与其他虚拟机一起共享这些物理资源的，功能完善的操作环境。容器通常是用来通过对单一主机的一个进程进行隔离，来保证被隔离的进程无法与处于同一个系统的其他进程进行互动。实际上，比起完全的虚拟机，容器与 BSD 的 Jail，chroot 的进程更加类似。 Docker 提供了什么Docker自身并不是一个容器的运行时环境；实际上 Docker 实际上是对容器技术不可知的（container technology agnostic），并且为了支持Solaris Zones和 BSD Jails 花了不少功夫。Docker 提供的是一种容器管理，打包和部署的方法。尽管这种类型的功能已经某一种程度地存在于虚拟机中，但在传统上，它们并不是为了绝大多数的容器方案而生的，而那些已经存在的，却又不如 Docker 一样容易使用且功能完善。 通过 Dockerfile 方式部署一个 blog (转载) 获取 blog 源码 12git clone http://github.com/madflojo/blog.gitcd blog 使用 FROM 继承一个 docker 镜像Dockerfile的第一条命令是 FROM 指令。这用来将存在的 Docker 镜像指定为基础镜像，这会让docker 使用 nginx 镜像。如果想使用最原始的空白状态。可以制定 ubuntu:latest使用 ubuntu 镜像。 12FROM nginx:latestMAINTAINER Charlie.Cui &lt;charlie.cui127@mail.com&gt; 除了使用 FROM 指令，还使用了 MAINTAINER 指令，用来显示 Dockerfile 的作者。Docker支持使用 # 用来当做注释的标示。 使用 RUN 来执行 apt-get 如果需要在 docker 中执行 apt update 和 apt install python-dev，可以通过 RUN 指令来实现。12345FROM nginx:latestMAINTAINER Charlie.Cui &lt;charlie.cui127@mail.com&gt;RUN apt -qq updateRUN apt -qqy install python-dev python-pip 安装 python 模块 如果需要安装 python 模块，在 docker 之外，可以使用 pip 命令完成并且引用在仓库中的一个名叫requirements.txt文件。Dockerfile 使用 COPY 指令123456789FROM nginx:latestMAINTAINER Charlie.Cui &lt;charlie.cui127@mail.com&gt;RUN apt -qq updateRUN apt -qqy install python-dev python-pipRUN mkdir -p /build/COPY requirements.txt /build/RUN pip install -r /build/requirements.txt 构建容器 1docker build -t blog:v1 . 使用 -t 表示来讲这个镜像打上 blog 标签 Docker 构建缓存 当docker 构建一个镜像的时候，不仅仅构建一个单一的镜像，它实际上在整个构建过程中构建多个镜像。每进行一步会构建一个镜像，当构建相同的容器时，会使用已经缓存的镜像，而不是重新构建一个镜像。凡是都会有两面，好的一面是当应用场景是 copy 文件，当源文件被更改，再次运行时 docker 会检测到文件不同，会从新 copy 新的文件，但是如果是安装 python-dev 这个软件包，当仓库更新了软件包版本，docker 是没法检测到这个变化，会傻傻的使用缓存，这样就会安装了一个老版本的软件。解决这个需要在 docker 构建时制定 --no-cache=True 来禁用缓存 部署 blog 其余部分 1234567891011121314151617FROM nginx:latestMAINTAINER Charlie.Cui &lt;charlie.cui127@mail.com&gt;RUN apt -qq updateRUN apt -qqy install python-dev python-pipRUN mkdir -p /build/COPY requirements.txt /build/RUN pip install -r /build/requirements.txtCOPY static /build/staticCOPY templates /build/templatesCOPY hamerkop /build/COPY config.yml /build/COPY articles /build/articlesRUN /build/hamerkop -c /build/config.yml 当再次运行 docker build -t blog:v1 .来构建 docker 镜像 运行一个定制化的容器 1docker run -d -p 80:80 --name=blog blog:v1 使用-p参数，可以标志让用户将一个端口从主机映射到容器的一个端口，]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[docker镜像]]></title>
      <url>http://czero000.github.io/2016/10/20/docker-images.html</url>
      <content type="text"><![CDATA[镜像什么是镜像 镜像是 Docker 的三大组件之一 Docker 镜像就是一个只读模版，一个镜像可以包含一个完整的ubuntu 操作系统，系统安装了 apache 和用户自定义应用软件。 镜像可以用来创建容器，Docker 提供了一个简单的机制来创建镜像或者更新现有镜像，用户甚至可以直接从其他人哪里下载已经做好的镜像来使用 Docker 运行容器之前需要本地存在对应镜像，如果不存在，Docker 就会从镜像仓库下载(默认是 Docker Hub 公共注册服务器的仓库) 获取镜像通过 docker pull 命令从仓库下载所需的镜像，镜像可以通过 Docker Hub 获取已有镜像并更新，也可以利用本地文件系统创建一个12\\下载一个ubuntu16.04操作系统镜像 docker pull ubuntu:16.04 该命令实际上是docker pull registry.hub.docker.com/ubuntu:16.04命令，即从注册服务器registry.hub.docker.com中的ubuntu仓库下载标记为16.04的镜像有的时候官方注册服务器下载较慢，可以从其他仓库下载，如：1docker pull somedomain:5000/ubuntu:16.04 列出当前镜像123docker images REPOSITORY TAG IMAGE ID CREATED SIZEubuntu 16.04 c73a085dc378 2 weeks ago 127.1 MB 在列出的信息中，可以看到几个字段的信息 来自那个仓库 -&gt; ubuntu 镜像的标记 -&gt; latest、16.04 ID -&gt; 唯一 创建时间 镜像大小TAG信息标记来自同一个仓库的不同镜像，例如ubuntu仓库有多个镜像，通过TAG信息区分放行版本，例如，10.04、12.04、12.10等。通过下面命令指定镜像 12\\ 通过ubuntu:16.04 启动一个容器docker run -t -i ubuntu:16.04 /bin/bash 如果不执行 TAG，则默认使用 latest 标记信息 修改已有镜像 利用镜像启动一个容器1docker run --name docker_test -i -t -d ubuntu:16.04 /bin/bash 在容器中添加vim软件1apt install -y vim 当结束后，使用exit退出，现在容器被改变了，使用docker commit命令提交更新后的副本12docker commit -m &quot;Added Vim&quot; -a &quot;charlie.cui&quot; 50eabeaf73f6 ubuntu:16.04v2325a4e26e96fdefb70a9941db1c19ead801cf3ac5d9228bca6fc6c1a13c0ab92 -m 来指定提交的说明信息,与使用版本控制工具一样 -a 可以指定更新的用户信息 容器ID 指定目标镜像仓库名和tag信息成功创建之后便会返回镜像的ID信息 使用 docker images 来查看新创建的镜像 之后便可以使用新的镜像启动容器1docker run -t -i ubuntu:16.04v2 /bin/bash 利用 Dockerfile 来创建镜像使用 docker commit 来扩展一个镜像相对简单，但是不方便在一个团队中分享。可以使用 docker build 来创建一个新的镜像，首先需要创建一个 Dockerfile ，包含一些如何创建镜像的指令 新建一个目录和一个 Dockerfile 123mkdir dockercd docker/touch Dockerfile Dockerfile 中每一条指令都创建镜像的一层123456cat Dockerfile#This is a commentFROM ubuntu:16.04MAINTAINER Charlie.Cui &lt; charlie.cui127@gmail.com &gt; RUN apt-get -qq updateRUN apt-get -qqy install vim Dockerfile 的基本语法 使用#来注释 FROM指令告诉Docker使用哪个镜像作为基础镜像 接着为维护者信息 RUN开头的指令会在创建中运行，比如安装一个软件包，在这里使用apt-get安装vim 编写 Dockerfile 之后，可以使用 docker build 来生成镜像123456789101112131415docker build -t &quot;ubuntu16.04:v1&quot; . Sending build context to Docker daemon 3.072 kBStep 1 : FROM ubuntu:16.04 ---&gt; e9ae3c220b23Step 2 : MAINTAINER Charlie.Cui ---&gt; Using cache ---&gt; 16d77dc9a444Step 3 : RUN apt-get -y -qq update ---&gt; Running in b8407b9d75c4 ---&gt; 8721117f7c1f...Processing triggers for libc-bin (2.19-0ubuntu6.6) ... ---&gt; 5a4b35abd4c4Removing intermediate container bb09f1a73b30Successfully built 5a4b35abd4c4 其中 -t 标记添加 tag，指定新的镜像用户信息。 .是 Dockerfile 所在的路径(当前目录)，也可以使用一个具体的 Dockerfile 路径 上面的过程可以看到 build 进程在执行操作。它所做的第一件事就是上传 Dockerfile 内容，应为所有的操作都是根据 Dockerfile 内容来执行。然后，Dockfile 中的指令被一条一条的执行，每一步都创建了一个新的容器，在容器中执行指令并提交修改(跟 docker commit 命令一样)。当所有的指令执行之后，返回最终的镜像 ID，所有的中间步骤产生的容器都被清理掉。 注： Dockerfile 中执行命令不能超过127 此外，还可以利用 ADD 命令赋值本地文件到镜像；用 EXPOSE 命令向外部开放端口；用 CMD 命令来描述容器启动后运行的程序123ADD myApp /var/wwwEXPOSE 80CMD [&quot;/usr/sbin/apachectl&quot;, &quot;-d&quot;, &quot;FOREGROUND&quot;] 现在可以利用新创建的镜像启动一个容器1docker]# docker run -t -i ubuntu16.04:v1 /bin/bash 还可以用 docker tag命令修改镜像标签1docker tag 5a4b35abd4c4 ubuntu16.04:devel 本地文件系统导入要从本地文件系统导入一个镜像，可以使用openvz的模版来创建：openvz的模版下载地址：http://openvz.org/Download/templates/precreated 下载一个centos-7-x86_64的镜像，使用下面命令导入123wget http://download.openvz.org/template/precreated/centos-7-x86_64.tar.gzcat centos-7-x86_64.tar.gz | docker import - centos:745a9c0d13bd2d94a69f8a70501541f5329dbbc4760e610013a801d8e11d8cb46 查看导入的新镜像123docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEcentos 7 45a9c0d13bd2 7 minutes ago 564.3 MB 存出镜像如果想要导出镜像到本地文件，可以使用docker save命令12\\ 保存镜像到本地文件docker save -o ubuntu_16.04.tar ubuntu:16.04 载入镜像可以使用docker load从导出的本地文件在导入到本地镜像库,命令会导入镜像以及其他的元数据信息(标签等)123docker load --input ubuntu_16.04.tar或者docker load &lt; ubuntu_16.04.tar 移除本地镜像如果要移除本地镜像，使用docker rmi命令1dock rmi ubuntu:16.04 在删除镜像之前要先docker rm删除掉依赖于这个镜像的容器 清理所有为打过标签的本地镜像docker images 可以列出本地的所有镜像，其中有很多中间状态的未打过标签的镜像，大量占用磁盘空间，使用下面命令清理本地镜像 1234docker rmi $(docker images -q -f &quot;dangling=true&quot;)\\ 完整写法docker rmi $(docker images --quiet --filter &quot;dangling=true&quot;) 镜像的实现原理 Docker 镜像是怎么实现增量的修改和维护的？ 每个镜像都由很多层次构成，Docker 使用 Union FS 将这些不同的层结合到一个镜像中去。通常 Union FS 有两个用途, 一方面可以实现不借助 LVM、RAID 将多个 disk 挂到同一个目录下,另一个更常用的就是将一个只读的分支和一个可写的分支联合在一起，Live CD 正是基于此方法可以允许在镜像不变的基础上允许用户在其上进行一些写操作。 Docker 在 AUFS 上构建的容器也是利用了类似的原理。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker入门介绍]]></title>
      <url>http://czero000.github.io/2016/10/20/rudiments-of-docker.html</url>
      <content type="text"><![CDATA[Docker 简介Docker 是什么 Docker is an open-source engine that automates the deployment of any application as a lightweight, portable, self-sufficient container that will run virtually anywhere. Docker[http://www.docker.com/] 是 PaaS 提供商 dotCloud 开源的一个基于 LXC 的高级容器引擎， ]源代码托管在 Github 上, 基于go语言并遵从Apache2.0协议开源。Docker近期非常火热，无论是从 GitHub 上的代码活跃度，还是Redhat宣布在 RHEL7中正式支持Docker，都给业界一个信号，这是一项创新型的技术解决方案。就连 Google 公司的 Compute Engine 也支持 docker 在其之上运行，国内 “BAT” 先锋企业百度 Baidu App Engine(BAE) 平台也是以Docker作为其PaaS云基础。 Docker产生的目的就是为了解决以下问题： 环境管理复杂：从各种 OS 到各种中间件再到各种 App，一款产品能够成功发布，作为开发者需要关心的东西太多，且难于管理，这个问题在软件行业中普遍存在并需要直接面对。Docker可以简化部署多种应用实例工作，比如 Web 应用、后台应用、数据库应用、大数据应用比如 Hadoop 集群、消息队列等等都可以打包成一个 Image 部署。 云计算时代的到来：AWS 的成功，引导开发者将应用转移到云上, 解决了硬件管理的问题，然而软件配置和管理相关的问题依然存在 (AWS cloudformation是这个方向的业界标准, 样例模板可参考这里)。Docker 的出现正好能帮助软件开发者开阔思路，尝试新的软件管理方法来解决这个问题。 虚拟化手段的变化：云时代采用标配硬件来降低成本，采用虚拟化手段来满足用户按需分配的资源需求以及保证可用性和隔离性。然而无论是 KVM 还是 Xen，在 Docker 看来都在浪费资源，因为用户需要的是高效运行环境而非OS，GuestOS 既浪费资源又难于管理，更加轻量级的 LXC 更加灵活和快速。 LXC 的便携性：LXC 在 Linux 2.6 的 Kernel 里就已经存在了，但是其设计之初并非为云计算考虑的，缺少标准化的描述手段和容器的可便携性，决定其构建出的环境难于分发和标准化管理(相对于 KVM 之类 image 和 snapshot 的概念)。Docker 就在这个问题上做出了实质性的创新方法。 Docker的主要特性 文件系统隔离： 每个进程容器运行在完全独立的根文件系统里。 资源隔离： 可以使用 cgroup 为每个进程容器分配不同的系统资源，例如 CPU 和内存。 网络隔离： 每个进程容器运行在自己的网络命名空间里，拥有自己的虚拟接口和 IP 地址。 写时复制： 采用写时复制方式创建根文件系统，这让部署变得极其快捷，并且节省内存和硬盘空间。 日志记录： Docker 将会收集和记录每个进程容器的标准流（stdout/stderr/stdin），用于实时检索或批量检索。 变更管理： 容器文件系统的变更可以提交到新的映像中，并可重复使用以创建更多的容器。无需使用模板或手动配置。 交互式 Shell： Docker 可以分配一个虚拟终端并关联到任何容器的标准输入上，例如运行一个一次性交互 shell。 Docker vs 传统虚拟化技术作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式（xen、kvm、vmware）相比具有众多的优势。 首先，Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多。 其次，Docker 对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器。容器除了运行其中应用外，基本不消耗额外的系统资源，使得应用的性能很高，同时系统的开销尽量小。传统虚拟机方式运行 10 个不同的应用就要起 10 个虚拟机，而 Docker 只需要启动 10 个隔离的应用即可。 具体说来，Docker 在如下几个方面具有较大的优势。 更快速的交付和部署对开发和运维（devop）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码。 Docker 可以快速创建容器，快速迭代应用程序，并让整个过程全程可见，使团队中的其他成员更容易理解应用程序是如何创建和工作的。 Docker 容器很轻很快！容器的启动时间是秒级的，大量地节约开发、测试、部署的时间。 更高效的虚拟化Docker 容器的运行不需要额外的 hypervisor 支持，它是内核级的虚拟化，因此可以实现更高的性能和效率。 更轻松的迁移和扩展Docker 容器几乎可以在任意的平台上运行，包括物理机、虚拟机、公有云、私有云、个人电脑、服务器等。 这种兼容性可以让用户把一个应用程序从一个平台直接迁移到另外一个。 更简单的管理使用 Docker，只需要小小的修改，就可以替代以往大量的更新工作。所有的修改都以增量的方式被分发和更新，从而实现自动化并且高效的管理。 对比传统虚拟机总结： 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 Docker vs lxcDocker 以 Linux 容器 LXC 为基础，实现轻量级的操作系统虚拟化解决方案。在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便，具体改进有 Portable deployment across machines Docker 提供了一种可移植的配置标准化机制，允许你一致性地在不同的机器上运行同一个 Container；而 LXC 本身可能因为不同机器的不同配置而无法方便地移植运行； Application-centric Docker 以 App 为中心，为应用的部署做了很多优化，而 LXC 的帮助脚本主要是聚焦于如何机器启动地更快和耗更少的内存； Automatic buildDocker 为 App 提供了一种自动化构建机制（Dockerfile），包括打包，基础设施依赖管理和安装等等； Versioning Docker 提供了一种类似 git 的 Container 版本化的机制，允许你对你创建过的容器进行版本管理，依靠这种机制，你还可以下载别人创建的 Container，甚至像 git 那样进行合并； Component reuse Docker Container 是可重用的，依赖于版本化机制，你很容易重用别人的 Container，作为基础版本进行扩展； Sharing Docker Container 是可共享的，有点类似 github 一样，Docker 有自己的 INDEX，你可以创建自己的 Docker 用户并上传和下载 Docker Image； Tool ecosystem Docker 提供了很多的工具链，形成了一个生态系统；这些工具的目标是自动化、个性化和集成化，包括对 PAAS 平台的支持等。 docker 应用场景Docker 作为一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。Docker 可以自动化打包和部署任何应用、创建一个轻量级私有 PaaS 云、搭建开发测试环境、部署可扩展的 Web 应用等。这决定了它在企业中的应用场景是有限的，Docker 将自己定位为“分发应用的开放平台”，其网站上也明确地提到了 Docker的典型应用场景 Automating the packaging and deployment of applications Creation of lightweight, private PAAS environments Automated testing and continuous integration/deployment Deploying and scaling web apps, databases and backend services 对应用进行自动打包和部署，创建轻量、私有的 PAAS 环境，自动化测试和持续整合与部署，部署和扩展Web应用、数据库和后端服务。 平台即服务一般与大数据量系统同在，反观当前我司各 IT 系统，可以在以下情形下使用 docker 替代方案： 结合 vagrant 或 supervisor，搭建统一的开发、测试环境多个开发人员共同进行一个项目，就必须保持开发环境完全一致，部署到测试环境、正式环境后，最好都是同一套环境，通过容器来保存状态，分发给开发人员或部署，可以让“代码在我机子上运行没有问题”这种说辞将成为历史。 对 memcached、mysql 甚至 tomcat，打包成一个个容器，避免重复配置比如将一个稳定版本的、已配置完善的 mysql，固化在一个镜像中，假如有新的环境要用到 mysql 数据库，便不需要重新安装、配置，而只需要启动一个容器瞬间完成。tomcat 应用场景更多，可以将不同版本的 jvm 和 tomcat 打包分发，应用于多 tomcat 集群，或在测试服务器上隔离多个不同运行环境要求的测试应用（例如旧系统采用的是 jdk6，新系统在jdk7上开发，但共用同一套测试环境）。 docker不足 LXC 是基于 cgroup 等 linux kernel 功能的，因此 container 的 guest 系统只能是 linux base 的 隔离性相比 KVM之类的虚拟化方案还是有些欠缺，所有 container公用一部分的运行库 网络管理相对简单，主要是基于 namespace 隔离 cgroup 的 cpu 和 cpuset 提供的 cpu 功能相比 KVM 的等虚拟化方案相比难以度量(所以 dotcloud 主要是安内存收费) container 随着用户进程的停止而销毁，container 中的 log 等用户数据不便收集 另外，Docker 是面向应用的，其终极目标是构建 PAAS 平台，而现有虚拟机主要目的是提供一个灵活的计算资源池，是面向架构的，其终极目标是构建一个 IAAS 平台，所以它不能替代传统虚拟化解决方案。目前在容器可管理性方面，对于方便运维，提供 UI 来管理监控各个 containers的功能还不足，还都是第三方实现如 DockerUI、Dockland、Shipyard 等。 docker 组成部分Docker 使用客户端-服务器 (client-server) 架构模式。Docker 客户端会与 Docker 守护进程进行通信。Docker 守护进程会处理复杂繁重的任务，例如建立、运行、发布你的Docker 容器。Docker 客户端和守护进程可以运行在同一个系统上，当然你也可以使用 Docker 客户端去连接一个远程的 Docker 守护进程。Docker 客户端和守护进程之间通过socket或者 RESTful API 进行通信。 images 镜像Docker 镜像就是一个只读的模板。例如，一个镜像可以包含一个完整的 ubuntu 操作系统环境，里面仅安装了 Apache 或用户需要的其它应用程序。镜像可以用来创建 Docker 容器。Docker 提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。 container 容器Docker 利用容器来运行应用。容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。 镜像是只读的，容器在启动的时候创建一层可写层作为最上层。 repository 仓库仓库是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。 公开仓库 docker团队控制的top-level的顶级repository，即Docker Hub，存放了数量庞大的镜像供用户下载，任何人都能读取，里面包含了许多常用的镜像，如ubuntu, mysql ,redis, python等。 个人仓库 个人公共库也是被托管在Docker Hub上，网络上的其它用户也可以pull你的仓库（如docker pull seanloook/centos6）你可以在修改完自己的container之后，通过commit命令把它变成本地的一个image，push到自己的个人公共库。（在此之前你需要docker login登录，或者vi ~/.dockercfg。） 私有仓库 首先与另外一种仓库区分——Docker Hub Private Repository，它简单理解为公网上的个人私有库，与上面的个人公共库相对应，在Docker Hub上Create Repository时选择Private便是，只有你自己才可以读写。这里所说的私有仓库是指自己在本地服务器上搭建的专属自己的内部仓库docker-registry，俗称“私服”，供无法访问互联网的内部网络使用，或者镜像到本地一份以加快pull、push的速度。它与公共仓库最明显的区分就是repository的命名，如必须使用带.的主机名或域名，后面必须接:port，如sean.tp-link.net:5000/centos6:your_tag_name，而公共仓库第一个斜杠前表示的是登录用户名。命名关系到推送到哪个服务器的哪个位置， 运行一个容器的内部过程docker client告诉docker daemon运行一个容器，例如：docker run -i -t ubuntu /bin/bash让我们分解一下这个命令，docker client启动使用一个二进制的docker命令，最小的docker client需要你告诉docker daemon你的容器是从哪个docker镜像构建的，你希望在容器内部运行哪个命令。所以启动过程如下： Pulling the ubuntu image docker检查是否存在ubuntu镜像，如果本地不存在ubuntu镜像，则docker会到docker index下载。 Creates a new container 利用镜像创建容器 Allocates a filesystem and mounts a read-write layer 为镜像创建文件系统层和read-write层 Allocates a network / bridge interface 为容器创建网络接口，使容器和本地机器可以通讯 Sets up an IP address 在地址池中为容器分配一个可用的IP地址 Executes a process that you specify 运行你的应用 Captures and provides application output 连接log的标准输入、输出、错误，以使你直到你的应用是否正常运行 安装 DockerDocker可以运行在Ubuntu16.04 LTS 和 CentOS7.x上，可能会和其他的二进制 EL7 兼容工作，但是 Docker 官方并没有去做测试。 准备先决条件： 运行64为CPU架构（x86_64和amd64），不支持32位 运行Linux3.8 或更高版本，老版本的2.6.x及之后版本也可以运行，但是运行结果大不相同 内核必须支持合适的存储驱动（storagedriver） Device Manager AUFS vfs btrfs 内核必须支持并开启cgroup和命名空间功能 安装 更新系统 123apt-get updateapt install linux-image-extra-$(uname -r) linux-image-extra-virtualapt-get install apt-transport-https ca-certificates 添加 GPG Key 1apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D 增加安装源 123456789vim /etc/apt/sources.list.d/docker.list// On Ubuntu Precise 12.04 (LTS)deb http://apt.dockerproject.org/repo ubuntu-precise main// On Ubuntu Trusty 14.04 (LTS)deb http://apt.dockerproject.org/repo ubuntu-trusty main// Ubuntu Wily 15.10deb http://apt.dockerproject.org/repo ubuntu-wily main// Ubuntu Xenial 16.04 (LTS)deb http://apt.dockerproject.org/repo ubuntu-xenial main 安装docker 12apt updateapt install docker 启动docker 1systemctl start docker 验证启动 1234567891011121314docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 1.12.2Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 0 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfs 使用 Docker及 docker 命令汇总查看 docker 信息 查看 docker 版本 1docker Version 显示 docker 系统的信息 1docker info 镜像相关 检索 image 12// docker search image_namedocker search ubuntu:16.04 下载一个预建立的镜像 1234// docker pull image_namedocker pull ubuntu:16.04Digest: sha256:28d4c5234db8d5a634d5e621c363d900f8f241240ee0a6a978784c978fe9c737Status: Downloaded newer image for ubuntu:16.04 这个将从索引仓库中通过名字找到ubuntu镜像，并从索引仓库中心下载到本地镜像存储当镜像下载成功后，你可以看到12位的hash值，如c73a085dc378，这是下载完整的镜像的精简ID，这些短的镜像ID是完整镜像ID前12个字符—可以使用docker inspect或者docker images -no-trunc=true来获取完整镜像ID 列出镜像列表 1docker images 删除一个或者多个镜像 12//docker rmi image_namedocker rmi ubuntu:16.04 显示一个镜像的历史 12// docker history image_namedocker history ubuntu:16.04 容器操作 创建容器 12//使用 docker run 命令创建容器,-i 保证容器中 STDIN 开启，-t 分配一个伪终端docker run -i -t ubuntu /bin/bash 使用 ubuntu:16.04 运行一个交互性的 shell,分配一个伪终端，附带 stdin 和 stout ,如果想要退出伪终端，使用 CTRL -p + CTRL -q,容器只有在指定的 /bin/bash 命令处于运行状态，容器才会运行，一旦退出 /bin/bash，容器随之停止。 如果容器因为某种错误导致停止，可以通过--restart标志，让docker自动重启容器。–restart会检查容器的退出状态，并据此来判断是否要重启容器1docker run --restart=always --name=docker_test -i -t -d ubuntu:16,04 /bin/bash 容器命名 容器命名可以是使用小写字母a-z、大写字母A-Z、数字0-9、下划线、圆点、横线。容器的命名必须是唯一1docker run --name docker_test -i -t ubuntu:16.04 /bin/bash 可以通过增加 -d 参数，创建一个长时间运行的容器1docker run --name docker_test -i -t -d ubuntu:16.04 /bin/bash 查看容器状态 通过 docker ps -a可以列出所有停止、运行的容器123docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESfd74d17e54f1 ubuntu:16.04 &quot;/bin/bash&quot; 2 minutes ago Up 2 minutes docker_test 查看容器进程 1docker top docker_test 深入容器 12// 获取更加详细的 docker 信息docker inspect docker_test 启动、重启、连接容器 1234567891011//启动docker start docker_test//停止docker stop docker_test// 杀死docker stop docker_test// 连接docker sttach docker_test 在容器内部运行进程 12345// -d 表明在后台运行一个进程docker exec -d docker_test touch /etc/new_config_file// 打开一个交互性的shelldocker exec -i -t docker_test /bin/bash 查看容器输出 12345678//到目前为止收集的输出docker logs docker_test//使用-f 可以监控docker输出docker logs -f docker_test//加上tail 命令可以查看某段输出，如最后10行docker log --tail 10 docker_tet//使用 -t 可以在每条日志加上时间戳docker log -ft docker_test 保存容器 12// docker commit id new_image_namedocker commit 2194cf55f5ea docker_test 删除容器 1234// 所有容器docker rm `docker ps -a -q`// 指定容器docker rm name/id 查看容器被修改的文件或目录 1docker diff docker_test 拷贝文件 1docker cp [name|id]:container_path local_path 保存和加载镜像 保存镜像 1docker save image_name -o file_path 加载本地镜像 1docker load -i file_path]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ansible-Playbooks]]></title>
      <url>http://czero000.github.io/2016/10/19/ansible-playbook.html</url>
      <content type="text"><![CDATA[PlaybooksPlaybooks 是 Ansible 的配置、部署、编排语言，相当于控制远程主机的一系列命令的集合，通过 YAML 语言编写。Ansible-Playbook 命令根据自上而写的顺序依次执行。 Playbook 允许传输摸个命令的状态到后面的指令，或者从一台主机的文件中获取内容并赋值变量，然后传给另外一台主机使用，这是 ansible 命令无法实现的。 YAML 语法介绍文件开始符1--- 数组列表列表中的所有成员都开始于相同缩进级别，并使用 - 来作为开头123- Apple- Orange- Mango 字典字典是有一个简单的 Key: value 形式组成，注意 : 后面有空格123name: charliejob: Developermail: charlie.cui127@gmail.com 在 playbook 中会有更为复杂的用法 字典与字典嵌套 1234martin: name: Martin D&apos;vloper job: Developer skill: Elite 字典与数组的嵌套 1234567891011121314- martin: name: Martin D&apos;vloper job: Developer skills: - python - perl - pascal- tabitha: name: Tabitha Bitumen job: Developer skills: - lisp - fortran - erlang 注意，如果变量里有 :,则需要加引号1foo: &quot;&#123;&#123; variable &#125;&#125;&quot; Playbook 基本用法最基本的 playbook 分为三部分： 在什么机器上以什么身份执行 hosts users 定义 playbook 执行需要的变量 variable 执行的任务是都有什么 tasks 善后的任务是什么 handlers 执行 Playbook 12345// 执行playbookAnsible-playbook user.yaml// 查看详细输出ansible-playbook user.yaml --list-hosts 示例官方示例要学习更多的 playbook 用法，可以通过Playbooks 官方示例。 Playbook 分享平台Ansible 提供了一个 Playbook 的分享平台，上面的例子是有 Ansible 使用者自己上传的。Ansible分享平台 简单示例 创建用户 12345678910111213141516// 新增一个用户cat user.yaml---- name: create user hosts: all \\ host or group user: root gather_facts: false vars: \\ variable - user: &quot;charlie&quot; tasks: \\ tasks - name: create user user: name= &quot;&#123;&#123; user &#125;&#125;&quot; notify: create user ok handlers: - name: create user ok debug: msg= &quot;Create User OK&quot; name 参数对该 playbook 实现功能的一个概述，后面执行过程中会打印 name 变量值 hosts 参数指定了那些主机 user 参数执行了使用什么用户登陆远程主机 gather_facts 参数指定了下面任务执行前，是否先执行 setup 模块获取主机相关信息，这些后面 task 会使用 setup 获取的信息 vars 参数指定了变量， 变量 user，值为 charlie，值得注意的是参数要用引号 task 指定了一个任务，下面的 name 参数同样是对任务的描述，在执行过程中打印出来。user 指定了调用 user模块，name 是user模块中的参数，增加的用户名是上面 user 的值 执行结果1234567891011121314151617ansible-playbook user.yamlPLAY [create user] *************************************************************TASK [create user] *************************************************************changed: [172.16.11.210]changed: [172.16.11.211]RUNNING HANDLER [create user] **************************************************ok: [172.16.11.210] =&gt; &#123; &quot;msg&quot;: &quot;Create User OK&quot;&#125;ok: [172.16.11.211] =&gt; &#123; &quot;msg&quot;: &quot;Create User OK&quot;&#125;PLAY RECAP *********************************************************************172.16.11.210 : ok=1 changed=1 unreachable=0 failed=0 172.16.11.211 : ok=1 changed=1 unreachable=0 failed=0 安装apache 12345678910111213141516171819cat apache.yaml---- hosts: all vars: http_port: 80 max_clients: 2048 user: root tasks: - name: ensure apache is at latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted 主机和用户 Host and User在执行 playbook 时，可以选择操作的目标主机是那些，以那个用户执行host 行的内容是一个或多个主机的 patterns， 以逗号分隔123---- hosts: 172.16.11.210, 172.16.11.211, [all] remote_user: root 还可以在每个 task 中，定义远程执行用户1234567---- hosts: all user: root tasks: - name: test connection ping: remote_user: root 也支持 sudo 方法,在 task中同样支持,在 sudo 需要密码时，可以加上选项 –ask-sudo-pass12345678---- hosts: all remote_user: charlie sudo: yes task： - service： name=nginx state=started sudo: yes sudo_user: root 任务列表 Tasks tasks 是从上到下顺序执行，如果中间发生错误，整个 playbook 便会中断。 每一个 task 是对module的一次调用,通常会带有特定参数，参数可以使用变量。 每一个 task 必须有一个 name 属性，name 值会在命令行中输出，以提示用户，如果没有定义，aciton 的值会作为输出信息来标记task 语法12345678910111213141516171819202122232425262728293031tasks: - name: make sure apache is running service: name=httpd state=running// 如果参数过长，可以使用空格或者缩进分隔为多行tasks: - name: copy ansible inventory file to client copy: src=/etc/ansible/hosts dest=/etc/ansible/hosts owner=root group=root mode=0644// 或者使用 yaml 的字典作为参数tasks: - name: copy ansible inventory file to client copy: src: /etc/ansible/hosts dest: /etc/ansible/hosts owner: root group: root mode: 0644// 大部分的模块都是使用 `key-value` 这种格式的，其中有两个比较特殊，command 和 shell 模块。tasks: - name: disable selinux command: /sbin/setenforce 0tasks: - name: run this command and ignore the result shell: /usr/bin/command || /bin/truetasks: - name: run some command and ignore the reslut shell: /usr/bin/somecommadn ignore_error: True 执行状态task 中每个 action 会调用一个 module，在 module 中会去检查当前系统状态是否需要重新执行，具体判断需要有各个 module 自己来实现。 如果执行那么 action 会得到返回值 changed； 如果部执行，那么 action 会得到返回值 OK 状态实例 以一个 copy 文件为例123456789101112131415161718192021222324252627282930313233343536373839404142// playbookcopy.yaml ---- name: copy a test file hosts: all user: root tasks: - name: copy a test file to /opt/ansible copy: src=/opt/ansible/test.txt dest=/opt/ansible/// 第一次执行结果ansible-playbook copy.yamlPLAY [copy a test file] ********************************************************TASK [setup] *******************************************************************ok: [172.16.11.211]ok: [172.16.11.210]TASK [copy a test file to /opt/ansible] ****************************************changed: [172.16.11.210]changed: [172.16.11.211]PLAY RECAP *********************************************************************172.16.11.210 : ok=2 changed=1 unreachable=0 failed=0 172.16.11.211 : ok=2 changed=1 unreachable=0 failed=0 // 第二次执行结果ansible-playbook copy.yamlPLAY [copy a test file] ********************************************************TASK [setup] *******************************************************************ok: [172.16.11.211]ok: [172.16.11.210]TASK [copy a test file to /opt/ansible] ****************************************ok: [172.16.11.210]ok: [172.16.11.211]PLAY RECAP *********************************************************************172.16.11.210 : ok=2 changed=0 unreachable=0 failed=0 172.16.11.211 : ok=2 changed=0 unreachable=0 failed=0 可以看到第一次 task的状态是 changed 状态，第二次再次执行，task 状态是 OK，说明文件已经存在，避免 ansible 再次重复执行。 响应事件 Handler什么是 handler每个主流的变成语言都会有 event 机制，那么 handler 就是 playbook 的 event。Handler 里面的每个 handler，也是对 module 的一次调用。不同的是 handler 不会默认的按照顺序执行。Tasks 中的任务是有状态的，changed 或者 ok。 在 Ansible 中，只有 task 的执行状态为 changed 时，才会触发，这就是 handler。 应用场景如果在 tasks 中修改了某个服务的配置文件，就需要重新启动服务，重新启动服务就可以设计成为一个 handler 触发Handlers只有 action 是 changed 时，才会执行 handler 第一次执行时，tasks 的状态是 changed， 回触发 handler 第二次执行时，task 的状态是 OK， 那么就不会触发 handler 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 一个 handler 最多被执行一次,在任务执行中，有多个 task notify 同一个 handler， 那么只执行一次---- name: handler state hosts: all remote_user: root vars: random_number1: &quot;&#123;&#123; 10 | random &#125;&#125;&quot; random_number2: &quot;&#123;&#123; 100 | random &#125;&#125;&quot; tasks: - name: Copy the /etc/hosts to /opt/ansible/host.&#123;&#123; random_number1 &#125;&#125; copy: src=/etc/hosts dest=/opt/ansible/host.&#123;&#123; random_number1 &#125;&#125; notify: - call in every action - name: Copy the /etc/hosts to /opt/ansible/host.&#123;&#123; random_number2 &#125;&#125; copy: src=/etc/hosts dest=/opt/ansible/host.&#123;&#123; random_number2 &#125;&#125; notify: - call in every action handlers: - name: call in every action debug: msg=&apos;call in every action, but execute only one time&apos;// 按照 handler 的定义顺序执行,handlers 是按照在 handlers 中定义的顺序执行的， 而不是按照 notify 的顺序执行的// notify 的定义顺序是 3 &gt; 2 &gt; 1，而实际 handler 结果是 handler 定义的顺序 1 &gt; 2 &gt; 3。cat handler_notify.yaml ---- hosts: all gather_facts: no remote_user: root vars: random_number1: &quot;&#123;&#123; 10 | random &#125;&#125;&quot; random_number2: &quot;&#123;&#123; 100 | random &#125;&#125;&quot; random_number3: &quot;&#123;&#123; 1000 | random &#125;&#125;&quot; tasks: - name: copy the /ets/hosts to /tmp/hosts.&#123;&#123; random_number1 &#125;&#125; copy: src=/etc/hosts dest=/tmp/hosts.&#123;&#123; random_number1 &#125;&#125; notify: - define the 3nd handler - name: copy the /ets/hosts to /tmp/hosts.&#123;&#123; random_number2 &#125;&#125; copy: src=/etc/hosts dest=/tmp/hosts.&#123;&#123; random_number2 &#125;&#125; notify: - define the 2nd handler - name: copy the /ets/hosts to /tmp/hosts.&#123;&#123; random_number3 &#125;&#125; copy: src=/etc/hosts dest=/tmp/hosts.&#123;&#123; random_number3 &#125;&#125; notify: - define the 1nd handler handlers: - name: define the 1nd handler debug: msg=&quot; defind the 1nd handler&quot; - name: define the 2nd handler debug: msg=&quot; defind the 2nd handler&quot; - name: define the 3nd handler debug: msg=&quot; defind the 3nd handler&quot; playbook roles 和 include在刚开始使用 playbook 时，习惯性会把 playbook 写成一个很大的文件，然而在实际情况下， 有些文件是可以重用的。playbook 可以使用 include，把其他 playbook 文件中的 variables、tasks 或者 handlers 从其他文件拉取过来。 规划目录组织结构通过目录规格，可以使 playbook 模块化，使代码易读、可以重用、层次清晰。 可以通过 ansible-galaxy 工具，初始化一个 role 目录123456789101112131415161718192021// initansible-galaxy init httpd// tree.├── defaults│ └── main.yml├── files├── handlers│ └── main.yml├── meta│ └── main.yml├── README.md├── tasks│ └── main.yml├── templates├── tests│ ├── inventory│ └── test.yml└── vars └── main.yml include 语句普通用法12345678// 可以像其他 include 语句一样， 直接include# possibly saved as tasks/firewall_httpd_default.yaml- name: insert firewalld rule for httpd firewalld: port=80/tcp permanent=true state=enable immediate=yes// main.ymltasks: - include: tasks/firewall_httpd_default.yml 高级用法，传递参数12345678910111213141516// 添加参数tasks: - include: tasks/firewall.yml port=80 - include: tasks/firewall.yml port=3306// 支持结构化tasks: - include: tasks/firewall.yml vars: wp_user: charlie ssh_key: - key/one.txt - key/two.txt// json格式tasks: - &#123; include: wordpress.yml, wp_user: timmy, ssh_keys: [ &apos;key/one.txt&apos;, &apos;key/two.txt&apos; ] &#125; 在 handlers section 中定义1234567// handlers.yml// this might be in a file line handlers/handlers.yml- name: restart apache service: name = apache state=restarted// 在一个 playbook 中引用 handlers.ymlhandlers: - include: handlers/handlers.yml include 语句可以和其他非 include 的 tasks 和 handlers 混合使用。 例如：12345678910- name: this is a play at the top level of a file host: all remote_user: root tasks: - name: say hi tags: foo shell: echo &quot;Hi &quot;- include: load_balancers.yml- include: webservers.yml- include: dbservers.yml RolesAnsible 中还有一个比 include 更为强大的代码重用机制，那就是roles！。Roles 基于一个已知的文件结构，去自动加载某些 var_files, tasks, handlers，基于 roles 对内容进行分组，更有利于与其他用户分享 roles。Ansible提供了一个分享role的平台, http://galaxy.ansible.com/, 在galaxy上可以找到别人写好的role. Roled的目录结构在 ansible 中，通过遵循特定的目录结构，可以实现对 role 的定义。下面的目录结构是定义了两个 role， 一个名字是 common，另外一个是 webserver，并在 site.yml 中调用这两个 role。12345678910111213141516171819202122232425262728// role 的目录结构site.ymlwebservers.ymlfooservers.ymlroles/ common/ files/ templates/ tasks/ handlers/ vars/ defaults/ meta/ webservers/ files/ templates/ tasks/ handlers/ vars/ defaults/ meta/// site.yml 中使用---- hosts: webservers roles: - common - webservers 使用带参数的 role12345678910111213141516---- hosts: webservers roles: - common - &#123; role: foo_app_instance, dir: &apos;/opt/a&apos;, port: 5000 &#125; - &#123; role: foo_app_instance, dir: &apos;/opt/b&apos;, port: 5001 &#125;// 设置触发条件,条件语句应用到 role 中的每个 task上。---- hosts: webservers roles: - &#123; role: some_role, when: &quot;ansible_os_family == &apos;RedHat&apos;&quot; &#125;// 分配 tags---- hosts: webservers roles: - &#123; role: foo, tags: [ &quot;bar&quot; , &quot;baz&quot; ] &#125; 指定默认的参数在指定默认参数后，如果在调用时传参数，那么就使用传入的参数值，否则使用默认参数。12345678910//指定默认参数main.ymlroles: role_with_var tasks: main.yml vars: main.yml// roles/role_with_var/vars/main.ymlparam: &quot;I am the default value&quot; 与条件语句一起执行12345//定义只有在 RedHat 系列才执行的 role---- host: webservers roles: - &#123; role: some_role, when: &quot;ansible_os_family == &apos;RedHat&apos;&quot; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ansible--变量使用]]></title>
      <url>http://czero000.github.io/2016/10/19/ansible-variable.html</url>
      <content type="text"><![CDATA[变量自动化技术使得重复做事变的更加容易，当系统有所不同，Ansible 可以是使用相同的 template，通过变量来处理不同系统。Ansible 的变量名称可以以 字母、数字和下划线 命名，变量开头要以 字母开头 在 inventory 中定义变量 可以参考 「Ansible–入门」 inventory 章节介绍 在 playbook 中定义变量 123- hosts: web vars: http_port: 80 使用变量在 template 语言 jinjia2 的语法引用，利用中括号和点号来访问子属性12foo[&apos;field1&apos;]foo.field2 在 playbook 中使用变量在 playbook 中使用，需要用两个大括号引用即可 1234567---- hosts: webservers vars: apache_config: labs.conf tasks: - name: deploy haproxy config template: src=&#123;&#123; apache_config &#125;&#125; dest=/etc/httpd/conf.d/&#123;&#123; apache_config &#125;&#125; 在 playbook 中使用变量文件定义变量1234567---- hosts: webservers vars_files: - vars/server_vars.yml tasks: - name: deploy haproxy config template: src=&#123;&#123; apache_config &#125;&#125; dest=/etc/httpd/conf.d/&#123;&#123; apache_config &#125;&#125; 变量文件 vars/server_vars.yml 内容1apache_config: labs.conf YAML 陷阱YAML 语法要求如果值以 开头，需要讲整行用双引号扩起来，为了确保你不是在声明一个字典。12345678910// 错误---- hosts: app_servers vars: app_path: &#123;&#123; base_path &#125;&#125;/22// 正确---- hosts: app_servers vars: app_path: &quot;&#123;&#123; base_path &#125;&#125;/22&quot; 使用 Facts 获取主机系统变量Ansible 可以通过 module_setup 收集远程主机的系统信息–facts，通过 facts 收集的信息，可以以变量形式来使用。1ansible all -m setup 在 playbook 中使用 facts 变量命令会返回海量的变量数据，这些变量可以在 playbook 中直接使用12345678910111213---- hosts: all name: install some package user: root tasks: - name: echo system shell: echo &#123;&#123; ansible_os_family &#125;&#125; - name: install Git on RedHat yum: name=git state=present when: ansible_os_family == &quot;RedHat&quot; - name: install Git on Debian apt: name=git state=installed when: ansible_os_family == &quot;Debian&quot; 使用复杂的 facts 变量使用通过 fact 收集到复杂的、多层次的变量。1234567891011121314151617181920212223&quot;ansible_eth1&quot;: &#123; &quot;active&quot;: true, &quot;device&quot;: &quot;eth1&quot;, &quot;ipv4&quot;: &#123; &quot;address&quot;: &quot;172.16.11.210&quot;, &quot;broadcast&quot;: &quot;172.16.11.255&quot;, &quot;netmask&quot;: &quot;255.255.255.0&quot;, &quot;network&quot;: &quot;172.16.11.0&quot; &#125;, &quot;ipv6&quot;: [ &#123; &quot;address&quot;: &quot;fe80::5054:ff:fec0:b2b3&quot;, &quot;prefix&quot;: &quot;64&quot;, &quot;scope&quot;: &quot;link&quot; &#125; ], &quot;macaddress&quot;: &quot;52:54:00:c0:b2:b3&quot;, &quot;module&quot;: &quot;virtio_net&quot;, &quot;mtu&quot;: 1500, &quot;pciid&quot;: &quot;virtio1&quot;, &quot;promisc&quot;: false, &quot;type&quot;: &quot;ether&quot; &#125;, 可以通过下面两种方式访问到复杂变量的自变量 1234// 中括号&#123;&#123; ansible_eth1[&quot;ipv4&quot;][&quot;address&quot;] &#125;&#125;// 点号&#123;&#123; ansible_eth1.ipv4.address &#125;&#125; 关闭facts在 playbook 中， 可以设置是否启用 gather_facts 来获取远程系统信息123---- hosts: webservers gather_facts: no 使用被控端自定义变量在被控端可以在 /etc/ansible/facts.d 目录中，任何以 .fact 结尾的文件都可以在 Ansible 提供局部 facts。12345678910111213141516171819//定义 /etc/ansible/facts.d/perferences.fact 文件[general]abcd=1bcde=2// 主控端获取变量172.16.11.210 | SUCCESS =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_local&quot;: &#123; &quot;perferences&quot;: &#123; &quot;general&quot;: &#123; &quot;abcd&quot;: &quot;1&quot;, &quot;bcde&quot;: &quot;2&quot; &#125; &#125; &#125; &#125;, &quot;changed&quot;: false&#125; 这样就可以在 playbook 中引用变量或者覆盖掉系统的 facts 值12345678910---- hosts: all user: root tasks: - name: create directory for ansible custom facts file: state=directory recurse=yes path=/etc/ansible/facts.d/ - name: install custom ipmi fact copy: src=/opt/ansible/playbooks/ipmi.fact dest=/etc/ansible/facts.d - name: re-read facts after adding custom fact setup: filter=ansible_local 注册变量可以把 tasks 运行结果作为变量，供后面的 action 使用，在运行 playbook 时，可以使用 -v 参数看到结果值，123456789---- hosts: webservers tasks: - shell: /bin/ls register: result ignore_errors: true - shell: /bin/echo &quot;&#123;&#123; result.stdout &#125;&#125;&quot; when: result.rc == 5 - debug: msg=&quot;&#123;&#123; result.stdout &#125;&#125;&quot; 在文件模板中使用变量Ansible 使用的模本是 python 的一个 jinja2 模板。在 playbook 中定义的变量，可以直接在 template 中使用。 template 变量的定义123456789101112131415161718192021222324252627// 使用template module来拷贝文件 index.html.j2，并替换 index.html.j2 中的变量为 playbook 中定义的变量。---- hosts: web vars: http_port: 80 defined_name: &quot;Hello My name is Charlie&quot; remote_user: root tasks: - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: Write the configuration file template: src=templates/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: - restart apache - name: Write the default index.html file template: src=templates/index2.html.j2 dest=/var/www/html/index.html - name: ensure apache is running service: name=httpd state=started - name: insert firewalld rule for httpd firewalld: port=&#123;&#123; http_port &#125;&#125;/tcp permanent=true state=enabled immediate=yes handlers: - name: restart apache service: name=httpd state=restarted template 变量的使用在 template index.html.j2 中可以直接使用系统变量和用户自定义的变量 系统变量 , 用户自定义变量： 命令行中传递变量在执行 playbook 命令时可以通过 vars_prompt 和 vars_files 传递变量 12345678910111213---- hosts: &apos;&#123;&#123; hosts &#125;&#125;&apos; remote_user: &apos;&#123;&#123; user &#125;&#125;&apos; tasks: - ....// 在命令行中传递参数ansible-playbook release.yml --extra-vars &quot;hosts=webservers user=web&quot;// 使用 JSON 格式传递参数ansible-playbook release.yml --extra-vars &quot;&#123;&apos;hosts&apos;:&apos;webservers&apos;, &apos;user&apos;:&apos;web&apos;&#125;&quot;// 通过文件传递参数ansible-playbook release.yml --extra-vars &quot;@vars.json&quot;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ansible--高级技巧]]></title>
      <url>http://czero000.github.io/2016/10/19/the-advanced-ansible.html</url>
      <content type="text"><![CDATA[Ansible 性能优化在使用 Ansible 过程中，当管理的服务器数量增加，就会有一个无法避免的问题–执行效率慢。下面是一些解决方法 优化前的准备–收集数据在做性能优化之前首先要收集一些统计数据，这样才能为后面的性能优化提供数据支持，对比优化前后结果，这里推荐一个 Ansible 任务计时插件 ansible-profile， 安装这个插件之后， 会显示 ansible-playbook 执行每个任务话费的时间。项目地址: http://github.com/jlafon/ansible-profile 。12345mkdir callback_pluginscd callback_pluginswget http://raw.githubusercontent.com/jlafon/ansible-profile/master/callback_plugins/profile_tasks.pyedit /etc/ansible/ansible.cfg#callback_whitelist = timer, mail =&gt; callback_whitelist = profile_tasks 先在执行 ansible-playbook 既可以看到每个 tasks 的用时情况。12345678PLAY RECAP *********************************************************************172.16.11.210 : ok=2 changed=0 unreachable=0 failed=0 172.16.11.211 : ok=2 changed=0 unreachable=0 failed=0 Sunday 18 September 2016 16:03:26 +0800 (0:00:00.204) 0:00:07.061 ******===============================================================================setup ------------------------------------------------------------------- 6.82sprint phone records ----------------------------------------------------- 0.20s 关闭 gathering facts在执行 ansible-playbook 的过程中，ansible-playbook 第一步骤总是执行 gather_facts，不论你是否在 playbook 中定义这个 tasks。如果执行 playbook 不需要 fact 的数据，可以关闭 fact 数据功能，以加快 ansible-playbook 的执行速度。12345// 在 playbook 中关闭 facts,只需要添加 `gather_facts: no`---- hosts: 172.16..11.210 gather_facts: no remote_user: root 关闭执行继续执行上面的 playbook,效果十分明显1234567PLAY RECAP *********************************************************************172.16.11.210 : ok=1 changed=0 unreachable=0 failed=0 172.16.11.211 : ok=1 changed=0 unreachable=0 failed=0 Sunday 18 September 2016 16:12:05 +0800 (0:00:00.195) 0:00:00.235 ******===============================================================================print phone records ----------------------------------------------------- 0.20s SSH PIPElinINGSSH PIPElinING 是一个加速 Ansible 执行速度的简单方法。SSH PIPElinING 默认是关闭的，因为要兼容不同的 sudo 配置，主要是 requiretty 选项。如果不适用 sudo 建议开启。打开此选项可以减少 ansible 执行没有传输时 ssh 在被控机器上执行任务的连接数，如果使用 sudo，必须关闭 requiretty 选项， 修改 /etc/ansible/ansible.cfg 开启 pipelineing1pipelining=False =&gt; pipelining=True ControlPersistControlPersist 特性需要高版本的 SSH 才支持，CentOS 6 默认是不支持的，如果需要使用，需要自行升级 openssh。ControlPersist 即持久化 socket，一次验证，多次通信。并且只需要修改 ssh 客户端就行，也就是 Ansible 机器即可。升级 openssh 的过程这里不做介绍。这里只介绍下 ControlPersist 设置的办法。12345678cat ~/.ssh/config Host * Compression yes ServerAliveInterval 60 ServerAliveCountMax 5 ControlMaster auto ControlPath ~/.ssh/sockets/%r@%h-%p ControlPersist 4h 在开启了 ControlPersist 特性后，SSH 在建立了 sockets 之后，节省了每次验证和创建的时间。在网络状况不是特别理想，尤其是跨互联网的情况下，所带来的性能提升是非常可观的。有这边需求的，试试就知道了。 ansible-playbook 技巧获取命令行输出在使用 ansible-playbook 中，当使用 common 或者 shell 模块执行自定义脚本，这些脚本都会有输出，用来表示执行正常或者是失败，在 ansible-playbook 中， 可以使用 register 来存储执行命令输出结果，将结果保存到变量中，在通过访问这个变量来获取输出结果。1234567891011121314--- - hosts: all gather_facts: no tasks: - name: echo date command: date register: date_output - name: echo data_output command: echo 30 notify: Hello when: date_output.stdout.split(&apos; &apos;)[2] == &quot;18&quot; handlers: - name: Hello debug: msg=&quot;Hello&quot; delegate_to 任务委派当要在 A 组服务器上执行 playbook 时，需要同时在另外一个不在 A 组的 B 服务器上执行另外操作，这里就可以使用 delegate_to 功能，用来委派任务给 B 服务器。123456tasks: - name: add host records shell: &apos;echo &quot;172.16.11.1 api.abc.com&quot; &gt;&gt; /etc/hosts&apos; - name: add hosts records to center Server shell: ‘echo &quot;172.16.11.1 api.abc.com&quot; &gt;&gt; /etc/hosts’ delegate_to: 172.16.11.211 本地操作功能ansible 默认只会对定义好的被控机执行命令，如果要在本地也执行操作，可以使用 delegate_to 功能，当然还有另外一种更好的方式：local_action1234567// local_action- name: add host record to center server local_action: shell &apos;echo &quot;192.168.1.100 test.xyz.com &quot; &gt;&gt; /etc/hosts&apos;// 当然您也可以使用 connection:local- name: add host record to center server shell: &apos;echo &quot;192.168.1.100 test.xyz.com &quot; &gt;&gt; /etc/hosts&apos; check 模式使用 check 参数运行 ansible-playbook时，不会对远端主机做任何操作，并带有检测功能，报告 playbook 会对主机做出什么操作。如果 playbook 中带有执行条件，检查就会出错了。 使用 tag 来选择性执行可能由于某些原因， 在一个大型的 playbook 中，只想执行其中的特定部分，这样就会用到 tag 功能。123456789101112- name: yun install package yum: name=&#123;&#123; item &#125;&#125; state=installed with_items: - httpd - memcached tags: - packages- name: configuration modity template: src=templates/src.j2 dest=/etc/foo.conf tags: - configuration 如果你只想运行 playbook 中的 configuration 和 packages，你可以这样做1ansible-playbook example.yml -tags “configuration,packages” 错误处理ansible 默认会检查命令和模块的返回状态，并进行相应的错误处理，默认遇到错误就会中断执行 playbook，当然这些是可以更改的 忽略错误 common 和 shell 模块执行的命令如果返回非零的状态码则 ansible 判断模块执行失败，通过 ignore_errors 忽略返回码123- name: this will not be counted as a filure command: /bin/false ignore_errors: true 自定义错误判定条件 命令不依赖返回状态码来判定是否执行失败，而是要查看命令返回内容来决定，比如返回内容中包括 failed 字符串，则判定为失败。示例如下：1234- name: this command prints FAILED when it fails command: /usr/bin/example-command -x -y -z register: command_result failed_when: &quot;&apos;FAILED&apos; in command_result.stderr&quot; ansible 会自动判断模块执行状态，command、shell 及其它模块如果修改了远程主机状态则被判定为 change 状态，不过也可以自己决定达到 changed 状态的条件，示例如下：1234567- name: copy in nginx conf template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf- name: validate nginx conf shell: &quot;/data/app/nginx/sbin/nginx -t&quot; register: command_result changed_when: command_result.stdout.find(&apos;successful&apos;) 命令返回中有“successful”字符串，则为 changed 状态，下面这个设定将永远也不会达到 changed 状态。123- name: validate nginx conf shell: &quot;/data/app/nginx/sbin/nginx -t&quot; changed_when: false]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ansible--循环]]></title>
      <url>http://czero000.github.io/2016/10/19/ansible-loop.html</url>
      <content type="text"><![CDATA[循环Ansible的循环也与编程语言中的类似，循环可以帮你重复做一件事，直到它收到某一个特定结果。 标准循环 简写重复的任务 12345- name: add server users user: name=&#123;&#123; item &#125;&#125; state=present group=wheel with_items: - testuser1 - testuser2 变量中使用 YAML 列表123456789101112131415// 在变量中使用 YAML 列表with_itm_items: &quot;&#123;&#123; somelist &#125;&#125;&quot;// 等同于- name: add_user testuser1 user: name=testuser1 state=present group=wheel- name: add_user testuser2 user: name=testuser2 state=present group=wheel// 支持哈希列表- name: add serveral user user: name=&#123;&#123; item.name &#125;&#125; state=present groups=&#123;&#123; item.groups &#125;&#125; with_itm_items: - &#123; name: &apos;testuser1&apos;, groups: &apos;wheel&apos; &#125; - &#123; name: &apos;testuser2&apos;, groups: &apos;root&apos;&#125; 嵌套循环12345- name: give users access to multiple databases mysql_user: name=&#123;&#123; item[0] &#125;&#125; priv=&#123;&#123; item[1] &#125;&#125;.*:ALL append_privs=yes password=foo with_nested: - [ &apos;alice&apos;, &apos;bob&apos;] - [ &apos;clientdb&apos;, &apos;employeedb&apos;, &apos;providerdb&apos;] 或者12345- name: here. &apos;users&apos; contains the above list of employees mysql_user: name=&#123;&#123; itme[0] &#125;&#125; priv=&#123;&#123; item[1] &#125;&#125;.*:ALL append_privs=yes password=foo with_nested: - &quot;&#123;&#123;users&#125;&#125;&quot; - [ &apos;clientdb&apos;, &apos;employeedb&apos;, &apos;providerdb&apos; ] 对哈希表使用循环使用 with_dict 来循环哈希表中的元素,下面打印用户名和电话号码1234567891011121314---- hosts: all vars: users: alice: name: Alice Appleworth telephone: 123-456-789 bob: name: Bob Bananarama telephone: 987-654-321 tasks: - name: print phone records debug: msg=&quot;User &#123;&#123; item.key &#125;&#125; is &#123;&#123; item.value.name &#125;&#125; (&#123;&#123; item.value.telephone &#125;&#125;]&quot; with_dict: &quot;&#123;&#123;users&#125;&#125;&quot; 对文件列表使用循环使用 with_fileglob 可以以非递归的方式来匹配单个目录的文件123456789---- hosts: all tasks: # first ensure out target directory exists - file: dest=/tmp/fooapp state=directory # copy each file over that matches the given pattern - copy: src=&#123;&#123; item &#125;&#125; dest=/tmp/fooapp/ owner=root mode=600 with_fileglob: - /opt/ansible/playbooks/fooapp/* 对并行数据使用循环123456789// 变量alpha: [&apos;a&apos;, &apos;b&apos;, &apos;c&apos; &apos;d&apos; ]numbers: [ 1, 2, 3, 4 ]// 得到 &apos;(a,1)&apos; 和 ‘(b,2)’,可以使用`with_together`tasks: - debug: msg=&quot;&#123;&#123; item.0 &#125;&#125; and &#123;&#123; item.1 &#125;&#125;&quot; with_together: - &quot;&#123;&#123; alpha &#125;&#125;&quot; - &quot;&#123;&#123; numbers &#125;&#125;&quot; 对子元素使用循环1234567891011121314151617181920212223242526272829--- - name: create user hosts: all vars: users: - name: alice authorized: - /tmp/alice/onekey.pub - /tmp/alice/twokey.pub mysql: password: mysql-password hosts: - &quot;%&quot; - &quot;127.0.0.1&quot; - &quot;::1&quot; - &quot;localhost&quot; privs: - &quot;*.*:SELECT&quot; - &quot;DB1.*:ALL&quot; - name: bob authrized: - /tmp/bob/id_rsa.pub mysql: password: other-mysql-password hosts: - &quot;db1&quot; privs: - &quot;*.*:SELECT&quot; - &quot;DB2.*:ALL&quot; 对子元素使用循环1234567- user: name=&#123;&#123; item.name &#125;&#125; state=present generate_ssh_key=yes with_items: &quot;&#123;&#123;users&#125;&#125;&quot;- authorized_key: &quot;user=&#123;&#123; item.0.name &#125;&#125; key=&apos;&#123;&#123; lookup(&apos;file&apos;, item.1) &#125;&#125;&apos;&quot; with_subelements: - users - authorized 根据mysql hosts以及预先给定的privs subkey列表,我们也可以在嵌套的subkey中迭代列表12345- name: Setup MySQL users mysql_user: name=&#123;&#123; item.0.user &#125;&#125; password=&#123;&#123; item.0.mysql.password &#125;&#125; host=&#123;&#123; item.1 &#125;&#125; priv=&#123;&#123; item.0.mysql.privs | join(&apos;/&apos;) &#125;&#125; with_subelements: - users - mysql.hosts 对整数数组使用循环with-sequence 可以以升序拍了生成一组序列，可以指定起始、终止及步长123456789101112131415161718192021---- hosts: all tasks: # create groups - group: name=evens state=present - group: name=odds state=present # create some test users - user: name=&#123;&#123; item &#125;&#125; state=present groups=evens with_sequence: start=0 end=32 format=testuser%02x # create a series of directories with even numbers for some reason - file: dest=/var/stuff/&#123;&#123; item &#125;&#125; state=directory with_sequence: start=4 end=16 stride=2 # a simpler way to use the sequence plugin # create 4 groups - group: name=group&#123;&#123; item &#125;&#125; state=present with_sequence: count=4 随机选择random_choice 可以随机获取值123456- debug: msg=&#123;&#123; item &#125;&#125; with_random_choice: - &quot;go through the door&quot; - &quot;drink from the goblet&quot; - &quot;press the red button&quot; - &quot;do nothing&quot; Do-Until 循环12345- action: shell /usr/bin/foo register: result until: result.stdout.find(&quot;all systems go&quot;) != -1 retries: 5 delay: 10 直到结果的stdout输出包含all systems go 或者经过重复 5 次任务 查找匹配文件12345- name: INTERFACES | Create Ansible header for /etc/network/interfaces template: src=&#123;&#123; item &#125;&#125; dest=/etc/foo.conf with_first_found: - &quot;&#123;&#123;ansible_virtualization_type&#125;&#125;_foo.conf&quot; - &quot;default_foo.conf&quot; 可以用于搜索路径123456789101112- name: some configuration template template: src=&#123;&#123; item &#125;&#125; dest=/etc/file.cfg mode=0444 owner=root group=root with_first_found: - files: - &quot;&#123;&#123;inventory_hostname&#125;&#125;/etc/file.cfg&quot; paths: - ../../../templates.overwrites - ../../../templates - files: - etc/file.cfg paths: - templates 迭代执行结果1234567- name: Example of looping over a REMOTE command result shell: /usr/bin/something register: command_result- name: Do something with each result shell: /usr/bin/something_else --param &#123;&#123; item &#125;&#125; with_items: &quot;&#123;&#123;command_result.stdout_lines&#125;&#125;&quot; 循环列表123- name: indexed loop demo debug: msg=&quot;at array position &#123;&#123; item.0 &#125;&#125; there is a value &#123;&#123; item.1 &#125;&#125;&quot; with_indexed_items: &quot;&#123;&#123;some_list&#125;&#125;&quot; 循环配置文件123// 使用 ini 插件- debug: msg=&quot;&#123;&#123;item&#125;&#125;&quot; with_ini: value[1-2] section=section1 file=lookup.ini re=true 在循环中是用注册器12345678910111213141516- hosts: 172.16.11.210 name: test loop register remote_user: root tasks: - name: test loop register shell: /bin/echo &quot;&#123;&#123; item &#125;&#125;&quot; with_items: - Hello - World register: echo_result #- debug: msg=&quot;&#123;&#123; echo_result.results &#125;&#125;&quot; - name: Fail if return code is not 0 debug: msg=&quot;The command (&#123;&#123; item.cmd &#125;&#125;) did not have a 0 return code.&quot; when: item.rc != 0 with_items: &quot;&#123;&#123; echo_result.results &#125;&#125;&quot;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ansible-入门]]></title>
      <url>http://czero000.github.io/2016/10/19/rudiments-of-nsible.html</url>
      <content type="text"><![CDATA[什么是 AnsibleAnsible 是基于 python 的配置管理和应用部署工具。官方给的 title是 “Ansible is Simple IT Automation” —简单的自动化IT工具。 架构图 工作原理 管理端支持 local、 ssh、zeromq 三种方式连接被控端，默认使用 ssh 可以按照一定规则进行 inventory，管理节点通过模块实现对应操作–ad-hoc 管理节点可以通过 playbook 实现对多个 task 的集合实现一类功能 安装 Ansible 源码安装 源码安装需要 python2.6 以上版本，依赖 paramiko， PyYAML， Jinja2， simplejsion、 pycrypto模块，可以通过 pip 来安装1234567891011121314151617181920212223// 获取源码git clone git://github.com/ansible/ansible.git --recursive cd ./ansible// 设置环境变量source ./hacking/env-setupsource ./hacking/env-setup.fishsource ./hacking/env-setup -q// 安装 Python 依赖easy_install pippip install paramiko PyYAML Jinja2 httplib2 six// 更新 Ansiblegit pull --rebasegit submodule update --init --recursive// 设置inventory文件echo &quot;127.0.0.1&quot; &gt; ~/ansible_hostsexport ANSIBLE_HOSTS=~/ansible_hosts// 测试命令ansible all -m ping --ask-pass 常用 Linux 发行版 12345678// CentOS、RHELyum install ansible//Ubuntu、Debiansudo apt-get install software-properties-commonsudo apt-add-repository ppa:ansible/ansiblesudo apt-get updatesudo apt-get install ansible 通过 pip 安装最新版Ansible 可以通过 pip 安装,同时也会安装 paramiko、PyYAML、jinja2 等 Python 依赖库。 12apt install python3-pippip3 install ansible 运行 Ansible添加被控远程主机清单已经安装好了 Ansible ，先在就可以运行 Ansible 了。 首先要在 /etc/ansible/hosts 文件中加入一个或者多个远程 ip 或者 domain。 12172.16.11.210172.16.11.211 配置基于 SSH key 方式 连接1234// 主控端操作ssh-keygen -t rsa -qssh-copy-id 172.16.11.210ssh-copy-id 172.16.11.211 运行 Ansible123456789ansible all -m ping172.16.11.210 | SUCCESS =&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;172.16.11.211 | SUCCESS =&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125; 配置 inventoryAnsible 可以同时操纵属于一个组的多台主机，主机和组的关系是通过 inventory 文件来配置即/etc/ansible/hosts。inventory可以通过 IP、Domain 来指定，未分组的机器要保留在 host 文件顶部，通过[] 来配置分组信息。 主机与组12345678910111213141516171819// 简单分组[web1]web210.example.comweb211.example.com// 配置端口号[web2]172.16.11.210:8000172.16.11.211:8000// 定义别名和端口[web]www ansible_ssh_port=1234 ansible_ssh_host=172.16.11.211 ansible_ssh_pass=passwd \\ 远程ip，ssh登陆用户、密码other1 ansible_connertion=ssh ansible_ssh_user = illlusion//执行主机，支持正则表达[web_www]www[01:10].example.comdb-[a:f].erample.com 变量12345678910111213141516171819202122232425262728293031323334// 主机变量，分配变量给主机，这些变量可以在之后的 playbook 中使用[web-www]www-a http_port=89 maxRequestsPerChild=808www-a http_port=303 maxRequestsPerChild=909//组的变量，组也可以赋予变量，这样组成员将继承组变量[web-www]www-a http_port=89 maxRequestsPerChild=808www-a http_port=303 maxRequestsPerChild=909[web-www:vars]ntp_server=ntp.example.comproxy=proxy.example.com// 组嵌套 可以把组作为另外一个组的子成员，已经分配变量给整个组使用。这些变量可以给 `/usr/bin/ansible-playbook` 使用，但是不能给 `/usr/bin/ansible` 使用[group1]host1host2[group2]host3host4[group3:children]group1group2[group3:vars]some_server=foo.example.comhalon_system_timeout=30self_destruct_countdown=60escape_pods=2 分文件定义 Host 和 group 变量在 inventory 文件中保存的所有变量并不是最佳方式，还可以保存在独立的文件中， 这些文件与 inventory 关联，要求使用 YAML语法。host 和 gourp 变量 要求存储在与 host 和 group 相同的目录名中12345678//假设有一个 host 为 foosball 主机，属于两个组，一个是 raleigh,另外一个是 webserver/etc/ansible/group_vars/raleigh/etc/ansible/group_vars/webservers/etc/ansible/host_vars/foosball// raleigh 组的变量ntp_server: acme.example.orgdatabase_server: storage.example.org 还可以在组变量目录下创建多个文件，设置不同类型的变量12/etc/ansible/group_vars/raleigh/db_settings/etc/ansible/group_vars/raleigh/cluster_settings inventory 参数说明1234567891011121314151617181920212223242526272829// 要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置.ansible_ssh_host// ssh 端口号.如果不使用默认,通过此变量设置.ansible_ssh_port// ssh 用户名ansible_ssh_user// ssh 密码(这种明文方式并不安全,强烈建议使用 --ask-pass 或 SSH 密钥)ansible_ssh_pass// sudo 密码(这种方式并不安全,强烈建议使用 --ask-sudo-pass)ansible_sudo_pass// sudo 命令路径(适用于1.8及以上版本)ansible_sudo_exe (new in version 1.8)// 与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko.1.2 以后默认使用 &apos;smart&apos;,&apos;smart&apos; 方式会根据是否支持 ControlPersist, 来判断&apos;ssh&apos; 方式是否可行.ansible_connection// ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况.ansible_ssh_private_key_file// 目标系统的 shell 类型.默认情况下,命令的执行使用 &apos;sh&apos; 语法,可设置为 &apos;csh&apos; 或 &apos;fish&apos;. ansible_shell_type// 目标主机的 python 路径.适用于的情况: 系统中有多个 Python, 或者命令路径不是&quot;/usr/bin/python&quot;,比如 \*BSD, 或者 /usr/bin/python ansible_python_interpreter Patterns在 ansible 中， patterns 是指如何确定有那些主机或组被管理，在 playbook 中，它是指对应主机应用特定的配置或执行特定进程。 ansible12345// 语法ansible &lt;pattern_goes_here&gt; -m &lt;module_name&gt; -a &lt;arguments&gt;// 示例ansible webservers -m service -a &quot;name=httpd state=restarted&quot; 简单的说， pattern 是一个主机筛选器，支持正则匹配。 12345678910111213141516// 所有主机all*//特定主机，支持 ip 地址和主机名web211172.16.11.211//主机组，可以指定特定组或多个组，多个组之间使用`:`分隔web_serverweb_server:database_server// 支持正则表达式和逻辑运算web_server:!web211web_server:&amp;db1web_server:database_server:&amp;db1:!web211 playbook在 playbook 中，通过使用 -e参数可以实现通过变量来确定 group 123456789101112131415161718192021webservers:!&#123;&#123;excluded&#125;&#125;:&amp;&#123;&#123;required&#125;&#125;// 通配符*.example.com*.com//通配符和正则同时one*.com:dbservers// 在 patterns 应用正则式时，使用 `~` 开头~(web|db).*\.example\.com// 索引和切片webservers[0]webservers[0-25]// 可以在使用 `--limit` 标记来添加排除条件ansible-playbook site.yml --limit datacenter2// 如果你想从文件读取 hosts,文件名以 @ 为前缀即可.ansible-playbook site.yml --limit @retry_hosts.txt 简单执行命令123456789ansible all -m ping172.16.11.210 | SUCCESS =&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;172.16.11.211 | SUCCESS =&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125; 可用该命令选项： -i：指定 inventory 文件，使用当前目录下的 hosts all：针对 hosts 定义的所有主机执行，这里也可以指定组名或模式 -m：指定所用的模块，我们使用 Ansible 内置的 ping 模块来检查能否正常管理远端机器 -u：指定远端机器的用户 12345678910111213141516171819202122232425262728293031323334353637ansible all -m ping \\ping 所有的节点ansible 127* -m pingansible -i /etc/ansible/hosts -m command -a &quot;uptime&quot; // 指定 pattens 文件ansible all -m ping -u testansible all -m ping -u test --sudoansible all -m ping -u test --sudo --sudo-user tomansible testhost -m setup -a &quot;filter=ansible_all_ipv4_addresses&quot; \\使用 filter 过滤信息 ansible testhosts -a &quot;/sbin/reboot&quot; -f 10 \\重启testhosts组的所有机器，每次重启10台ansible testhosts -m copy -a &quot;src=/etc/hosts dest=/tmp/hosts&quot; \\拷贝本地hosts 文件到testhosts组所有主机的/tmp/hostsansible webservers -m file -a &quot;dest=/srv/foo/a.txt mode=600&quot; \\file 模块允许更改文件的用户及权限ansible webservers -m file -a &quot;dest=/srv/foo/b.txt mode=600 owner=mdehaan group=mdehaan&quot;ansible webservers -m file -a &quot;dest=/path/to/c mode=755 owner=mdehaan group=mdehaan state=directory&quot; \\使用 file 模块创建目录，类似 mkdir -pansible webservers -m file -a &quot;dest=/path/to/c state=absent&quot; \\file 模块允许更改文件的用户及权限 ansible testhosts -a &apos;cal&apos; \\默认是使用 command 模块，所以使用command的命令时不用添加 -mansible webhosts -m command -a &apos;date&apos; \\在 hosts 文件中的 webhosts 组下的所有主机都使用 date 命令ansible webhosts -m command -a &apos;ping&apos; \\在 hosts 文件中的 webhosts 组下的所有主机都使用 date 命令ansible testhosts -m service -a &quot;name=ntpd state=restarted&quot;使用 user 模块对于创建新用户和更改、删除已存在用户非常方便：ansible all -m user -a &quot;name=foo password=&lt;crypted password here&gt;&quot;ansible all -m user -a &quot;name=foo state=absent&quot;// 服务管理：ansible webservers -m service -a &quot;name=httpd state=restarted&quot; \\重启 webservers 组所有主机的 httpd 服务ansible webservers -m service -a &quot;name=httpd state=started&quot; \\确保 webservers 组所有主机的 httpd 是启动的ansible webservers -m service -a &quot;name=httpd state=stopped&quot; \\确保 webservers 组所有主机的 httpd 是关闭的//后台运行，长时间运行的操作可以放到后台执行，ansible 会检查任务的状态；在主机上执行的同一个任务会分配同一个 job IDansible all -B 3600 -a &quot;/usr/bin/long_running_operation --do-stuff&quot; \\后台执行命令 3600s，-B 表示后台执行的时间ansible all -m async_status -a &quot;jid=123456789&quot; \\检查任务的状态ansible all -B 1800 -P 60 -a &quot;/usr/bin/long_running_operation --do-stuff&quot; \\后台执行命令最大时间是 1800s 即 30 分钟，-P 每 60s 检查下状态默认 15s// 搜集系统信息ansible all -m setup \\搜集主机的所有系统信息ansible all -m setup --tree /tmp/facts \\搜集系统信息并以主机名为文件名分别保存在 /tmp/facts 目录ansible all -m setup -a &apos;filter=ansible_*_mb&apos; \\搜集和内存相关的信息ansible all -m setup -a &apos;filter=ansible_eth[0-2]&apos; \\搜集网卡信息 Ad-Hoc执行 Ad-Hoc 跟在 Linux 执行命令差不多， 用来快速完成简单的任务。 语法1ansible [host or group] -m [module_name] -a [commond] [ ansible-options ] 实例 执行安装程序， 安装 python-simplejson 1ansible all -m raw -a &apos;yum -y install python-simplejson&apos; 重启 web 服务假如 web_server 是一个组， 这里组里面有很多webserver，先在需要在 web_server 组上的左右机器执行 reboot 命令， -f 参数会 fork 出 10 个子进程，以并行的方式执行 reboot，即每次重启 10 台 1ansible web_server -a &quot;/sbin/reboot&quot; -f 10 在执行时，默认是以当前用户身份去执行该命令，如果需要执行执行用户，添加 -u username，或者需要使用 sudo 去执行,添加 -u username --sudo [--ask-sudo-pass]。如果不是以 passwordless 的模式执行 sudo,应加上 –ask-sudo-pass (-K)选项,加上之后会提示你输入 密码.使用 passwordless 模式的 sudo, 更容易实现自动化,但不要求一定要使用 passwordless sudo. 文件传输 ansible 的另外一种用法就是可以以并行的方式同时 scp 大量的文件到多台主机。 1ansible all -m copy -a &quot;src=/opt/ansible/test.txt dest=/opt/ansible/test.txt&quot; 如果是用 playbook，择可以利用 template 模块来实现更高级操作。 使用 file 模块 可以修改文件的属主和权限1ansible all -m file -a &apos;dest=/opt/ansible/test.txt mode=600 owner=nobody group=nobody&apos; 使用 file 模块还可以创建、删除目录和文件12345// 创建目录ansible all -m file -a &apos;dest=/opt/ansible/test mode=755 owner=root group=root state=directory&apos;// 删除目录和文件ansible all -m file -a &apos;dest=/opt/ansible/test state=absent&apos; 更多详见copy模块说明 包管理 ansible 提供了对 yum 和 apt 的支持12345 // 安装软件包 ansible all -m yum -a &apos;name=vim state=present&apos;// 卸载软件包 ansible all -m yum -a &apos;name=vim state=absent&apos; 在不同的发行版的软件包管理软件， ansible 有其对应的模块， 如果没有，你可以使用 command 模块去安装软件。更多详见package模块说明 用户和组管理 12345678// 创建用户ansible all -m user -a &apos;name=charlie password=123456 state=present&apos;// 修改用户， 增加属组和修改shellansible all -m user -a &apos;name=Cc groups=nobody shell=/sbin/nologin state=present&apos;//移除用户ansible all -m user -a &apos;name=Cc state=absent&apos; 更多参数详见user模块说明 服务管理 123456// 启动服务ansible all -m service -a &apos;name=rsyslog state=started&apos;// 重启服务ansible all -m service -a &apos;name=rsyslog state=restarted&apos;// 停止服务ansible all -m service -a &apos;name=rsyslog state=stopped&apos; 系统自身变量获取 ansible 可以通过 setup 模块来获取客户端自身的以便固有信息，叫做 facts12345// 获取所有 facts 变量ansible all -m setup// 通过 filter 获取某一个 fact 变量ansible all -m setup -a &apos;filter=ansible_*mb&apos;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[搭建GitLab服务器]]></title>
      <url>http://czero000.github.io/2016/10/19/build-gitlab.html</url>
      <content type="text"><![CDATA[Gitlab 是一个基于 Ruby on Rails 开发的开源项目管理程序，可以通过 WEB 界面进行访问公开的或者私人项目，实现一个自托管的 Git 项目仓库。它拥有与 GitHub 类似的功能，可以浏览代码，管理缺陷和注释。 安装依赖软件1apt-get install curl openssh-server ca-certificates postfix 添加 GitLab仓库 ,安装软件包12curl -sS http://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bashapt-get install gitlab-ce 如果不习惯使用命令行管道的安装方式，官方提供了安装脚本 或者 手动下载相应平台及版本的软件包12curl -LJO http://packages.gitlab.com/gitlab/gitlab-ce/packages/ubuntu/xenial/gitlab-ce-XXX.deb/downloaddpkg -i gitlab-ce-XXX.deb 如果访问速度慢，可以使用国内的镜像站如：http://mirror.tuna.tsinghua.edu.cn/help/gitlab-ce/ 启动 GitLab1gitlab-cli reconfigure 可以通过 gitlab-clt status 查看 GitLab 安装是否成功12345678gitlab-ctl statusrun: gitlab-workhorse: (pid 17111) 276s; run: log: (pid 17010) 298srun: logrotate: (pid 17034) 294s; run: log: (pid 17033) 294srun: nginx: (pid 17019) 296s; run: log: (pid 17018) 296srun: postgresql: (pid 16863) 383s; run: log: (pid 16862) 383srun: redis: (pid 16776) 389s; run: log: (pid 16775) 389srun: sidekiq: (pid 17001) 300s; run: log: (pid 17000) 300srun: unicorn: (pid 16970) 302s; run: log: (pid 16969) 302s 访问 GitLab访问 http:gitlab_serverip，即可访问 GitLab 的 Web 界面 首次使用要设置密码]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用gitolite管理git授权]]></title>
      <url>http://czero000.github.io/2016/10/19/use-gitolite-manager-git.html</url>
      <content type="text"><![CDATA[使用 gitolite 管理 git 服务器由于Git的设计初衷，在使用 Git 在面向团队服务时，如果需要对权限控制，就需要第三方的工具来帮助 Git。在 Git 管理工具中，有三个解决方案。 Gitosis 轻量级、开源项目，使用 SSH 公钥认证，只能做到库级别的权限控制。现在项目已经停止开发，不在维护； Gitolite 轻量级、开源项目，使用 SSH 公钥认证，可以做到对分支级的权限控制； [Git + Repo + Gerrit] 重量级，集版本控制、库管理和代码审核。可以用来管理大型项目 由于 gitosis 不在提供更新，新建项目使用 gitolite 配置 git 的访问控制。 安装 GitoliteGitolite 的安装步骤如下如： 系统环境系统采用最新的 Ubuntu-16-04 LTS 角色 ip gitolite_gitServer 172.16.11.210 git_client 172.16.11.211 git_client 172.16.8.247 创建管理用户1234adduser --system --shell /bin/bash --group --gecos &apos;Git SCM User&apos;--disabled-password --home /home/gitolite gitolitesu - gitolitessh-keygen -t rsa -qcp ~/.ssh/id_rsa.pub /tmp/gitolite.pub 软件安装12345678// apt 安装sudo apt install git-core gitolite3// git clonegit clone git://github.com/sitaramc/gitolitemkdir ~/bingitolite/install -ln ~/bin~/bin/gitolite setup -pk /tmp/gitolite.pub 配置授权配置管理库1234567// 执行命令之后，会在家目录中创建 `gitolite-admin` 的 git 仓库，可以通过修改这个仓库来管理 Gitolitegit clone gitolite@172.16.11.210:gitolite-admin.git // 配置 gitgit config --global push.default simplegit config --global user.email &quot;charlie.cui127@gmail.com&quot;git config --global user.name &quot;Cc&quot; 在 gitolite 仓库中有两个目录 conf 和 keydir,前者是配置权限的配置文件，后者是用来存放 Client 的 key/ 配置新用户添加新用户很简单。添加一个名为 client1 的用户，获取她的公钥，命名为 client1.pub，然后放到在 gitolite-admin克隆的 keydir 目录。添加，提交，然后推送更改。这样用户就被添加了1234ssh-keygen -t rsa -qscp id_rsa.pub 172.16.11.210:/tmp/client1.pub// ssh-key 都采用这样的命名方式 &lt;yourname&gt;.pubcp /tmp/client1.pub /home/gitolite/gitolite-admin/keydir/client1.pub 定制配置官方示例 123456cat conf/gitolite.confrepo gitolite-admin RW+ = gitoliterepo testing RW+ = @all 用户管理可以给用户或者仓库分组 @代表组，成员之间空格分隔 123@oss_repos = linux perl gitolite@admin = Cc@devops = alice bob charlie 权限分类1234567C: 代表创建，仅用在通配符版本库授权时可以使用，用于指定那个用户可以创建和通配符匹配版本库R: 只读RW: 读写RW+: 除了读写权限，还可以对 rewind 的提交强制 pushRWC、RW+C: 只有当授权指令中定义了正则引用（正则表达式定义的分支、里程碑等），才可以使用该授权指令。其中 C 的含义是允许创建和正则引用匹配的引用（分支或里程碑等）。RWD, RW+D: 只有当授权指令中定义了正则引用（正则表达式定义的分支、里程碑等），才可以使用该授权指令。其中 D 的含义是允许删除和正则引用匹配的引用（分支或里程碑等）。RWCD, RW+CD: 只有当授权指令中定义了正则引用（正则表达式定义的分支、里程碑等），才可以使用该授权指令。其中 C 的含义是允许创建和正则引用匹配的引用（分支或里程碑等），D 的含义是允许删除和正则引用匹配的引用（分支或里程碑等）。 拒绝访问1234还有一种权限是 `-`表示拒绝， 拒绝RW master integ = @engineers- master integ = @engineersRW+ = @engineers 限制文件123repo foo RW = @devops - VERF/Makefile = @devops 提交变更1234// 使用 gitlite 用户git add .git commit -m &apos;xxx&apos;git push 新增项目123456789git init mytestcd mytest/echo &quot;is test.&quot; &gt; m.txtgit add .git commit -am &apos;abc&apos;git remote add origin ssh://gitolite@localhost/mytest.gitgit push origin mastergit remote show origingit push --set-upstream origin master]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[awk思维导图]]></title>
      <url>http://czero000.github.io/2016/07/30/awk-mindmap.html</url>
      <content type="text"><![CDATA[awk 思维导图]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Bash思维导图]]></title>
      <url>http://czero000.github.io/2016/07/26/bash-mindmap.html</url>
      <content type="text"><![CDATA[Bash 思维导图]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用zsh作为默认shell]]></title>
      <url>http://czero000.github.io/2016/07/22/bash-change-to-zsh.html</url>
      <content type="text"><![CDATA[号称终极 Shell 的 Zsh 兼容 Bash，在命令补全方面有很好的体验，丰富的插件和主题可提供使用，配合 Oh-my-zsh 更加强大。 Linux 系统一般预装几种 Shell，系统默认的 Shell 是 Bash，安装前可以查看系统安装了哪些 Shell 1cat /etc/shells 安装 Debian/Ubuntu 12sudo apt-get updatesudo apt-get install zsh Redhat/CentOS 12yum updateyum install zsh 安装完成后将 Zsh 替换 Bash 作为默认的 Shell，避免每次重启需要重新进入 Zsh 1chsh -s /bin/zsh 安装 Oh-my-zsh需要使用到 Git，安装方法同上 下面通过自动安装的方式安装 Oh-my-zsh 1sh -c &quot;$(wget http://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot; 或者使用 123git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zshcp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc 安装完成用户目录下会出现 .zshrc 文件，环境变量和别名都在这里定义，更改主题需要修改 123ZSH_THEME=”robbyrussell”这里改为一个比较受欢迎的一款主题ZSH_THEME=&quot;agnoster&quot; oh my zsh 提供了数十种主题，相关文件在~/.oh-my-zsh/themes目录下，你可以随意选择，也可以编辑主题满足自己的变态需求，我采用了默认主题robbyrussell，但是做了一点小小的改动 123PROMPT=&apos;%&#123;$fg_bold[red]%&#125;➜ %&#123;$fg_bold[green]%&#125;%p%&#123;$fg[cyan]%&#125;%d %&#123;$fg_bold[blue]%&#125;$(git_prompt_info)%&#123;$fg_bold[blue]%&#125;% %&#123;$reset_color%&#125;&gt;&apos;#PROMPT=&apos;%&#123;$fg_bold[red]%&#125;➜ %&#123;$fg_bold[green]%&#125;%p %&#123;$fg[cyan]%&#125;%c %&#123;$fg_bold[blue]%&#125;$(git_prompt_info)%&#123;$fg_bold[blue]%&#125; % %&#123;$reset_color%&#125;&apos; 插件在这项配置项里添加需要的插件即可1plugins=(git bundler osx rake ruby) Zsh 的基本配置到这里结束，强大的 Zsh 还有更多功能可以发现。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[开源MySQL自动补全客户端]]></title>
      <url>http://czero000.github.io/2016/05/31/autocompletion-of-opensource-mysqlclient.html</url>
      <content type="text"><![CDATA[介绍MyCli 是一个 MySQL 的命令行客户端，可以实现自动补全 auto-completion 和语法高亮，同时也可应用于 MariaDB 和 Percona。 功能特征 MyCli 使用 Python Prompt Toolkit 编写。 支持语法高亮 当你输入 SQL 关键字，数据库的表格和列时可自动补全。 智能补全(默认启用)，会提示文本感应的 context-sensitive 补全。 配置文件在第一次启动时，自动创建在 ~/.myclirc 安装 兼容性：OS X 和 Linux 上测试过。运行在 Python 2.6、2.7、3.3、3.4、3.5。能够很好地处理 unicode 输入/输出。 Python Package 1$ pip install myclior$ easy_install mycli Mac OS X 最简单的方法在 OS X 机器安装 mycli 是使用 homebrew 1$ brew update &amp;&amp; brew install mycli Linux Debian/Ubuntu Packagemycli托管在debian软件包packagecloud.io.添加gpg密钥packagecloud包验证。 1$ curl http://packagecloud.io/gpg.key | apt-key add - 安装 apt-transport-https 包，支持 apt 使用 https 下载包 1$ apt-get install -y apt-transport-https 添加 mycli 安装源 1$ echo &quot;deb http://packagecloud.io/amjith/mycli/ubuntu/ trusty main&quot; | sudo tee -a /etc/apt/sources.list 更新 mycli 的安装源，然后安装 mycli 12$ sudo apt-get update$ sudo apt-get install mycli 现在使用 sudo apt-get upgrade mycli很容易使 mycli 升级！ RHEL、Centos、Fedora我还没有为 mycli 构建 RPM 包。所以请使用 pip 安装 mycli。你可以在你的系统上安装 pip 使用 1$ sudo yum install python-pip python-devel 一旦安装 pip ,您可以如下安装 mycli: 1$ sudo pip install mycli 效果图： 自动补全简单的完成如关键字和sql函数。 智能提示Table name completions after the ‘FROM’ keyword. 列名中引用的表的查询范围 别名支持列完成将即使工作表名称别名。 语法高亮显示sql 的语法高亮显示。 pager一个 sql 命令的输出是通过更少的命令自动输送。 动态效果图如下]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python自动补全]]></title>
      <url>http://czero000.github.io/2016/05/09/python-auto-completion.html</url>
      <content type="text"><![CDATA[Python 自动补全下面是如何实现PythonTab补全和历史命令管理方法。 Python的startup文件为readline添加tab键自动补全功能，像shell一样管理历史命令 获取python安装目录 123&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.path['', '/usr/lib64/python27.zip', '/usr/lib64/python2.7', '/usr/lib64/python2.7/plat-linux2', '/usr/lib64/python2.7/lib-tk', '/usr/lib64/python2.7/lib-old', '/usr/lib64/python2.7/lib-dynload', '/usr/lib64/python2.7/site-packages', '/usr/lib64/python2.7/site-packages/gtk-2.0', '/usr/lib/python2.7/site-packages'] 安装目录为’/usr/lib64/python2.7’ 切换目录编写startup.py脚本,cp startup.py /usr/lib64/python2.7/ 1234567891011121314151617#!/usr/bin/env python# python startup fileimport sysimport readlineimport rlcompleterimport atexitimport os# tab completionreadline.parse_and_bind('tab: complete')# history filehistfile = os.path.join(os.environ['HOME'], '.pythonhistory')try: readline.read_history_file(histfile)except IOError: passatexit.register(readline.write_history_file, histfile)del os, histfile, readline, rlcompleter 增加环境变量 123456edit .bashrc// 增加下面内容export PYTHONSTARTUP=/usr/lib64/python2.7/startup.py// 变量生效source .bashrc vim增加自动补全 下载插件 pydiction:http://www.vim.org/scripts/script.php?script_id=850 安装插件 123456wget http://www.vim.org/scripts/download_script.php?src_id=21842unzip pydiction-1.2.3.zipcp pydiction/after/ftplugin/python_pydiction.vim /usr/share/vim/vim74/ftplugin/mkdir /usr/share/vim/vim74/pydictioncp pydiction/complete-dict /usr/share/vim/vim74/pydiction/cp pydiction/pydiction.py /usr/share/vim/vim74/pydiction/ 修改vim配置文件 12let g:pydiction_location = &apos;/usr/share/vim/vim74/pydiction/complete-dict&apos;let g:pydiction_menu_height = 20]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Git仓库搭建]]></title>
      <url>http://czero000.github.io/2016/05/09/git-repo.html</url>
      <content type="text"><![CDATA[Github就是一个提供免费托管开源代码的远程仓库，但对于一些敏感代码或者不想开源的源代码，有不舍得付费，那么就需要自己搭建一台Git服务器作为私有仓库来使用。下面是搭建Git服务器过程。 安装配置 安装git 1yum install git -y 创建一个git用户，用来运行git服务 1useradd git 创建证书登录所有需要登录的用户，将他们自己的id_rsa.pub文件及公钥，导入到/home/git/.ssh/authorized_keys文件里，一行一个。 初始化git仓库选当一个目录作为Git仓库，比如/opt/GitWork，在/opt/GitWork目录下创建git仓库 12git init --bare sample.gitInitialized empty Git repository in /opt/GitWork/sample.git/ Git会创建一个裸仓库，仓库没有工作区。 克隆远程仓库 123git clone git@172.16.11.211:/opt/GitWork/sample.gitCloning into &apos;sample&apos;...warning: You appear to have cloned an empty repository. 公钥管理 如果团队很小，把每个人的公钥收集起来放到服务器的/home/git/.ssh/authorized_keys文件里就是可行的。如果团队有几百号人，就没法这么玩了，这时，可以用Gitosis来管理公钥。 权限管理有很多不但视源代码如生命，而且视员工为窃贼的公司，会在版本控制系统里设置一套完善的权限控制，每个人是否有读写权限会精确到每个分支甚至每个目录下。因为Git是为Linux源代码托管而开发的，所以Git也继承了开源社区的精神，不支持权限控制。不过，因为Git支持钩子（hook），所以，可以在服务器端编写一系列脚本来控制提交等操作，达到权限控制的目的。Gitolite就是这个工具。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MooseFS技术详解]]></title>
      <url>http://czero000.github.io/2016/04/27/mfs-Technology.html</url>
      <content type="text"><![CDATA[MFS 概述MooseFS是一款具有冗余容错功能的分布式文件系统。它把数据分散在多台服务器上，确保一份数据多个备份副本，对外提供统一的结构。 功能特性对于标准的文件操作，MooseFS表现与其他类Unix文件系统一致。支持的通过文件系统特性： 层次结构（目录树） 兼容POSIX文件属性 支持特殊文件 符号链接和硬链接 基于IP地址和密码的访问控制 独有特性 高可靠性(数据的多个副本存储在不同服务器) 容量动态扩展（添加新硬盘或者服务器） 可以回收在制定时间内删除的文件，类似回收站功能 可以对整个文件甚至是正在被写入的文件创建文件快照 MFS整体架构的四种角色 Master（元数据服务器）负责各个数据存储服务器的管理，文件读写调度，文件空间回收以及恢复，多节点拷贝。 Metalogger（元数据日志服务器）负责备份Master服务器的changelog。文件类型为changelog.*.mfs，以便在Master出问题时接替其工作 Chunk（数据存储服务器）负责连接Master，听从Master调度，提供存储空间，并为客户端提供数据传输 Client（客户端挂载）通过FUSE内核接口挂载远程管理服务器（master）上所管理的数据存储服务器，使用起来和本地文件系统一样 MFS工作图解 网络架构 工作原理 集群拓扑 安装配置MFS系统环境介绍 OS：CentOS Linux release 7.2.1511 (Core) 软件版本：2.0.81-1 节点配置 ip地址 角色 172.16.18.137 master 172.16.18.134 metalogger 172.16.18.183 chunk 172.16.18.184 chunk 172.16.18.185 chunk 172.16.18.186 chunk 172.16.18.187 chunk chunk上有四块硬盘，第一块为系统，剩下三块作为数据存储，每块容量为4TB 软件安装从官方软件库安装MFS 添加yum key 1curl &quot;http://ppa.moosefs.com/RPM-GPG-KEY-MooseFS&quot; &gt; /etc/pki/rpm-gpg/RPM-GPG-KEY-MooseFS 下载软件库配置文件 123456789//For EL7 family:curl &quot;http://ppa.moosefs.com/MooseFS-stable-el7.repo&quot; &gt; /etc/yum.repos.d/MooseFS.repo//For EL6 family:curl &quot;http://ppa.moosefs.com/MooseFS-stable-el6.repo&quot; &gt; /etc/yum.repos.d/MooseFS.repoFor EL5 family:Due to GPGv4 incompatibility with CentOS 5, CentOS 5 is deprecated.If you really need CentOS 5 packages, please contact support@moosefs.com. 安装软件包 1234567891011// For Master Server:yum install moosefs-master moosefs-cli moosefs-cgi moosefs-cgiserv// For Chunkservers:yum install moosefs-chunkserver//For Metaloggers:yum install moosefs-metaloggerFor Clients://yum install moosefs-client 启动服务 1234567891011//To start process manually:mfsmaster startmfschunkserver start//For systemd OS family - EL7:systemctl start moosefs-master.servicesystemctl start moosefs-chunkserver.service//For SysV OS family - EL6:service moosefs-master startservice moosefs-chunkserver start 从源码安装MFS 下载软件包 1wget http://ppa.moosefs.com/src/moosefs-2.0.88-1.tar.gz 添加用户和组 1useradd -s /sbin/nologin -M mfs 安装软件包 1234567891011tar-zxf moosefs-2.0.88-1.tar.gzcd moosefs-2.0.88// For master./configure --prefix=/usr/local/mfs --with-default-user=mfs --with-default-group=mfs --disable-mfschunkserver --disable-mfsmount// For metalogger./configure --prefix=/usr/local/mfs --with-default-user=mfs --with-default-group=mfs --disable-mfschunkserver --disable-mfsmount// For chunk./configure --prefix=/usr/local/mfs --with-default-user=mfs --with-default-group=mfs --disable-mfsmaster --disable-mfsmount --disable-mfscgi --disable-mfscgiserv 安装MFS client client安装需要fuse支持，fuse可以从源码和仓库中安装 1./configure --prefix=/usr/local/mfs --with-default-user=mfs --with-default-group=mfs --disable-mfsmaster --disable-mfschunkserver --disable-mfscgi --disable-mfscgiserv 配置MFSMaster 配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// mfsmaster.cfg# WORKING_USER = mfs 运行 master server 的用户# WORKING_GROUP = mfs 运行 master server 的组# SYSLOG_IDENT = mfsmaster master server 在 syslog中的标识，说明是由 master serve 产生的# LOCK_MEMORY = 0 是否执行 mlockall()以避免 mfsmaster 进程溢出（默认为 0）# NICE_LEVEL = -19 运行的优先级(如果可以默认是 -19; 注意: 进程必须是用 root启动)# EXPORTS_FILENAME = /usr/local/mfs/etc/mfsexports.cfg 被挂接目录及其权限控制文件的存放位置# TOPOLOGY_FILENAME = /usr/local/mfs/etc/mfs/mfstopology.cfg# DATA_PATH = /usr/local/mfs/var/mfs 数据存放路径，此目录下大致有三类文件，changelog，sessions和 stats；# BACK_LOGS = 50 metadata 的改变 log 文件数目(默认是 50);# BACK_META_KEEP_PREVIOUS = 1# REPLICATIONS_DELAY_INIT = 300 延迟复制的时间（默认是 300s）;# REPLICATIONS_DELAY_DISCONNECT = 3600 chunkserver 断开的复制延迟（默认是 3600）；# MATOML_LISTEN_HOST = * metalogger 监听的 IP 地址(默认是*，代表任何 IP)；# MATOML_LISTEN_PORT = 9419 metalogger 监听的端口地址(默认是 9419)；# MATOML_LOG_PRESERVE_SECONDS = 600# MATOCS_LISTEN_HOST = * 用于 chunkserver 连接的 IP 地址（默认是*，代表任何 IP）；# MATOCS_LISTEN_PORT = 9420 用于 chunkserver 连接的端口地址（默认是 9420）；# MATOCU_LISTEN_HOST = * 用于客户端挂接连接的 IP 地址(默认是*，代表任何 IP)；# MATOCU_LISTEN_PORT = 9421 用于客户端挂接连接的端口地址（默认是 9421）；# CHUNKS_LOOP_MAX_CPS = 100000# CHUNKS_LOOP_MIN_TIME = 300 chunks 的回环频率（默认是：300 秒）；注：原文为Chunks loop frequency in seconds (default is 300)# CHUNKS_SOFT_DEL_LIMIT = 10# CHUNKS_HARD_DEL_LIMIT = 25# CHUNKS_WRITE_REP_LIMIT = 2# CHUNKS_READ_REP_LIMIT = 10# ACCEPTABLE_DIFFERENCE = 0.1# SESSION_SUSTAIN_TIME = 86400# REJECT_OLD_CLIENTS = 0 弹出低于 1.6.0 的客户端挂接（0 或 1，默认是 0）注意mfsexports 访问控制对于那些老客户是没用的# deprecated:# CHUNKS_DEL_LIMIT - use CHUNKS_SOFT_DEL_LIMIT instead# LOCK_FILE - lock system has been changed, and this option is used only to search for old lockfile\\ mfsexport.cfg#* / ro#192.168.1.0/24 / rw#192.168.1.0/24 / rw,alldirs,maproot=0,password=passcode#10.0.0.0-10.0.0.5 /test rw,maproot=nobody,password=test* . rw#* / rw,alldirs,maproot=0172.16.18.221 . rw \\ 回收站172.16.18.221 / rw,alldirs,maproot=0172.16.18.134 / rw,alldirs,maproot=0 修改配置文件 123cd /usr/local/mfs/etc/mv mfsmaster.cfg.dist mfsmaster.cfgmv mfsexports.cfg.dist mfsexports.cfg mfsmaster.cfg : master的主配置文件，配置文件中所有的选项都是用#注释掉的，这代表的是将会使用的选项的默认参数，如果要修改只需取消注释修改其值为你所要使用的值即可； mfsexportes.cfg 为共享mfs文件系统的控制文件，NFS要共享一个目录时，我们会使用vim /etc/exports命令，编写共享给谁，所要共享的目录，共享出去的属性这些内容，而mfsexports.cfg的作用与其类似其书写格式如下： 123client Directory Property* / rw,alldirs,maproot=0client支持格式：ip、ip/netmask、ip/位数掩码、ip-ip、* 该文件每一个条目分为三部分：第一部分：客户端的ip 地址第二部分：被挂接的目录第三部分：客户端拥有的权限123456789101112131415//地址可以指定的几种表现形式：* 所有的ip 地址n.n.n.n 单个ip 地址n.n.n.n/b IP 网络地址/位数掩码n.n.n.n/m.m.m.m IP 网络地址/子网掩码f.f.f.f-t.t.t.t IP 段//目录部分需要注意两点：/ 标识MooseFS 根;. 表示MFSMETA 文件系统//权限部分：ro 只读模式共享rw 读写的方式共享alldirs 许挂载任何指定的子目录 启动服务 1234/usr/local/mfs/sbin/mfsmaster start//为了监控moosefs的当前运行状态，我们可以运行cgi服务，这样就可以用浏览器查看整个moosefs的运行情况/usr/local/mfs/sbin/mfscgiserv Metalogger 修改配置文件 1234mv mfsmetalogger.cfg.dist mfsmetalogger.cfgMETA_DOWNLOAD_FREQ = 24 \\元数据备份下载请求频率，设置为1小时MASTER_HOST = 172.16.18.137 \\修改MASTER_HOST的值，为MASTER_HOST的ip地址 启动服务 1/usr/local/mfs/sbin/mfsmetalogger start ChunkServer 配置分区 123456parted -s /dev/sdb &apos;mklabel gpt&apos;;parted -s /dev/sdc &apos;mklabel gpt&apos;;parted -s /dev/sdd &apos;mklabel gpt&apos;parted -s /dev/sdb &apos;mkpart primary 0 -1&apos;; parted -s /dev/sdc &apos;mkpart primary 0 -1&apos;; parted -s /dev/sdd &apos;mkpart primary 0 -1&apos;mkfs.ext4 -q -T largefile /dev/sdb1;mkfs.ext4 -q -T largefile /dev/sdc1;mkfs.ext4 -q -T largefile /dev/sdd1mkdir /MFS_data&#123;1,2,3&#125; mount /dev/sdb1 /MFS_data1; mount /dev/sdc1 /MFS_data2; mount /dev/sdd1 /MFS_data3chown mfs:mfs /MFS_data* 修改配置文件 123456789mv mfschunkserver.cfg.dist mfschunkserver.cfg修改MASTER_HOST的值，为MASTER_HOST的ip地址：MASTER_HOST = 172.16.18.137mv mfshdd.cfg.dist mfshdd.cfg增加挂载目录信息/MFS_data1/MFS_data2/MFS_data3 启动服务 1/usr/local/mfs/sbin/mfschunkserver start Client 挂载MFS 123mkdir /MFS_data/usr/local/mfs/bin/mfsmount /MFS_data -H 172.16.18.137mfsmaster accepted connection with parameters: read-write,restricted_ip ; root mapped to root:root 特别需要注意的是，所有的MFS 都是挂接同一个元数据服务器master 的IP,而不是其他数据存储服务器chunkserver 的IP 使用MFSMFS文件系统使用Client通过MFS软件提供的工具来管理MFS文件系统，下面是工具介绍 1234567891011121314151617181920212223242526/usr/local/mfs/bin/mfstools -hmfs multi toolusage: mfstools create - create symlinks (mfs&lt;toolname&gt; -&gt; /usr/local/mfs/bin/mfstools)tools: mfsgetgoal // 设定副本数 mfssetgoal // 获取副本数 mfsgettrashtime // 设定回收站时间 mfssettrashtime // 设定回收站时间 mfscheckfile // 检查文件 mfsfileinfo // 文件信息 mfsappendchunks mfsdirinfo // 目录信息 mfsfilerepair // 文件修复 mfsmakesnapshot // 快照 mfsgeteattr // 设置权限 mfsseteattr mfsdeleattrdeprecated tools: // 递归设置 mfsrgetgoal = mfsgetgoal -r mfsrsetgoal = mfssetgoal -r mfsrgettrashtime = mfsgettreshtime -r mfsrsettrashtime = mfssettreshtime -r 挂载文件系统MooseFS 文件系统利用下面的命令： 12345mfsmount mountpoint [-d][-f] [-s][-m] [-n][-p] [-HMASTER][-PPORT] [-S PATH][-o OPT[,OPT...]]-H MASTER：是管理服务器（master server）的ip 地址-P PORT： 是管理服务器（ master server）的端口号，要按照mfsmaster.cfg 配置文件中的变量MATOCU_LISTEN_POR 的之填写。如果master serve 使用的是默认端口号则不用指出。-S PATH：指出被挂接mfs 目录的子目录，默认是/目录，就是挂载整个mfs 目录。 Mountpoint：是指先前创建的用来挂接mfs 的目录。在开始mfsmount 进程时，用一个-m 或-o mfsmeta 的选项，这样可以挂接一个辅助的文件系统MFSMETA，这么做的目的是对于意外的从MooseFS 卷上删除文件或者是为了释放磁盘空间而移动的文件而又此文件又过去了垃圾文件存放期的恢复，例如： 1/usr/local/mfs/bin/mfsmount -m /MFS_meta/ -H 172.16.18.137 设定副本数量目标（goal），是指文件被拷贝副本的份数，设定了拷贝的份数后是可以通过mfsgetgoal 命令来证实的，也可以通过mfsrsetgoal 来改变设定。 12mfssetgoal 3 /MFS_data/test/mfssetgoal 3 /MFS_data/test/ 用mfsgetgoal –r 和mfssetgoal –r 同样的操作可以对整个树形目录递归操作，其等效于mfsrsetgoal命令。实际的拷贝份数可以通过mfscheckfile 和mfsfile info命令来证实。 注意以下几种特殊情况： 一个不包含数据的零长度的文件,尽管没有设置为非零的目标（the non-zero “goal”）,但用mfscheckfile 命令查询将返回一个空的结果；将文件填充内容后，其会根据设置的goal创建副本；这时再将文件清空，其副本依然作为空文件存在。 假如改变一个已经存在的文件的拷贝个数，那么文件的拷贝份数将会被扩大或者被删除，这个过程会有延时。可以通过mfscheckfile 命令来证实。 对一个目录设定“目标”，此目录下的新创建文件和子目录均会继承此目录的设定，但不会改变已经存在的文件及目录的拷贝份数。 可以通过mfsdirinfo来查看整个目录树的信息摘要。 垃圾回收站一个被删除文件能够存放在一个“ 垃圾箱”的时间就是一个隔离时间， 这个时间可以用mfsgettrashtime 命令来验证，也可以使用`mfssettrashtime 命令来设置。12mfssettrashtime 64800 /MFS_data/test/test1mfsgettrashtime /MFS_data/test/test1 时间的单位是秒(有用的值有:1 小时是3600 秒,24 - 86400 秒,1天 - 604800 秒)。就像文件被存储的份数一样, 为一个目录设定存放时间是要被新创建的文件和目录所继承的。数字0 意味着一个文件被删除后, 将立即被彻底删除，在想回收是不可能的。 删除文件可以通过一个单独安装MFSMETA 文件系统。特别是它包含目录/ trash (包含任然可以被还原的被删除文件的信息)和/ trash/undel (用于获取文件)。只有管理员有权限访问MFSMETA(用户的uid 0，通常是root)。 1/usr/local/mfs/bin/mfsmount -m /MFS_meta/ -H 172.16.18.137 被删文件的文件名在“垃圾箱”目录里还可见,文件名由一个八位十六进制的数i-node 和被删文件的文件名组成，在文件名和i-node 之间不是用“/”,而是用了“|”替代。如果一个文件名的长度超过操作系统的限制（通常是255 个字符），那么部分将被删除。通过从挂载点起全路径的文件名被删除的文件任然可以被读写。 移动这个文件到trash/undel 子目录下，将会使原始的文件恢复到正确的MooseFS 文件系统上路径下（如果路径没有改变）。如果在同一路径下有个新的同名文件，那么恢复不会成功。 从“垃圾箱”中删除文件结果是释放之前被它站用的空间(删除有延迟,数据被异步删除)。 在MFSMETA中还有另一个目录reserved，该目录内的是被删除但依然打开的文件。在用户关闭了这些被打开的文件后，reserved 目录中的文件将被删除，文件的数据也将被立即删除。在reserved 目录中文件的命名方法同trash 目录中的一样，但是不能有其他功能的操作。 快照snapshotMooseFS 系统的另一个特征是利用mfsmakesnapshot 工具给文件或者是目录树做快照1mfsmakesnapshot source ... destination Mfsmakesnapshot 是在一次执行中整合了一个或是一组文件的拷贝，而且任何修改这些文件的源文件都不会影响到源文件的快照， 就是说任何对源文件的操作,例如写入源文件，将不会修改副本(或反之亦然)。也可以使用mfsappendchunks：1mfsappendchunks destination-file source-file ... 当有多个源文件时，它们的快照被加入到同一个目标文件中（每个chunk 的最大量是chunk）。 MFS集群维护启动MFS集群安全的启动MooseFS 集群（避免任何读或写的错误数据或类似的问题）的方式是按照以下命令步骤： 启动mfsmaster 进程 启动所有的mfschunkserver 进程 启动mfsmetalogger 进程（如果配置了mfsmetalogger） 当所有的chunkservers 连接到MooseFS master 后，任何数目的客户端可以利用mfsmount 去挂接被export 的文件系统。（可以通过检查master 的日志或是CGI 监视器来查看是否所有的chunkserver被连接）。 停止MFS集群安全的停止MooseFS 集群： 在所有的客户端卸载MooseFS 文件系统（用umount 命令或者是其它等效的命令） 用mfschunkserver stop 命令停止chunkserver 进程 用mfsmetalogger stop 命令停止metalogger 进程 用mfsmaster stop 命令停止master 进程 Chunkservers 的维护若每个文件的goal（目标）都不小于2，并且没有under-goal 文件（这些可以用mfsgetgoal –r和mfsdirinfo 命令来检查），那么一个单一的chunkserver 在任何时刻都可能做停止或者是重新启动。以后每当需要做停止或者是重新启动另一个chunkserver 的时候，要确定之前的chunkserver 被连接，而且要没有under-goal chunks。 MFS元数据备份通常元数据有两部分的数据： 主要元数据文件metadata.mfs，当mfsmaster 运行的时候会被命名为metadata.mfs.back 元数据改变日志changelog.*.mfs，存储了过去的N 小时的文件改变（N 的数值是由BACK_LOGS参数设置的，参数的设置在mfschunkserver.cfg 配置文件中）。 主要的元数据文件需要定期备份，备份的频率取决于取决于多少小时changelogs 储存。元数据changelogs 实时的自动复制。1.6版本中这个工作都由metalogger完成。 MFS Master的恢复一旦mfsmaster 崩溃（例如因为主机或电源失败），需要最后一个元数据日志changelog 并入主要的metadata 中。这个操作时通过mfsmetarestore工具做的，最简单的方法是： 1mfsmetarestore -a 如果master 数据被存储在MooseFS 编译指定地点外的路径，则要利用-d 参数指定使用，如： 1mfsmetarestore -a -d /opt/mfsmaster 从MetaLogger中恢复Master如果mfsmetarestore -a无法修复，则使用metalogger也可能无法修复，暂时没遇到过这种情况，这里不暂不考虑。 找回metadata.mfs.back 文件，可以从备份中找，也可以中metalogger 主机中找（如果启动了metalogger 服务），然后把metadata.mfs.back 放入data 目录，一般为{prefix}/var/mfs 从在master 宕掉之前的任何运行metalogger 服务的服务器上拷贝最后metadata 文件，然后放入mfsmaster 的数据目录。 利用mfsmetarestore 命令合并元数据changelogs，可以用自动恢复模式mfsmetarestore –a，也可以利用非自动化恢复模式 1mfsmetarestore -m metadata.mfs.back -o metadata.mfs changelog_ml.*.mfs 或：强制使用metadata.mfs.back创建metadata.mfs，可以启动master，但丢失的数据暂无法确定。 Automated Failover生产环境使用 MooseFS 时，需要保证 master 节点的高可用。 使用 ucarp 是一种比较成熟的方案，或者DRBD+[hearbeat|keepalived]。ucarp 类似于 keepalived，通过主备服务器间的健康检查来发现集群状态，并执行相应操作。另外 MooseFS商业版本已经支持双主配置，解决单点故障。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[git常用命令]]></title>
      <url>http://czero000.github.io/2016/04/18/git-common.html</url>
      <content type="text"><![CDATA[Git已经成为程序员日常工具之一，那些Git基本的命令，每天都要用的命令你都记住了吗？如果还没的话，笔者整理了一份清单，以备不时之需所用。 三个基本概念 工作区(Workspace)是计算机中项目的根目录 暂存区(Index)像个缓存区域，临时保存你的改动 版本库(Repository)分为本地仓库（Local)和远程仓库(Remote)几乎所有常用命令就是围绕这几个概念来操作的，一图胜千言，下面是一张比较简单的图，包括了最基本的命令 但只会使用以上命令是不够的，在这个复杂纷繁的程序世界，事情没你想的那么简单，不过有些事情想想就够了，不一定要去做，真要去做你也做不来，比如自己写个git来，但是，更多地的了解git是我们每个程序员都可以做得到的事。再看下图： 下面的命令结合上面两张图来理解、练习、记忆效果更加。暂时用不着的命令记不住，不理解也没关系，哪天遇到问题，再来找找有没有合适的方法也不迟。 新建/克隆代码库 1234git init #当前目录新建一个Git代码库git init [project-name] #新建一个目录，将其初始化为Git代码库git clone [url] #下载一个项目和它的整个代码历史git fetch [url] #下载/同步项目到 添加/删除文件 123456git add [file1] [file2] ... # 添加指定文件到暂存区git add [dir] # 添加指定目录到暂存区，包括子目录git add . # 添加当前目录的所有文件到暂存区git rm [file1] [file2] ... # 删除工作区文件，并且将这次删除放入暂存区git rm --cached [file] # 停止追踪指定文件，但该文件会保留在工作区git mv [file-original] [file-renamed] # 改名文件，并且将这个改名放入暂存区 代码提交 12345git commit -m [message] # 提交暂存区所有文件到仓库区，并指定提交说明git commit [file1] [file2] ... -m [message] # 提交暂存区的指定文件到仓库区，并指定提交说明git commit -a # 提交工作区自上次commit之后的变化，直接到仓库区。是git add 和 git commit的组合操作git commit -v # 提交时显示所有diff信息git commit --amend -m [message] # 使用一次新的commit，替代上一次提交 分支 1234567891011git branch # 列出所有本地分支git branch -r # 列出所有远程分支git branch -a # 列出所有本地分支和远程分支git branch [branch-name] # 新建一个分支，但依然停留在当前分支git checkout -b [branch] # 新建一个分支，并切换到该分支git branch [branch] [commit] # 新建一个分支，指向指定commitgit checkout [branch-name] # 切换到指定分支git merge [branch] # 合并指定分支到当前分支git branch -d [branch-name] # 删除本地分支git push origin --delete [branch-name] # 方法一：删除远程分支git branch -dr [remote/branch] # 方法二：删除远程分支 撤销 123456789git checkout [file] # 恢复暂存区的指定文件到工作区（注意区别分支操作中得checkout命令）git checkout [commit] [file] # 恢复某个commit的指定文件到暂存区和工作区git checkout . # 恢复暂存区的所有文件到工作区git reset [file] # 重置暂存区的指定文件，与最新的commit保持一致，但工作区不变git reset --hard # 重置暂存区与工作区，与最新的commit保持一致git reset [commit] # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变git reset --hard [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致git reset --keep [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变git revert [commit] # 新建一个commit，用来撤销指定commit 标签 123456789git tag # 列出所有taggit tag [tag] # 在当前commit新建一个taggit tag [tag] [commit] # 在指定commit新建一个taggit tag -d [tag] # 删除本地taggit push origin :refs/tags/[tagName] # 删除远程taggit show [tag] # 查看tag信息git push [remote] [tag] # 提交指定taggit push [remote] --tags # 提交所有taggit checkout -b [branch] [tag] # 新建一个分支，指向某个tag 查看日志 123456789101112git status # 显示所有变更文件git log # 显示当前分支的版本历史git log --stat # 显示当前分支的版本历史，以及发生变更的文件git blame [file] # 显示指定文件是什么人在什么时间修改过git log -p [file] # 显示指定文件相关的每一次diffgit diff # 显示暂存区和工作区的差异git diff --cached [commit] # 显示暂存区和某个commit的差异git diff HEAD # 显示工作区与当前分支最新commit之间的差异git show [commit] # 显示某次提交的元数据和内容变化git show --name-only [commit] # 显示某次提交发生变化的文件git show [commit]:[filename] # 显示某次提交时，某个文件的内容git reflog # 显示当前分支的最近几次提交 远程同步 12345678git fetch [remote] # 下载远程仓库的所有变动到暂存区git remote -v # 显示所有远程仓库git remote show [remote] # 显示某个远程仓库的信息git remote add [shortname] [url] # 增加一个新的远程仓库，并命名git pull [remote] [branch] # 取回远程仓库的变化，并与本地分支合并git push [remote] [branch] # 上传本地指定分支到远程仓库git push [remote] --force # 即使有冲突，强行推送当前分支到远程仓库git push [remote] --all # 推送所有分支到远程仓库 设置 git的配置文件是.gitconfig，支持全局配置和项目配置，全部配置对所有项目有效，用 –global选择指定。 1234git config --list #显示配置git config -e [--global] #编辑(全局)配置文件git config [--global] user.name &quot;xx&quot; #设置 commit 的用户git config [--global] user.email &quot;xx@xx.com&quot; #设置 commit 的邮箱]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SaltStack-Nodegroup]]></title>
      <url>http://czero000.github.io/2016/04/07/saltstack-nodegroup.html</url>
      <content type="text"><![CDATA[为了便于管理功能相似的minion，SaltStack提供了分组模式，官方文档：http://docs.saltstack.com/en/latest/topics/targeting/nodegroups.htmlNode group为预先在master配置文件中定义的minion组，用来进行批量对minion操作。在master配置文件中，删除default_include: master.d/*.conf注释。 编辑配置文件： /etc/salt/master.d/nodegroup.conf 123456##### Node Groups ################################################ Node groups allow for logical groupings of minion nodes. A group consists of a group# name and a compound target.nodegroups: minion: &apos;172.16.11.211&apos; 重启master 测试通过-N参数在命令行指定运行的节点组：123salt -N minion test.ping172.16.11.211: True 在top file中增加组分类 12345base: minion: - match: nodegroup - apache - ssh]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SaltStack-States]]></title>
      <url>http://czero000.github.io/2016/04/07/saltstack-states.html</url>
      <content type="text"><![CDATA[SaltStack的stateSaltStack使用state模块文件进行配置管理，state使用YAML语法编写，其实它也支持python编写。sls(salt state file)文件为SaltStack state模块的核心，sls文件表示一个系统应处于的系统状态，并且有一个简单的格式设置这些数据，称为配置管理。 It is all just data其实sls文件只是一个数据结构，对于sls文件的深入理解会有助于对salt state的深入理解和应用。sls文件事实上只是一个字典、列表、字符串或者数字。通过对配置进行数据结构化，使其满足开发者的各种需求，写的越多，越易于理解。 The top file所有的state file都可以通过top.sl文件来分配不同的主机使用，这是个整体入口描述，在执行命令的时候，会先检查这个文件，可以看作是基础配置文件 Default data -yaml默认情况下salt表现的数据格式采用最简单的序列化数据格式-YAML，由于不同架构经常使用不同的名称和安装包，apache在红帽系列中是httpd，其他发行版多为apache，salt对于底层服务器管理使用init下的脚本，系统命令名，配置文件等，执行service.get_all函数来获取对应服务器可用的服务名称 使用state通过命令查看state使用方法123456// 查看所有states列表salt -N minion&apos; sys.list_state_modules// 查看指定states的functionssalt -N &apos;minion&apos; sys.list_state_functions file//查看指定states的用法salt -N &apos;minion&apos; sys.state_doc file 通过示例了解state 安装软件包及启动服务 由于不同架构经常使用不同的名称和安装包，apache在红帽系列中是httpd，其他发行版多为apache，salt对于底层服务器管理使用init下的脚本，系统命令名，配置文件等，执行service.get_all函数来获取对应服务器可用的服务名称 1234567httpd: pkg: - installed service: - running - require: - pkg: httpd 这些sls数据确保apache包被安装而且apache服务处于运行状态。第一行：被称为ID，这个ID是将要执行这些命令的名字第二行和第四行：用来声明salt state开始的状态，分别使用包管理和服务管理，这个pkg状态管理，通过本地的软件包管理器进行软件安装，service管理系统守护进程第三行、第五行：是要执行的function，这些函数被定义在pkg和service中，这里标示包会被安装，并且apache守护进行会运行最后一行：require是一个必要的声明，用来定义状态之剑的依赖，他们保证apache服务安装成功后才会启动apache守护进程state和方法可以通过点连接起来，上例和下文相同：12345httpd: pkg.installed service.running - require: - pkg: httpd 在实际配置管理中，需要编写大量state.sls文件。这些文件会有一个top.sls（非必须）文件作为入口文件，负责指定minion调用某些state.sls文件。 将上面的sls保存为init.sls放置在salt://apache目录下， 1234/srv/salt/├── apache│ └── init.sls└── top.sls 添加配置文件和用户 ​ 当建立类似Apache服务器这样的服务时，许多组件需要被安装。apache的配置文件要被管理起来，而且还需要特定的用户和用户 12345678910111213141516171819202122232425262728httpd: pkg: - installed service: - running - watch: - pkg: httpd - file: /etc/httpd/conf/httpd.conf - user: apache user.present: - name: apache - uid: 48 - gid: 48 - home: /var/www - shell: /bin/nologin - require: - group: apache group.present: - name: apache - gid: 48 - require: - pkg: httpd/etc/httpd/conf/httpd.conf: file.managed: - source: salt://apache/httpd.conf - user: root - group: root - mode: 644 ​ 这个例子扩展了上面，其中包括了一个配置文件、一个用户、一个用户组还有一个新的声明：watch。在service中的require换成了watch，从需要一个软件包改成监视3个state（分别是pkg、file、user）。watch语句和require很相似，都能保证被监视或者需要的state在自己之前执行，但是watch还有其他作用。当被监视的state发生变化时，定义watch语句的state与执行自己的watcher函数，当更新软件包、配置文件或者修改apache用户的uid都会触发service state的watcher函数，在本例子中，service state的watcher会重启apache服务。 多个sls文件 ​ 在具有扩展性的SaltStack时，需要不止一个sls，上面的例子中只使用了1个sls文件，多个sls文件可以结合成state tree。sls文件以一定的目录结构分布在master，sls和要发到minion上的文件只是普通文件. ssh/init.sls 123456789101112131415161718192021222324252627282930313233343536373839404142::::::::::::::init.sls::::::::::::::include: - client - server::::::::::::::client.sls::::::::::::::openssh-clients: pkg.installed/etc/ssh/ssh_config: file.managed: - user: root - group: root - mode: 644 - source: salt://ssh/files/ssh_config - require: - pkg: openssh-clients ::::::::::::::server.sls::::::::::::::include: - sshopenssh-server: pkg.installedsshd: service.running: - require: - pkg: openssh-clients - pkg: openssh-server - file: /etc/ssh/sshd_config/etc/ssh/sshd_config: file.managed: - user: root - group: root - mode: 644 - source: salt://ssh/files/sshd_config - require: - pkg: openssh-server 扩展被引用的sls数据 什么是扩展呢。在ssh/server.sls文件中定义了一个apache通用的服务器，现在需要增加一个带有mod_python模块的apache，不需要重新写sls，可以直接include原来的server.sls，然后增加安装mod_python的state，在apache service的watch列表中增加mod_python即可。** python/mod_ypthon.sls内容如下： 12345678910include: - apacheextend: apache: service: - watch: - pkg:mod_pythonmod_python: pkg.installed 这个例子中，先把apache目录下init.sls文件包含进来（在include一个目录时，salt会自动查找init.sls文件），然后拓展了ID为apache下的service state中的watch列表。也可以在extending中修改下载文件位置。extend是salt 的sls更加灵活。 理解渲染系统Render System 因为sls仅是数据，所以不是非要用YAML来表达。salt 默认用YAML，只是因为容易学习和使用，只要提供一个渲染器，sls文件可以以任意格式呈现出来。 ​ 缺省的渲染系统是yaml_jinja渲染器。yaml_jinja渲染器使用jinjia2模版引擎来处理sls，然后在调用YAML解析。其他可用的渲染其还包括：yaml_mako模版引擎；yaml_wempy，使用Wempy模版引擎；py，使用Python写sls文件；pydsl，建立在python语法基础上的描述语言。 默认渲染器—yaml_jinja 关于jinjia模板系统使用参考官方稳定：http://jinja.pocoo.org/docs 在基于模板引擎的渲染器，可以从3个组件中获取需要的数据：salt，grains和pilla。在模板文件中，salt对象允许任何salt函数从模板内容进行调用，grains允许grains从模板中访问： 12345678910111213141516171819202122232425262728293031323334apache: pkg: - installed &#123;% if grains[ &apos;os&apos; ] == &apos;CentOS&apos; %&#125; - name: httpd &#123;% endif %&#125; service: - running &#123;% if grains[ &apos;os&apos; ] == &apos;CentOS&apos;%&#125; - name: httpd &#123;% endif %&#125; - watch: - pkg: apache - file: /etc/httpd/conf/httpd.conf - user: apache user.present: - name: apache - uid: 48 - gid: 48 - home: /var/www - shell: /bin/nologin - require: - group: apache group.present: - name: apache - gid: 48 - require: - pkg: apache/etc/httpd/conf/httpd.conf: file.managed: - source: salt://apache/files/httpd.conf - user: root - group: root - mode: 644 这个例子很容易理解，用到jinja中的条件结构，如果grains中os表明minion的操作系统是CentOS，那么apache的软件包和服务名应当是httpd。更有意思的例子，用到jinja的循环结构，在设置MooseFS分布式中chunkserver： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950moosefs/chunk.sls：include: - moosefs&#123;% for mnt in salt['cmd.run']('ls /dev/data/moose*').split() %&#125;/mnt/moose&#123;&#123; mnt[-1] &#125;&#125;: mount.mounted: - device: &#123;&#123; mnt &#125;&#125; - fstype: xfs - mkmnt: True file.directory: - user: mfs - group: mfs - require: - user: mfs - group: mfs&#123;% endfor %&#125;/etc/mfshdd.cfg: file.managed: - source: salt://moosefs/mfshdd.cfg - user: root - group: root - mode: 644 - template: jinja - require: - pkg: mfs-chunkserver /etc/mfschunkserver.cfg: file.managed: - source: salt://moosefs/mfschunkserver.cfg - user: root - group: root - mode: 644 - template: jinja - require: - pkg: mfs-chunkserver mfs-chunkserver: pkg: - installedmfschunkserver: service: - running - require:&#123;% for mnt in salt['cmd.run']('ls /dev/data/moose*') %&#125; - mount: /mnt/moose&#123;&#123; mnt[-1] &#125;&#125; - file: /mnt/moose&#123;&#123; mnt[-1] &#125;&#125;&#123;% endfor %&#125; - file: /etc/mfschunkserver.cfg - file: /etc/mfshdd.cfg - file: /var/lib/mfs 这个例子展示了jinja的强大之处，多个for循环用来动态的检查并挂载磁盘，并多次使用salt cmd.run执行模块执行shell命令。 运行和调用salt states 一旦写好sls文件，就应该测试，以保证能够正常工作，调用这些规则，只需要在命令行中执行 salt * state.highstate。如果返回的只有主机名，很可能是sls文件存在问题，在minion，使用salt-call命令执行 salt-call state.highstate -l debug来调试输出的作物信息，亦可以在前台执行salt-minion -l debug state多环境配置 master 12345file_roots: base: - /srv/salt/base dev: - /srv/salt/dev 通过命令执行不同环境state 12salt -N &apos;minion&apos; state.sls saltenv=&apos;dev&apos;salt -N &apos;minion&apos; state.sls saltenv=&apos;base&apos;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SaltStack-Pillar]]></title>
      <url>http://czero000.github.io/2016/04/06/saltstack-pillar.html</url>
      <content type="text"><![CDATA[什么是pillarPillar是SaltStack非常重要的一个组件，经常与States配合使用在配置管理中。它用于给特定的minin定义任何你需要的数据，定义存储格式与grains类似，都是用dict结构，使用YAML格式。pillar数据和minion相关联，每个minion只可以看到自己的数据，所以可以用pillar传递敏感数据。pillar可以在以下场景中使用到： 敏感数据例如ssh key、加密证书、由于Pillar使用独立的加密session，可以确保敏感数据不被其他minion看到 变量可以在pillar中处理平台差异化，比如针对不同的操作系统设置软件包名称，然后在state中引用 其他数据可以在pillar中添加任意可以使用到的数据，例如定义用户和UID的关系、minion角色 Targetting可以用来选择minion，使用-I参数默认master配置文件中的所有数据到添加到pillar中，且对所有minion可用。如果要禁用，可以在修改master配置文件#pillar_opts: True 使用配置pillar创建pillar目录123456789101112131415161718192021222324252627282930313233// 修改master配置文件，定义pillar工作目录pillar_roots: base: - /srv/pillar// 创建工作目录mkdir /srv/pillar//创建top.sls入口文件,用来组织其他pillar文件,可以定义多个环境不同的pillar目录cat top.slsbase: //指定环境 &apos;*&apos;: // 引用主机 - packages // 引用packages.sls或者packages/init.sls - services // 引用services.sls或者services/init.sls - test // 引用test.sls或者test/init.slsdev: &apos;os:CentOS&apos; //pillar还可以使用其他的匹配方式来选择minion - git// 定义pillarcat test/init.slsNAME: zeroID: 1314CONTENT: This is a test !!cat packages/init.sls&#123;% if grains[&apos;os&apos;] == &apos;CentOS&apos; %&#125; apache: httpd git: git&#123;% elif grains[&apos;os&apos;] == &apos;Debian&apos; %&#125; apache: apache2 git: git-core&#123;&amp; endif &amp;&#125; base环境中所有的minion都具有packages、services、test 中定义的数据。pillar采用与file server相同的文件映射方式。packages映射到文件/srv/pillar/packages/init.sls。services映射到/srv/pillar/services/init.sls。值得注意的是key与value要用冒号分隔，没有空格的话解析会失败。 查看定义的pillar12345678910111213141516171819202122salt &apos;*&apos; pillar.data172.16.11.211: ---------- CONTENT: This is a test !! ID: 1314 NAME: zero http: ---------- package-name: httpd port: 80 user: nobody version: 2.4.6salt &apos;*&apos; saltutil.refresh_pillar // 在master上修改pillar文件后，需要用命令刷新minion数据 在pillar中使用列表pillar的key/value结构中的value可以是string，也可以是一个list。pillar文件定义如下： 123456789101112131415161718/srv/pillar/users/init.sls:users: zero: 1000 damon: 1001在top.sls中引用pillar文件，对所有的minion应用users中的内容：/srv/pillar/top.sls:base: &apos;*&apos;: - users// 现在所有的minion都既有user数据，可以在state文件中使用：/srv/salt/user/init.sls:&#123;% for user,uid in pillar.get(&apos;users&apos;,&#123;&#125;).items() %&#125;&#123;&#123;user&#125;&#125;: user.present: - uid: &#123;&#123;uid&#125;&#125;&#123;% endfor %&#125; 利用pillar处理平台差异不同的操作系统不仅管理资源的方式不同，软件包的名字、配置文件的路径也有可能不一样。Salt的执行模块屏蔽了系统管理资源的差异。其他的差异可以根据grains中的os、cpuarch等信息来处理，这些条件判断可以写在state，但会使得state文件的逻辑不清晰。pillar可以很好的解决这些问题。下面的例子中，在不同的os上安装对应的软件包，但是state file完全相同，不需要针对os做修改，灵活方便。12345678910111213141516171819202122232425/srv/pillar/pkg/init.sls:packages: &#123;% if grains[&apos;os_family&apos;] == &apos;CentOS&apos; %&#125; apache: httpd vim: vim-enhanced &#123;% elif grains[&apos;os_family&apos;] == &apos;Debian&apos; %&#125; apache: apache2 vim: vim (% elif grains[&apos;os&apos;] == &apos;arch&apos; %) apache: apache vim: vim &#123;&amp; endif &amp;&#125;/srv/pillar/top.sls：base:&apos;*&apos;:- data - users - pkg /srv/salt/apache/init.sls：apache: pkg.installed:- name: &#123;&#123; pillar[&apos;pkgs&apos;][&apos;apache&apos;] &#125;&#125;// 还可以在state file中设置默认值： srv/salt/apache/init.sls：apache: pkg.installed:- name: &#123;&#123; salt[&apos;pillar.get&apos;](&apos;pkgs:apache&apos;, &apos;httpd&apos;) &#125;&#125; Grains 和Pillar区别在下面的表格中通过多个维度对它们进行对比。 名称 存储位置 数据类型 数据采集更新方式 应用 Grains Minion端 静态数据 Minion启动时收集，也可以使用saltutil.sync_grains进行刷新。 存储Minion基本数据。比如用于匹配Minion，自身数据可以用来做资产管理等。 Pillar Master端 动态数据 在Master端定义，指定给对应的Minion。可以使用saltutil.refresh_pillar刷新 存储Master指定的数据，只有指定的Minion可以看到。用于敏感数据保存]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[GlusterFS技术详解]]></title>
      <url>http://czero000.github.io/2016/04/05/glusterfs-technical-explanation.html</url>
      <content type="text"><![CDATA[什么是GlusterFS GlusterFS概述 GlusterFS是Scale-Out存储解决方案Gluster的核心，他是一个开源的分布式文件系统，具有强大的横向扩展能力，通过扩展能够支持数PB存储容量和处理数千客户端。GlusterFS借助TCP/IP或InfiniBand RDMA(一种支持多并发链接的“转换线缆”技术)网络将物理分布的存储资源聚集在一起，使用单一全局命名空间来管理数据。GlusterFS基于可堆叠的用户空间设计，可为各种不同的数据负载提供优异的性能。 GlusterFS支持运行在任何标准IP网络上标准应用程序的标准客户端，如图2所示，用户可以在全局统一的命名空间中使用NFS/CIFS等标准协议来访问应用数据。GlusterFS使得用户可摆脱原有的独立、高成本的封闭存储系统，能够利用普通廉价的存储设备来部署可集中管理、横向扩展、虚拟化的存储池，存储容量可扩展至TB/PB级。GlusterFS主要特征如下： 扩展性和高性能 GlusterFS利用双重特性来提供几TB至数PB的高扩展存储解决方案。Scale-Out架构允许通过简单地增加资源来提高存储容量和性能，磁盘、计算和I/O资源都可以独立增加，支持10GbE和InfiniBand等高速网络互联。Gluster弹性哈希（Elastic Hash）解除了GlusterFS对元数据服务器的需求，消除了单点故障和性能瓶颈，真正实现了并行化数据访问。 高可用性 GlusterFS可以对文件进行自动复制，如镜像或多次复制，从而确保数据总是可以访问，甚至是在硬件故障的情况下也能正常访问。自我修复功能能够把数据恢复到正确的状态，而且修复是以增量的方式在后台执行，几乎不会产生性能负载。GlusterFS没有设计自己的私有数据文件格式，而是采用操作系统中主流标准的磁盘文件系统（如EXT3、ZFS）来存储文件，因此数据可以使用各种标准工具进行复制和访问。 全局统一命名空间 全局统一命名空间将磁盘和内存资源聚集成一个单一的虚拟存储池，对上层用户和应用屏蔽了底层的物理硬件。存储资源可以根据需要在虚拟存储池中进行弹性扩展， 比如扩容或收缩。当存储虚拟机映像时，存储的虚拟映像文件没有数量限制，成千虚拟机均通过单一挂载点进行数据共享。虚拟机I/O可在命名空间内的所有服务器上自动进行负载均衡，消除了SAN环境中经常发生的访问热点和性能瓶颈问题。 弹性哈希算法 GlusterFS采用弹性哈希算法在存储池中定位数据，而不是采用集中式或分布式元数据服务器索引。在其他的Scale-Out存储系统中，元数据服务器通常会导致I/O性能瓶颈和单点故障问题。GlusterFS中，所有在Scale-Out存储配置中的存储系统都可以智能地定位任意数据分片，不需要查看索引或者向其他服务器查询。这种设计机制完全并行化了数据访问，实现了真正的线性性能扩展。 弹性卷管理 数 据储存在逻辑卷中，逻辑卷可以从虚拟化的物理存储池进行独立逻辑划分而得到。存储服务器可以在线进行增加和移除，不会导致应用中断。逻辑卷可以在所有配置 服务器中增长和缩减，可以在不同服务器迁移进行容量均衡，或者增加和移除系统，这些操作都可在线进行。文件系统配置更改也可以实时在线进行并应用，从而可 以适应工作负载条件变化或在线性能调优。 基于标准协议 Gluster存储服务支持NFS, CIFS, HTTP, FTP以及Gluster原生协议，完全与POSIX标准兼容。现有应用程序不需要作任何修改或使用专用API，就可以对Gluster中的数据进行访问。这在公有云环境中部署Gluster时非常有用，Gluster对云服务提供商专用API进行抽象，然后提供标准POSIX接口。 设计目标GlusterFS的设计思想显著区别有现有并行/集群/分布式文件系统。如果GlusterFS在设计上没有本质性的突破，难以在与Lustre、PVFS2、Ceph等的竞争中占据优势，更别提与GPFS、StorNext、ISILON、IBRIX等具有多年技术沉淀和市场积累的商用文件系统竞争。其核心设计目标包括如下三个： 弹性存储系统（Elasticity） 存储系统具有弹性能力，意味着企业可以根据业务需要灵活地增加或缩减数据存储以及增删存储池中的资源，而不需要中断系统运行。GlusterFS设计目标之一就是弹性，允许动态增删数据卷、扩展或缩减数据卷、增删存储服务器等，不影响系统正常运行和业务服务。GlusterFS早期版本中弹性不足，部分管理工作需要中断服务，目前最新的3.1.X版本已经弹性十足，能够满足对存储系统弹性要求高的应用需求，尤其是对云存储服务系统而言意义更大。GlusterFS主要通过存储虚拟化技术和逻辑卷管理来实现这一设计目标。 线性横向扩展（Linear Scale-Out） 线性扩展对于存储系统而言是非常难以实现的，通常系统规模扩展与性能提升之间是LOG对数曲线关系，因为同时会产生相应负载而消耗了部分性能的提升。现在的很多并行/集群/分布式文件系统都具很高的扩展能力，Luster存储节点可以达到1000个以上，客户端数量能够达到25000以上，这个扩展能力是非常强大的，但是Lustre也不是线性扩展的。 纵向扩展（Scale-Up）旨在提高单个节点的存储容量或性能，往往存在理论上或物理上的各种限制，而无法满足存储需求。横向扩展（Scale-Out）通过增加存储节点来提升整个系统的容量或性能，这一扩展机制是目前的存储技术热点，能有效应对容量、性能等存储需求。目前的并行/集群/分布式文件系统大多都具备横向扩展能力。 GlusterFS是线性横向扩展架构，它通过横向扩展存储节点即可以获得线性的存储容量和性能的提升。因此，结合纵向扩展GlusterFS可以获得多维扩展能力，增加每个节点的磁盘可增加存储容量，增加存储节点可以提高性能，从而将更多磁盘、内存、I/O资源聚集成更大容量、更高性能的虚拟存储池。GlusterFS利用三种基本技术来获得线性横向扩展能力： 消除元数据服务 高效数据分布，获得扩展性和可靠性 通过完全分布式架构的并行化获得性能的最大化** 高可靠性（Reliability） 与GFS（Google File System）类似，GlusterFS可以构建在普通的服务器和存储设备之上，因此可靠性显得尤为关键。GlusterFS从设计之初就将可靠性纳入核心设计，采用了多种技术来实现这一设计目标。首先，它假设故障是正常事件，包括硬件、磁盘、网络故障以及管理员误操作造成的数据损坏等。GlusterFS设计支持自动复制和自动修复功能来保证数据可靠性，不需要管理员的干预。其次，GlusterFS利用了底层EXT3/ZFS等磁盘文件系统的日志功能来提供一定的数据可靠性，而没有自己重新发明轮子。再次，GlusterFS是无元数据服务器设计，不需要元数据的同步或者一致性维护，很大程度上降低了系统复杂性，不仅提高了性能，还大大提高了系统可靠性。 技术特点GlusterFS在技术实现上与传统存储系统或现有其他分布式文件系统有显著不同之处，主要体现在如下几个方面。 完全软件实现（Software Only） GlusterFS认为存储是软件问题，不能够把用户局限于使用特定的供应商或硬件配置来解决。GlusterFS采用开放式设计，广泛支持工业标准的存储、网络和计算机设备，而非与定制化的专用硬件设备捆绑。对于商业客户，GlusterFS可以以虚拟装置的形式交付，也可以与虚拟机容器打包，或者是公有云中部署的映像。开源社区中，GlusterFS被大量部署在基于廉价闲置硬件的各种操作系统上，构成集中统一的虚拟存储资源池。简而言之，GlusterFS是开放的全软件实现，完全独立于硬件和操作系统。 完整的存储操作系统栈（Complete Storage Operating System Stack） GlusterFS不仅提供了一个分布式文件系统，而且还提供了许多其他重要的分布式功能，比如分布式内存管理、I/O调度、软RAID和自我修复等。GlusterFS汲取了微内核架构的经验教训，借鉴了GNU/Hurd操作系统的设计思想，在用户空间实现了完整的存储操作系统栈。 用户空间实现（User Space） 与传统的文件系统不同，GlusterFS在用户空间实现，这使得其安装和升级特别简便。另外，这也极大降低了普通用户基于源码修改GlusterFS的门槛，仅仅需要通用的C程序设计技能，而不需要特别的内核编程经验。 模块化堆栈式架构（Modular Stackable Architecture） GlusterFS采用模块化、堆栈式的架构，可通过灵活的配置支持高度定制化的应用环境，比如大文件存储、海量小文件存储、云存储、多传输协议应用等。每个功能以模块形式实现，然后以积木方式进行简单的组合，即可实现复杂的功能。比如，Replicate模块可实现RAID1，Stripe模块可实现RAID0，通过两者的组合可实现RAID10和RAID01，同时获得高性能和高可靠性。 原始数据格式存储（Data Stored in Native Formats） GlusterFS以原始数据格式（如EXT3、EXT4、XFS、ZFS）储存数据，并实现多种数据自动修复机制。因此，系统极具弹性，即使离线情形下文件也可以通过其他标准工具进行访问。如果用户需要从GlusterFS中迁移数据，不需要作任何修改仍然可以完全使用这些数据。 无元数据服务设计（No Metadata with the Elastic Hash Algorithm） 对Scale-Out存 储系统而言，最大的挑战之一就是记录数据逻辑与物理位置的映像关系，即数据元数据，可能还包括诸如属性和访问权限等信息。传统分布式存储系统使用集中式或 分布式元数据服务来维护元数据，集中式元数据服务会导致单点故障和性能瓶颈问题，而分布式元数据服务存在性能负载和元数据同步一致性问题。特别是对于海量 小文件的应用，元数据问题是个非常大的挑战。 GlusterFS独 特地采用无元数据服务的设计，取而代之使用算法来定位文件，元数据和数据没有分离而是一起存储。集群中的所有存储系统服务器都可以智能地对文件数据分片进 行定位，仅仅根据文件名和路径并运用算法即可，而不需要查询索引或者其他服务器。这使得数据访问完全并行化，从而实现真正的线性性能扩展。无元数据服务器 极大提高了GlusterFS的性能、可靠性和稳定性。 总体架构和设计 GlusterFS总体架构与组成部分如上图所示，它主要由存储服务器（Brick Server）、客户端以及NFS/Samba存储网关组成。不难发现，GlusterFS架构中没有元数据服务器组件，这是其最大的设计这点，对于提升整个系统的性能、可靠性和稳定性都有着决定性的意义。GlusterFS支持TCP/IP和InfiniBand RDMA高速网络互联，客户端可通过原生Glusterfs协议访问数据，其他没有运行GlusterFS客户端的终端可通过NFS/CIFS标准协议通过存储网关访问数据。 存储服务器主要提供基本的数据存储功能，最终的文件数据通过统一的调度策略分布在不同的存储服务器上。它们上面运行着Glusterfsd进行，负责处理来自其他组件的数据服务请求。如前所述，数据以原始格式直接存储在服务器的本地文件系统上，如EXT3、EXT4、XFS、ZFS等，运行服务时指定数据存储路径。多个存储服务器可以通过客户端或存储网关上的卷管理器组成集群，如Stripe（RAID0）、Replicate（RAID1）和DHT（分布式Hash）存储集群，也可利用嵌套组合构成更加复杂的集群，如RAID10。 由于没有了元数据服务器，客户端承担了更多的功能，包括数据卷管理、I/O调度、文件定位、数据缓存等功能。客户端上运行Glusterfs进程，它实际是Glusterfsd的符号链接，利用FUSE（File system in User Space）模块将GlusterFS挂载到本地文件系统之上，实现POSIX兼容的方式来访问系统数据。在最新的3.1.X版本中，客户端不再需要独立维护卷配置信息，改成自动从运行在网关上的glusterd弹性卷管理服务进行获取和更新，极大简化了卷管理。GlusterFS客户端负载相对传统分布式文件系统要高，包括CPU占用率和内存占用。 GlusterFS存储网关提供弹性卷管理和NFS/CIFS访问代理功能，其上运行Glusterd和Glusterfs进程，两者都是Glusterfsd符号链接。卷管理器负责逻辑卷的创建、删除、容量扩展与缩减、容量平滑等功能，并负责向客户端提供逻辑卷信息及主动更新通知功能等。GlusterFS 3.1.X实现了逻辑卷的弹性和自动化管理，不需要中断数据服务或上层应用业务。对于Windows客户端或没有安装GlusterFS的客户端，需要通过NFS/CIFS代理网关来访问，这时网关被配置成NFS或Samba服务器。相对原生客户端，网关在性能上要受到NFS/Samba的制约。 GlusterFS是模块化堆栈式的架构设计，如图3所示。模块称为Translator，是GlusterFS提供的一种强大机制，借助这种良好定义的接口可以高效简便地扩展文件系统的功能。服务端与客户端模块接口是兼容的，同一个translator可同时在两边加载。每个translator都是SO动态库，运行时根据配置动态加载。每个模块实现特定基本功能，GlusterFS中所有的功能都是通过translator实现，比如Cluster, Storage, Performance, Protocol, Features等，基本简单的模块可以通过堆栈式的组合来实现复杂的功能。这一设计思想借鉴了GNU/Hurd微内核的虚拟文件系统设计，可以把对外部系统的访问转换成目标系统的适当调用。大部分模块都运行在客户端，比如合成器、I/O调度器和性能优化等，服务端相对简单许多。客户端和存储服务器均有自己的存储栈，构成了一棵Translator功能树，应用了若干模块。模块化和堆栈式的架构设计，极大降低了系统设计复杂性，简化了系统的实现、升级以及系统维护。 弹性哈希算法对于分布式系统而言，元数据处理是决定系统扩展性、性能以及稳定性的关键。GlusterFS另辟蹊径，彻底摒弃了元数据服务，使用弹性哈希算法代替传统分布式文件系统中的集中或分布式元数据服务。这根本性解决了元数据这一难题，从而获得了接近线性的高扩展性，同时也提高了系统性能和可靠性。GlusterFS使用算法进行数据定位，集群中的任何服务器和客户端只需根据路径和文件名就可以对数据进行定位和读写访问。换句话说，GlusterFS不需要将元数据与数据进行分离，因为文件定位可独立并行化进行。GlusterFS中数据访问流程如下： 计算hash值，输入参数为文件路径和文件名； 根据hash值在集群中选择子卷（存储服务器），进行文件定位； 对所选择的子卷进行数据访问。 GlusterFS目前使用Davies-Meyer算法计算文件名hash值，获得一个32位整数。Davies-Meyer算法具有非常好的hash分布性，计算效率很高。假设逻辑卷中的存储服务器有N个，则32位整数空间被平均划分为N个连续子空间，每个空间分别映射到一个存储服务器。这样，计算得到的32位hash值就会被投射到一个存储服务器，即我们要选择的子卷。难道真是如此简单？现在让我们来考虑一下存储节点加入和删除、文件改名等情况，GlusterFS如何解决这些问题而具备弹性的呢？ 逻辑卷中加入一个新存储节点，如果不作其他任何处理，hash值 映射空间将会发生变化，现有的文件目录可能会被重新定位到其他的存储服务器上，从而导致定位失败。解决问题的方法是对文件目录进行重新分布，把文件移动到 正确的存储服务器上去，但这大大加重了系统负载，尤其是对于已经存储大量的数据的海量存储系统来说显然是不可行的。另一种方法是使用一致性哈希算法，修改 新增节点及相邻节点的hash映射空间，仅需要移动相邻节点上的部分数据至新增节点，影响相对小了很多。然而，这又带来另外一个问题，即系统整体负载不均衡。GlusterFS没有采用上述两种方法，而是设计了更为弹性的算法。GlusterFS的 哈希分布是以目录为基本单位的，文件的父目录利用扩展属性记录了子卷映射信息，其下面子文件目录在父目录所属存储服务器中进行分布。由于文件目录事先保存 了分布信息，因此新增节点不会影响现有文件存储分布，它将从此后的新创建目录开始参与存储分布调度。这种设计，新增节点不需要移动任何文件，但是负载均衡 没有平滑处理，老节点负载较重。GlusterFS在设计中考虑了这一问题，在新建文件时会优先考虑容量负载最轻的节点，在目标存储节点上创建文件链接直向真正存储文件的节点。另外，GlusterFS弹性卷管理工具可以在后台以人工方式来执行负载平滑，将进行文件移动和重新分布，此后所有存储服务器都会均会被调度。 GlusterFS目前对存储节点删除支持有限，还无法做到完全无人干预的程度。如果直接删除节点，那么所在存储服务器上的文件将无法浏览和访问，创建文件目录也会失败。当前人工解决方法有两个，一是将节点上的数据重新复制到GlusterFS中，二是使用新的节点来替换删除节点并保持原有数据。 如果一个文件被改名，显然hash算法将产生不同的值，非常可能会发生文件被定位到不同的存储服务器上，从而导致文件访问失败。采用数据移动的方法，对于大文件是很难在实时完成的。为了不影响性能和服务中断，GlusterFS采 用了文件链接来解决文件重命名问题，在目标存储服务器上创建一个链接指向实际的存储服务器，访问时由系统解析并进行重定向。另外，后台同时进行文件迁移， 成功后文件链接将被自动删除。对于文件移动也作类似处理，好处是前台操作可实时处理，物理数据迁移置于后台选择适当时机执行。 弹性哈希算法为文件分配逻辑卷，那么GlusterFS如何为逻辑卷分配物理卷呢？GlusterFS3.1.X实现了真正的弹性卷管理，如图4所 示。存储卷是对底层硬件的抽象，可以根据需要进行扩容和缩减，以及在不同物理系统之间进行迁移。存储服务器可以在线增加和移除，并能在集群之间自动进行数 据负载平衡，数据总是在线可用，没有应用中断。文件系统配置更新也可以在线执行，所作配置变动能够快速动态地在集群中传播，从而自动适应负载波动和性能调 优。 ​ 弹性哈希算法本身并没有提供数据容错功能，GlusterFS使用镜像或复制来保证数据可用性，推荐使用镜像或3路复制。复制模式下，存储服务器使用同步写复制到其他的存储服务器，单个服务器故障完全对客户端透明。此外，GlusterFS没有对复制数量进行限制，读被分散到所有的镜像存储节点，可以提高读性能。弹性哈希算法分配文件到唯一的逻辑卷，而复制可以保证数据至少保存在两个不同存储节点，两者结合使得GlusterFS具备更高的弹性。 Translators如前所述，Translators是GlusterFS提供的一种强大文件系统功能扩展机制，这一设计思想借鉴于GNU/Hurd微内核操作系统。GlusterFS中所有的功能都通过Translator机制实现，运行时以动态库方式进行加载，服务端和客户端相互兼容。GlusterFS 3.1.X中，主要包括以下几类Translator： Cluster：存储集群分布，目前有AFR, DHT, Stripe三种方式 Debug：跟踪GlusterFS内部函数和系统调用 Encryption：简单的数据加密实现 Features：访问控制、锁、Mac兼容、静默、配额、只读、回收站等 Mgmt：弹性卷管理 Mount：FUSE接口实现 Nfs：内部NFS服务器 Performance：io-cache, io-threads, quick-read, read-ahead, stat-prefetch, sysmlink-cache, write-behind等性能优化 Protocol：服务器和客户端协议实现 Storage：底层文件系统POSIX接口实现 这里我们重点介绍一下Cluster Translators，它是实现GlusterFS集群存储的核心，它包括AFR（Automatic File Replication）、DHT（Distributed Hash Table）和Stripe三种类型。 AFR相当于RAID1，同一文件在多个存储节点上保留多份，主要用于实现高可用性以及数据自动修复。AFR所有子卷上具有相同的名字空间，查找文件时从第一个节点开始，直到搜索成功或最后节点搜索完毕。读数据时，AFR会把所有请求调度到所有存储节点，进行负载均衡以提高系统性能。写数据时，首先需要在所有锁服务器上对文件加锁，默认第一个节点为锁服务器，可以指定多个。然后，AFR以日志事件方式对所有服务器进行写数据操作，成功后删除日志并解锁。AFR会自动检测并修复同一文件的数据不一致性，它使用更改日志来确定好的数据副本。自动修复在文件目录首次访问时触发，如果是目录将在所有子卷上复制正确数据，如果文件不存则创建，文件信息不匹配则修复，日志指示更新则进行更新。 DHT即上面所介绍的弹性哈希算法，它采用hash方式进行数据分布，名字空间分布在所有节点上。查找文件时，通过弹性哈希算法进行，不依赖名字空间。但遍历文件目录时，则实现较为复杂和低效，需要搜索所有的存储节点。单一文件只会调度到唯一的存储节点，一旦文件被定位后，读写模式相对简单。DHT不具备容错能力，需要借助AFR实现高可用性, 如图5所示应用案例。 Stripe相当于RAID0，即分片存储，文件被划分成固定长度的数据分片以Round-Robin轮转方式存储在所有存储节点。Stripe所有存储节点组成完整的名字空间，查找文件时需要询问所有节点，这点非常低效。读写数据时，Stripe涉及全部分片存储节点，操作可以在多个节点之间并发执行，性能非常高。Stripe通常与AFR组合使用，构成RAID10/RAID01，同时获得高性能和高可用性，当然存储利用率会低于50%。 设计讨论GlusterFS是一个具有高扩展性、高性能、高可用性、可横向扩展的弹性分布式文件系统，在架构设计上非常有特点，比如无元数据服务器设计、堆栈式架构等。然而，存储应用问题是很复杂的，GlusterFS也不可能满足所有的存储需求，设计实现上也一定有考虑不足之处，下面我们作简要分析。 无元数据服务器 vs 元数据服务器 无元数据服务器设计的好处是没有单点故障和性能瓶颈问题，可提高系统扩展性、性能、可靠性和稳定性。对于海量小文件应用，这种设计能够有效解决元数据的难点 问题。它的负面影响是，数据一致问题更加复杂，文件目录遍历操作效率低下，缺乏全局监控管理功能。同时也导致客户端承担了更多的职能，比如文件定位、名字 空间缓存、逻辑卷视图维护等等，这些都增加了客户端的负载，占用相当的CPU和内存。 用户空间 vs 内核空间 用户空间实现起来相对要简单许多，对开发者技能要求较低，运行相对安全。用户空间效率低，数据需要多次与内核空间交换，另外GlusterFS借助FUSE来实现标准文件系统接口，性能上又有所损耗。内核空间实现可以获得很高的数据吞吐量，缺点是实现和调试非常困难，程序出错经常会导致系统崩溃，安全性低。纵向扩展上，内核空间要优于用户空间，GlusterFS有横向扩展能力来弥补。l 堆栈式 vs 非堆栈式 这有点像操作系统的微内核设计与单一内核设计之争。GlusterFS堆栈式设计思想源自GNU/Hurd微内核操作系统，具有很强的系统扩展能力，系统设计实现复杂性降低很多，基本功能模块的堆栈式组合就可以实现强大的功能。查看GlusterFS卷配置文件我们可以发现，translator功能树通常深达10层以上，一层一层进行调用，效率可见一斑。非堆栈式设计可看成类似Linux的单一内核设计，系统调用通过中断实现，非常高效。后者的问题是系统核心臃肿，实现和扩展复杂，出现问题调试困难。 原始存储格式 vs 私有存储格式 GlusterFS使 用原始格式存储文件或数据分片，可以直接使用各种标准的工具进行访问，数据互操作性好，迁移和数据管理非常方便。然而，数据安全成了问题，因为数据是以平凡的方式保存的，接触数据的人可以直接复制和查看。这对很多应用显然是不能接受的，比如云存储系统，用户特别关心数据安全，这也是影响公有云存储发展的一 个重要原因。私有存储格式可以保证数据的安全性，即使泄露也是不可知的。GlusterFS要实现自己的私有格式，在设计实现和数据管理上相对复杂一些，也会对性能产生一定影响。 大文件 vs 小文件 GlusterFS适合大文件还是小文件存储？弹性哈希算法和Stripe数据分布策略，移除了元数据依赖，优化了数据分布，提高数据访问并行性，能够大幅提高大文件存储的性能。对于小文件，无元数据服务设计解决了元数据的问题。但GlusterFS并没有在I/O方面作优化，在存储服务器底层文件系统上仍然是大量小文件，本地文件系统元数据访问是一个瓶颈，数据分布和并行性也无法充分发挥作用。因此，GlusterFS适合存储大文件，小文件性能较差，还存在很大优化空间。 可用性 vs 存储利用率 GlusterFS使用复制技术来提供数据高可用性，复制数量没有限制，自动修复功能基于复制来实现。可用性与存储利用率是一个矛盾体，可用性高存储利用率就低，反之亦然。采用复制技术，存储利用率为1/复制数，镜像是50%，三路复制则只有33%。其实，可以有方法来同时提高可用性和存储利用率，比如RAID5的利用率是(n-1)/n，RAID6是(n-2)/n，而纠删码技术可以提供更高的存储利用率。但是，鱼和熊掌不可得兼，它们都会对性能产生较大影响。另外，GlusterFS目前的代码实现不够好，系统不够稳定，BUGS数量相对还比较多。从其官方网站的部署情况来看，测试用户非常多，但是真正在生产环境中的应用较少，存储部署容量几TB－几十TB的占很大比率，数百TB－PB级案例非常少。这也可以从另一个方面说明，GlusterFS目前还不够稳定，需要更长的时间来检验。然而不可否认，GlusterFS是一个有着光明前景的集群文件系统，线性横向扩展能力使它具有天生的优势，尤其是对于云存储系统。 使用GlusterFS术语解释Brick ：GFS中的存储单元，通过是一个受信存储池中的服务器的一个导出目录。可以通过主机名和目录名来标识，如’SERVER:EXPORT’ Client ：挂载了GFS卷的设备 Extended Attributes:xattr 是一个文件系统的特性，其支持用户或程序关联文件/目录和元数据。 FUSE:Filesystem Userspace是一个可加载的内核模块，其支持非特权用户创建自己的文件系统而不需要修改内核代码。通过在用户空间运行文件系统的代码通过FUSE代码与内核进行桥接。 Geo-Replication GFID ：GFS卷中的每个文件或目录都有一个唯一的128位的数据相关联，其用于模拟inode Namespace ：每个Gluster卷都导出单个ns作为POSIX的挂载点 Node ：一个拥有若干brick的设备 RDMA：远程直接内存访问，支持不通过双方的OS进行直接内存访问。 RRDNS：round robin DNS是一种通过DNS轮转返回不同的设备以进行负载均衡的方法 Self-heal：用于后台运行检测复本卷中文件和目录的不一致性并解决这些不一致。 Split-brain：脑裂 Translator： Volfile：glusterfs进程的配置文件，通常位于/var/lib/glusterd/vols/volname Volume：一组bricks的逻辑集合 安装GlusterFS系统环境介绍 OS版本：CentOS Linux release 7.1.1503 (Core) 软件版本： 3.7.3（最新为3.7.10） 系统节点 ip地址 挂载路径 172.16.18.241 /export/brick1/gv0 172.16.18.242 /export/brick1/gv0 172.16.18.243 /export/brick1/gv0 172.16.18.244 /export/brick1/gv0 安装GlusterFS安装软件包12345// 下载GlusterFs yum源配置wget -P /etc/yum.repos.d http://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-epel.repo// 安装GlusterFSyum install -y glusterfs glusterfs-fuse glusterfs-server xfsprogs 配置开机启动1234#systemctl enable glusterfsd.servicesystemctl enable glusterd.servicesystemctl start glusterd#systemctl start glusterfsd 配置GlusterFS集群添加节点到GlusterFS集群12345678910111213141516171819202122232425//添加节点到存储池，在其中一个节点上操作 gluster peer probe 172.16.18.241peer probe: success: on localhost not needed gluster peer probe 172.16.18.242peer probe: successgluster peer probe 172.16.18.243peer probe: success gluster peer probe 172.16.18.244peer probe: success//查看各个节点状态gluster peer statusNumber of Peers: 3Hostname: 172.16.18.242Uuid: beb0aae7-a939-45ec-a273-0c21c2f59546State: Peer in Cluster (Connected)Hostname: 172.16.18.243Uuid: eab486b3-d1a1-4851-b9ec-45aab1ef9a66State: Peer in Cluster (Connected)Hostname: 172.16.18.244Uuid: 3108764d-d6b3-4356-810d-88872d56ceb6State: Peer in Cluster (Connected) 创建数据存储目录123456parted /dev/sdb rm 1mkfs.xfs -i size=512 /dev/sdb -fmkdir -p /export/brick1/bin/mount -t xfs /dev/sdb /export/brick1mkdir /export/brick1/gv0echo &quot;/dev/sdb /export/brick1 xfs defaults 1 2&quot; &gt;&gt; /etc/fstab 创建GlusterFS磁盘卷1234567891011121314151617181920212223// 创建系统卷gv0（副本卷）gluster volume create gv0 replica 2 172.16.18.241:/export/brick1/gv0 172.16.18.242:/export/brick1/gv0 172.16.18.243:/export/brick1/gv0 172.16.18.244:/export/brick1/gv0 force//启动系统卷gv0 gluster volume start gv0volume create: gv0: success: please start the volume to access data//查看系统卷信息gluster volume info Volume Name: gv0Type: Distributed-ReplicateVolume ID: e64cb61c-0f18-41b5-bf4d-c45ee085ca3bStatus: StartedNumber of Bricks: 2 x 2 = 4Transport-type: tcpBricks:Brick1: 172.16.18.241:/export/brick1/gv0Brick2: 172.16.18.242:/export/brick1/gv0Brick3: 172.16.18.243:/export/brick1/gv0Brick4: 172.16.18.244:/export/brick1/gv0Options Reconfigured:performance.readdir-ahead: on 安装客户端并mount GlusterFS文件系统1234567891011121314151617181920212223// 下载仓库文件wget -P /etc/yum.repos.d http://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-epel.repo//安装软件yum install glusterfs glusterfs-fuse glusterfs-server//创建挂载点mkdir -p /opt/vmx/gv0//client挂载/bin/mount -t glusterfs 172.16.18.241:/gv0 /opt/vmx/gv0df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/centos-root 50G 5.6G 45G 12% /devtmpfs 12G 0 12G 0% /devtmpfs 12G 12K 12G 1% /dev/shmtmpfs 12G 25M 12G 1% /runtmpfs 12G 0 12G 0% /sys/fs/cgroup/dev/mapper/centos-home 217G 33M 217G 1% /home/dev/sda1 497M 102M 395M 21% /boot/dev/sdb 280G 33M 280G 1% /export/brick1172.16.18.241:/gv0 559G 1.6G 558G 1% /opt/vmx/gv0 管理使用GlusterFSGluster节点管理在创建volume之前需要先将一组存储设备组成一个存储池，通过存储设备提供的bricks来组成卷。在设备上启动glusterd之后，可通过设备的主机名或IP地址，将设备加到存储池中。 1gluster peer command 节点状态123456789101112// 在任意节点操作，可以看到其他节点与本节点的连接状态gluster peer statusNumber of Peers: 3Hostname: 172.16.18.242Uuid: beb0aae7-a939-45ec-a273-0c21c2f59546State: Peer in Cluster (Connected)Hostname: 172.16.18.243Uuid: eab486b3-d1a1-4851-b9ec-45aab1ef9a66State: Peer in Cluster (Connected)Hostname: 172.16.18.244Uuid: 3108764d-d6b3-4356-810d-88872d56ceb6State: Peer in Cluster (Connected) 添加节点命令：gluster peer HostName 12// 将节点server添加到存储池中gluster peer prober server 删除节点命令： gluster peer detach HostName 12// 将节点server从存储池中移除，移除节点时要保证节点上没有brick，需要提前移除brickgluster peer detch server gluster对于每个节点都会生成一个UUID来标识，因此如果节点的IP或主机名发生了变化，只需要重新执行peer probe即可。不过如果一个主机名曾经用过，想再改回去，则gluster会提示已经保存过。此时只能把节点detach掉，然后重新probe。 Gluster卷管理Gluster文件系统基于需求支持不同类型的卷类型。有些卷类型有益于扩展存储大小、一些可以提高性能、还有可以兼顾两者。 卷的类型 Distributed Glusterfs Volume（分布卷） 这个是GlusterFS文件系统默认的卷类型，文件通过hash算法随机的分布到由bricks组成的卷上，因此不存在数据冗余。对于这样一个存储卷的优点是磁盘容量扩展强和使用率高。但是这也意味着一个brick损坏将导致数据丢失，除非brick底层使用硬件Raid等外部冗余措施。 Replicated Glusterfs Volume（镜像卷、副本卷） 镜像卷类似raid1，解决了数据冗余问题，在创建时指定副本数量，副本在存储时会存放到不同brick上， 因此，有几个复本就必须提供至少多个brick。 注意：在创建复本卷时，brick数量与复本个数必须相等；否则将会报错。另外如果同一个节点提供了多个brick，也可以在同一个结点上创建复本卷，但这并不安全，因为一台设备挂掉，其上面的所有brick就无法访问了。 Striped Glusterfs Volume（条带卷） 类似与raid0，但是考虑一个大文件被存储在一个brick，许多客户在同一时间经常访问。这将导致单个brick过多的负载并会降低性能。带区卷数据存储在砖后将它划分为不同的条纹，将大文件将被分为小块(等于brick的数量体积),每个块都存储在一个brick。实现负载分布和文件可以获取更快读取速度，但不提供数据冗余。 Distributed Replicated Glusterfs Volume（分布式复制卷） 此类型卷是基本复本卷的扩展,兼顾分布卷和复制卷的功能。，可以指定若干brick组成一个复本卷，另外若干brick组成另个复本卷。单个文件在复本卷内数据保持复制，不同文件在不同复本卷之间进行分布。 Striped Glusterfs Volume（分布式条带卷） volume中brick所包含的存储服务器数必须是stripe的倍数(&gt;=2倍)，兼顾分布式和条带式的功能。 其他拓展卷 创建卷 创建分布式卷(DHT) 123// DHT卷将数据以哈希计算方式分布到各个brick上，数据是以文件为单位存取，基本达到分布均衡，提供的容量为各个brick的容量总和gluster volume create NEW-VOLNAME [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...gluster volume create dht_vol 172.16.18.&#123;241,242,243,244&#125;:/export/brick1/gv0 创建副本卷(AFR) 123// AFR提供数据副本，副本数为replica，即每个文件存储replica份数，文件不分割，以文件为存储单位：副本数需要等于brick数；当brick数是副本的倍数时，则自动变化为Replicated-Distributed卷gluster volume create NEW-VOLNAME [replica COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...gluster volume create afr_vol replica 2 [transport tcp] 172.16.18.&#123;241,242,243,244&#125;:/export/brick/gv0 每两个brick组成一组，每组两个副本，文件又以DHT分布在三个组上，这样是副本卷和分布式卷的组合 创建条带卷 123//stripe卷类似raid0，将数据条带化，分布在不同的brick，该方式将文件分块，将文件分成stripe块，分别进行存储，在大文件读取是有优势。stripe需要等于brick数；当brick数等于stripe数的倍数时，则自动变化为stripe-distributed卷。gluster volume create NEW-VOLNAME [stripe COUNT] [transport [tcp | dma | tcp,rdma]] NEW-BRICK...gluster volume create str_vol stripe 2 172.16.18.&#123;241,242,243,244&#125;:/export/brick1/gv0 每2个brick组成一组，每组2个brick，文件以DHT分布在两个组中，每个组中将文件条带成2块 创建Replicated-Stripe-Distributed卷 12//使用8个brick创建一个组合卷，即brick数是stripe*replica的倍数，则创建三种基本卷的组合卷，若刚好等于stripe*replica则为stript-Distrubted卷gluster volume create str_afr_dht_vol stripe 2 replica 2 172.16.18.&#123;241,242,243,244&#125;:/export/brick1/gv0 172.16.18.&#123;241,242,243,244&#125;:/export/brick1/gv1 卷信息命令：gluster volume info12345678910111213141516// 该命令能够查看存储池中当前卷的信息，包括卷方式、包含的brick、卷的当期状态、卷名及UUID等gluster volume info Volume Name: gv0Type: Distributed-ReplicateVolume ID: e64cb61c-0f18-41b5-bf4d-c45ee085ca3bStatus: StartedNumber of Bricks: 2 x 2 = 4Transport-type: tcpBricks:Brick1: 172.16.18.241:/export/brick1/gv0Brick2: 172.16.18.242:/export/brick1/gv0Brick3: 172.16.18.243:/export/brick1/gv0Brick4: 172.16.18.244:/export/brick1/gv0Options Reconfigured:performance.readdir-ahead: on 卷状态命令： gluster volume status1234567891011121314151617181920212223// 该命令能够查看当前卷的状态，包括其中各个brick的状态、NFS的服务状态及当前task执行情况和一些系统设置状态等gluster volume statusStatus of volume: gv0Gluster process TCP Port RDMA Port Online Pid------------------------------------------------------------------------------Brick 172.16.18.241:/export/brick1/gv0 49152 0 Y 1970Brick 172.16.18.242:/export/brick1/gv0 49152 0 Y 9547Brick 172.16.18.243:/export/brick1/gv0 49152 0 Y 1800Brick 172.16.18.244:/export/brick1/gv0 49152 0 Y 9741NFS Server on localhost N/A N/A N N/A Self-heal Daemon on localhost N/A N/A Y 2605NFS Server on 172.16.18.244 N/A N/A N N/A Self-heal Daemon on 172.16.18.244 N/A N/A Y 15386NFS Server on 172.16.18.243 N/A N/A N N/A Self-heal Daemon on 172.16.18.243 N/A N/A Y 1794NFS Server on 172.16.18.242 N/A N/A N N/A Self-heal Daemon on 172.16.18.242 N/A N/A Y 1966Task Status of Volume gv0------------------------------------------------------------------------------Task : Rebalance ID : fad4f770-87dd-4248-b41e-733641c8bccaStatus : completed 启动、停止卷命令： gluster volume start/stop VOLNAME123// 将创建的卷启动，才能进行客户端挂载；stop能够将系统将停止；此外gluster并未提供restart的重启命令gluster volume start gv0volume create: gv0: success: please start the volume to access data 删除卷命令：gluster volume delete VOLNAME 123// 删除卷的操作能够将整个卷删除，操作前需要将卷先停止gluster volume stop gv0gluster volume delete gv0 均衡卷123456\\ 不迁移数据gluster volume gv0 rebalance fix-layout startgluster volume gv0 rebalance startgluster volume gv0 rebalance startforcegluster volume gv0 rebalance statusgluster volume gv0 rebalance stop 修复卷 1234gluster volume heal mamm-volume #只修复有问题的文件 gluster volume heal mamm-volume full #修复所有文件 gluster volume heal mamm-volume info#查看自愈详情 gluster volume heal mamm-volume info healed|heal-failed|split-brain 设置卷 命令：gluster volume set options 设置卷传输端口类型 Unmount the volume on all the clients using the following command: 1# umount mount-point Stop the volumes using the following command: 1# gluster volume stop volname Change the transport type. For example, to enable both tcp and rdma execute the followimg command: 1# gluster volume set volname config.transport tcp,rdma OR tcp OR rdma Mount the volume on all the clients. For example, to mount using rdma transport, use the following command: 1# mount -t glusterfs -o transport=rdma server1:/test-volume /mnt/glusterfs Brick管理添加brick命令：gluster volume add-brick VOLNAME NEW-BRICK1234//添加两个brick到存储gv0，副本卷则要一次添加的bricks数是replica的整数倍；stripe同样要求gluster peer probe 172.16.18.245gluster peer probe 172.16.18.246gluster volume add-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 移除brick命令： gluster volume remove-brick VOLNAME BRICK start/status/commit12345678// 若是副本卷，则要移除的Brick是replica的整数倍，stripe具有同样的要求，副本卷要移除一对Brick，在执行移除操作时，数据会移到其他节点。gluster volume remove-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 start// 在执行移除操作后，可以使用status命令进行task状态查看gluster volume remove-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 status// 使用commit命令执行brick移除，则不会进行数据迁移而直接删除brick，符合不需要数据迁移的用户需求gluster volume remove-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 commit ps：系统的扩容及缩减可以通过如上的节点、brick管理组合达到目的1. 扩容时，可以下增加系统节点，然后添加新增节点上的brick即可2. 缩减时，可以先移除brick，然后在进行节点删除达到缩减的目的，并保证不丢失数据 替换brick命令：gluster volume replace-brick VOLNAME BRICKNEW-BRICK start/pause/sbort/status/commit 1234567891011// 将172.16.18.244：/export/brick1/gv0替换为172.16.18.245:/export/brick1/gv0。在执行replcase-brick，使用start启动命令之后，开始将原始brick的数据迁移到即将需要替换的brick上gluster volume replace-brick gv0 172.16.18.244:/export/brick1/gv0 172.16.18.245:/export/brick1/gv0 start force//在数据迁移过程中，可以查看替换状态gluster volume replace-brick gv0 172.16.18.244:/export/brick1/gv0 172.16.18.245:/export/brick1/gv0 status// 在数据迁移的过程中，可以执行abort命令终止brick替换gluster volume replace-brick gv0 172.16.18.244:/export/brick1/gv0 172.16.18.245:/export/brick1/gv0 abort//当数据迁移结束之后，执行commit命令结束任务，则进行brick替换。使用volume info命令可以查看到brick已经被替换gluster volume replace-brick gv0 172.16.18.244:/export/brick1/gv0 172.16.18.245:/export/brick1/gv0 start 系统拓展系统配额开启、关闭系统配额12//在使用系统配额功能时，需要使用enable将其开启；disable为关闭命令gluster volume quota VOLNAME enable/disable 设置目录配额1234gluster volume quota VOLNAME limit-usage /directory limit-value//设置gv0卷下quota子目录目录限额为10GB，这个目录是以系统挂载目录为根目录，所以/quota即客户端挂载目录下的子目录gluster volume quota gv0 limit-usage /quota 10GB 配额查看1234gluster volume quota VOLNAME listgluster volume quota VOLNAME list /directory_name//可以使用上面命令查看卷的配额，第一个查看全部配额设置，第二个可以根据目录查看，显示配额大小及当前使用容量，如无使用容量则说明设置的目录有误(不存在)gluster volume quota gv0 list 地域复制(geo-replication)123456gluster volume geo-replication MASTER SLAVE start/status/stop//地域复制是系统提供的灾备功能，能够将系统的全部数据进行异步的增量备份到另外的磁盘中gluster volume geo-replication gv0 172.16.18.250:/export/brick/gv0 start//当开始执行gv0卷的所有内容备份到18.250下的/export/brick/gv0中的task，值得注意的是，这个备份目标不能是系统中的brick I/O信息查看profile command提供了一个接口查看每个卷中的每个brick的io信息12345678// 启动profiling，之后便可以进行io查看gluster volume profile VOLNAME start// 查看io信息，可以查看到每个brick的io信息gluster volume profile VOLNAME info// 管理profilinig功能gluster volume profile VOLNAME stop top监控top command允许你查看bricks的性能，read、write、file open calls、file read caclls、file write calls、directory open calls、directory read calls。所有的查看都可以设置top数，默认是1000123456789101112131415161718// 查看打开的fdgluster volume top VOLNAME open [brick BRICK-NAME] [list-cnt cnt]// 查看调用次数最多的读调用gluster volume top VOLNAME read [brick BRICK-NAME] [list-cnt cnt]// 查看调用次数最多的写调用gluster volume top VOLNAME write [brick BRICK-NAME] [list-cnt cnt]// 查看次数最多的目录调用gluster volume top opendir [brick BRICK-NAME] [list-cnt cnt]gluster volume top readdir [brick BRICK-NAME] [list-cnt cnt]//查看每个brick的读性能gluster volume top VOLNAME read-perf [bs blk-size count count] [brick BRICK-NAME] [list-cnt cnt]//查看每个brick的写性能gluster volume top VOLNAME write-perf [bs blk-size count count] [brick BRICK-NAME] [list-cnt cnt] Glusterfs冗余镜像（AFR）修复原理以及脑裂分析什么是脑裂所谓脑裂，就是指两个或多个节点都“认为”自身是正常节点而互相“指责”对方，导致不能选取正确的节点进行接管或修复，导致脑裂状态。这种现象出现在数据修复、集群管理等等高可用场景。Glusterfs的冗余镜像（下文简称AFR）提供了数据副本功能，能够在即使只有一个冗余节点的情况下仍能正常工作，不中断上层应用。当节点恢复后，能够将数据修复到一致状态，保证数据的安全。 AFR工作原理 AFR数据修复主要涉及三个方面：ENTRY，META，DATA，我们以冗余度为2即含有两个副本A和B的DATA修复为例进行讲解。记录描述副本状态的称之为ChangeLog，记录在每个副本文件扩展属性里，读入内存后以矩阵形式判断是否需要修复以及要以哪个副本为Source进行修复。初始值以及正常值为0.（注：ENTRY和META,DATA分布对应着一个数值）。 Write的步骤可分解为： 下发Write操作 加锁Lock 向A，B副本的ChangeLog分别加1，记录到各个副本的扩展属性中 对A，B副本进行写操作 若该副本写成功则ChangeLog减1，若该副本写失败则ChangLog值不变，记录到各个副本的扩展属性中 解锁UnLock 向上层返回，只要有一个副本写成功就返回成功。 上述在AFR中是完整的一个transaction动作。根据两个副本记录的ChangeLog的数值确定了副本的几种状态： WISE，智慧的，即该副本的ChangeLog中对方对应的数值大于0而且自身对应的数值等于0. INNOCENT，无辜的，即该副本上的ChangeLog即不指责对方也指责自己，ChangeLog全为0. FOOL，愚蠢的，即该副本上的ChangeLog是指责自己的。 IGNORANT，忽略的，即该副本的ChangeLog丢失。 所以一般情况下，会选取WISE的副本作为Sourse进行修复。但是当两个节点都是WISE状态时，这就出现了声名狼藉的脑裂状态。 AFR脑裂 两个副本均为WISE时发生脑裂，那么在哪种场景下会产生脑裂呢？我们还是以冗余度为2的情况举一个简单的例子：某文件X的两个副本位于物理机A和物理机B上，在A和B上分别运行着进程a和进程b，a和b持续通过各自所在的物理机上的客户端对文件X进行不同的写操作。然后物理机A和B之间网络中断，因为AFR在一个副本的情况下仍能不中断上层应用，所以进程a和进程b仍会持续运行，但因为网络中断，文件X在A和B上的副本数据不再一致且都认为对方是异常的，当网络恢复时，两个副本互相“指责”，即出现了脑裂。当然这是脑裂发生的场景之一，有时候是有可能发生脑裂，而有时候是必然发生脑裂。 官方提供解决方案 参考文献官方文档:http://gluster.readthedocs.org/en/latest/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SaltStack--Grains]]></title>
      <url>http://czero000.github.io/2016/04/01/saltstack-grains.html</url>
      <content type="text"><![CDATA[什么是GrainsGrains是SaltStack组件中非常重要的组件，在实际使部署配置中会经常使用到grains。Grains与Puppet中facter功能类似，存放minion启动时收集的静态信息，也可以理解为Grains记录每台minion的常用属性，例如CPU、内存、硬盘、网络等，在下次启动minion之前，grains收集的数据不会改变所以称之为静态信息。我们可以通过grains.items查看某台或多台minion的grains信息。grains信息是在每台minion在启动时上报到master，在实际应用中，经常会根据实际业务需求，自定义grains，自定义grains方法如下： 通过minion配置文件定义 通过grains相关模块定义 通过python脚本定义 Grains常用操作1234567891011121314151617salt &apos;172.16.11.211&apos; sys.list_functions grains172.16.11.211: - grains.append - grains.delval - grains.filter_by - grains.get - grains.get_or_set_hash - grains.has_value - grains.item - grains.items - grains.ls - grains.remove - grains.setval - grains.setvalssalt &apos;*&apos; grains.ls //列出可用的grains salt &apos;*&apos; grains.items //列出所有grains的名称和内容 定义Grains通过minion配置文件通过文件定义Grains，有三种格式符合YAML格式的 Key:value：os:CentOS 字典格式:ip_interfaces: {&#39;lo&#39;: [&#39;127.0.0.1&#39;], &#39;em1&#39;: [&#39;172.16.11.211&#39;], em2: []} 多分行列表： 123osmajorrrelease: 6 5 修改minion配置文件，将default_include: minion.d/*.conf取消注释，并在/etc/salt/minion.d/添加grains配置文件 1234567grains: //官方示例 roles: - webserver - memcache deployment: datacenter4 cabinet: 13 cab_u: 14-15 重启minion，使自定义grains生效 1234567salt &apos;172.16.11.211&apos; grains.item roles172.16.11.211: ---------- roles: - webserver - memcache// 可以看到自定义的grainis已经生效 通过grains模块定义 设置自定义granins 1234567891011salt &apos;172.16.11.211&apos; grains.append salt &apos;Hello World&apos; //自定义granins172.16.11.211: ---------- salt: - Hello Worldsalt &apos;172.16.11.211&apos; grains.item salt // 查看grains172.16.11.211: ---------- salt: - Hello World 使用Grains.setvals同时设置多个grains 1234567salt &apos;172.16.11.211&apos; grains.setvals &quot;&#123;&apos;Salt&apos;: &apos;Hello&apos;, &apos;Stack&apos;: &apos;World&apos;&#125;&quot;172.16.11.211: ---------- Salt: Hello Stack: World 在_grains目录定义grains 使用默认的master的file_root配置路径 /srv/salt，那么_grains的位置是/srv/salt/_grains，添加自定义grains item，注意的是python脚本返回值是一个字典。 12345678910111213141516// 脚本内容def my_grains(): grains = &#123;&apos;zero&apos; : [&apos;HelloWorld&apos;]&#125; return grains//推送_grains内模块到minionsalt &apos;*&apos; saltutil.sync_grains// 查看新増grains salt &apos;*&apos; grains.item zero172.16.11.211: ---------- zero: - HelloWorld//重新加载模块，刷新grains静态数据salt &apos;*&apos; sys.reload_modules 在minin的/var/cache/salt/minion/extmods/grains目录下，可以找到master下发的grains文件 删除自定义granins 1salt &apos;172.16.11.211&apos; grains.remove salt &apos;Hello SaltStack&apos;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Markdown简明语法说明]]></title>
      <url>http://czero000.github.io/2016/04/01/markdown-syntax.html</url>
      <content type="text"><![CDATA[什么是 MarkdownMarkdown 是一种轻量级标记语言，创始人为约翰·格鲁伯（John Gruber）。它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的 XHTML (或者 HTML )文档”。目前被越来越多的写作爱好者、撰稿者广泛使用。 Markdown语法说明http://github.com/riku/Markdown-Syntax-CN/blob/master/syntax.md 概述 宗旨 兼容 HTML 特殊字符自动转换 区块元素 段落和换行 标题 区块引用 列表 代码区块 分隔线 区段元素 链接 强调 代码 图片 其它 反斜杠 自动链接 感谢 Markdown 免费编辑器 概述宗旨 Markdown 的目标是实现「易读易写」。 可读性，无论如何，都是最重要的。一份使用 Markdown 格式撰写的文件应该可以直接以纯文本发布，并且看起来不会像是由许多标签或是格式指令所构成。Markdown 语法受到一些既有 text-to-HTML 格式的影响，包括 Setext、atx、Textile、reStructuredText、Grutatext 和 EtText，而最大灵感来源其实是纯文本电子邮件的格式。 总之， Markdown 的语法全由一些符号所组成，这些符号经过精挑细选，其作用一目了然。比如：在文字两旁加上星号，看起来就像*强调*。Markdown 的列表看起来，嗯，就是列表。Markdown 的区块引用看起来就真的像是引用一段文字，就像你曾在电子邮件中见过的那样。 兼容 HTML Markdown 语法的目标是：成为一种适用于网络的书写语言。 Markdown 并不是想取代 HTML的地位，甚至接近它。它的语法种类很少，只对应 HTML 标记的一小部分。Markdown 的构想不是要使得 HTML 文档更容易书写。在我看来， HTML 已经很容易写了。Markdown 的理念是，能让文档更容易读、写和随意改。HTML 是一种发布的格式，Markdown 是一种书写的格式。就这样，Markdown 的格式语法只涵盖纯文本可以涵盖的范围。 不在 Markdown 涵盖范围之内的标签，都可以直接在文档里面用 HTML 撰写。不需要额外标注这是 HTML 或是 Markdown；只要直接加标签就可以了。 要制约的只有一些 HTML 区块元素――比如 &lt;div&gt;、&lt;table&gt;、&lt;pre&gt;、&lt;p&gt; 等标签，必须在前后加上空行与其它内容区隔开，还要求它们的开始标签与结尾标签不能用制表符或空格来缩进。Markdown 的生成器有足够智能，不会在 HTML 区块标签外加上不必要的 &lt;p&gt; 标签。 例子如下，在 Markdown 文件里加上一段 HTML 表格： 这是一个普通段落。 &lt;table&gt; &lt;tr&gt; &lt;td&gt;Foo&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 这是另一个普通段落。 请注意，在 HTML 区块标签间的 Markdown 格式语法将不会被处理。比如，你在 HTML 区块内使用 Markdown 样式的*强调*会没有效果。 HTML 的区段（行内）标签如 &lt;span&gt;、&lt;cite&gt;、&lt;del&gt; 可以在 Markdown 的段落、列表或是标题里随意使用。依照个人习惯，甚至可以不用 Markdown 格式，而直接采用 HTML 标签来格式化。举例说明：如果比较喜欢 HTML 的 &lt;a&gt; 或 &lt;img&gt; 标签，可以直接使用这些标签，而不用 Markdown 提供的链接或是图像标签语法。 和处在 HTML 区块标签间不同，Markdown 语法在 HTML 区段标签间是有效的。 特殊字符自动转换 在 HTML 文件中，有两个字符需要特殊处理： &lt; 和 &amp; 。 &lt; 符号用于起始标签，&amp; 符号则用于标记 HTML 实体，如果你只是想要显示这些字符的原型，你必须要使用实体的形式，像是 &amp;lt; 和 &amp;amp;。 &amp; 字符尤其让网络文档编写者受折磨，如果你要打「AT&amp;T」 ，你必须要写成「AT&amp;amp;T」。而网址中的 &amp; 字符也要转换。比如你要链接到： http://images.google.com/images?num=30&amp;q=larry+bird 你必须要把网址转换写为： http://images.google.com/images?num=30&amp;amp;q=larry+bird 才能放到链接标签的 href 属性里。不用说也知道这很容易忽略，这也可能是 HTML 标准检验所检查到的错误中，数量最多的。 Markdown 让你可以自然地书写字符，需要转换的由它来处理好了。如果你使用的 &amp; 字符是 HTML 字符实体的一部分，它会保留原状，否则它会被转换成 &amp;amp;。 所以你如果要在文档中插入一个版权符号 ©，你可以这样写： &amp;copy; Markdown 会保留它不动。而若你写： AT&amp;T Markdown 就会将它转为： AT&amp;amp;T 类似的状况也会发生在 &lt; 符号上，因为 Markdown 允许 兼容 HTML ，如果你是把 &lt; 符号作为 HTML 标签的定界符使用，那 Markdown 也不会对它做任何转换，但是如果你写： 4 &lt; 5 Markdown 将会把它转换为： 4 &amp;lt; 5 不过需要注意的是，code 范围内，不论是行内还是区块， &lt; 和 &amp; 两个符号都一定会被转换成 HTML 实体，这项特性让你可以很容易地用 Markdown 写 HTML code （和 HTML 相对而言， HTML 语法中，你要把所有的 &lt; 和 &amp; 都转换为 HTML 实体，才能在 HTML 文件里面写出 HTML code。） 区块元素 段落和换行 一个 Markdown 段落是由一个或多个连续的文本行组成，它的前后要有一个以上的空行（空行的定义是显示上看起来像是空的，便会被视为空行。比方说，若某一行只包含空格和制表符，则该行也会被视为空行）。普通段落不该用空格或制表符来缩进。 「由一个或多个连续的文本行组成」这句话其实暗示了 Markdown 允许段落内的强迫换行（插入换行符），这个特性和其他大部分的 text-to-HTML 格式不一样（包括 Movable Type 的「Convert Line Breaks」选项），其它的格式会把每个换行符都转成 &lt;br /&gt; 标签。 如果你确实想要依赖 Markdown 来插入 &lt;br /&gt; 标签的话，在插入处先按入两个以上的空格然后回车。 的确，需要多费点事（多加空格）来产生 &lt;br /&gt; ，但是简单地「每个换行都转换为 &lt;br /&gt;」的方法在 Markdown 中并不适合， Markdown 中 email 式的 区块引用 和多段落的 列表 在使用换行来排版的时候，不但更好用，还更方便阅读。 标题 Markdown 支持两种标题的语法，类 Setext 和类 atx 形式。 类 Setext 形式是用底线的形式，利用 = （最高阶标题）和 - （第二阶标题），例如： This is an H1 ============= This is an H2 ------------- 任何数量的 = 和 - 都可以有效果。 类 Atx 形式则是在行首插入 1 到 6 个 # ，对应到标题 1 到 6 阶，例如： # 这是 H1 ## 这是 H2 ###### 这是 H6 你可以选择性地「闭合」类 atx 样式的标题，这纯粹只是美观用的，若是觉得这样看起来比较舒适，你就可以在行尾加上 #，而行尾的 # 数量也不用和开头一样（行首的井字符数量决定标题的阶数）： # 这是 H1 # ## 这是 H2 ## ### 这是 H3 ###### 区块引用 Blockquotes Markdown 标记区块引用是使用类似 email 中用 &gt; 的引用方式。如果你还熟悉在 email 信件中的引言部分，你就知道怎么在 Markdown 文件中建立一个区块引用，那会看起来像是你自己先断好行，然后在每行的最前面加上 &gt; ： &gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, &gt; consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. &gt; Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. &gt; &gt; Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse &gt; id sem consectetuer libero luctus adipiscing. Markdown 也允许你偷懒只在整个段落的第一行最前面加上 &gt; ： &gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. &gt; Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. 区块引用可以嵌套（例如：引用内的引用），只要根据层次加上不同数量的 &gt; ： &gt; This is the first level of quoting. &gt; &gt; &gt; This is nested blockquote. &gt; &gt; Back to the first level. 引用的区块内也可以使用其他的 Markdown 语法，包括标题、列表、代码区块等： &gt; ## 这是一个标题。 &gt; &gt; 1. 这是第一行列表项。 &gt; 2. 这是第二行列表项。 &gt; &gt; 给出一些例子代码： &gt; &gt; return shell_exec(&quot;echo $input | $markdown_script&quot;); 任何像样的文本编辑器都能轻松地建立 email 型的引用。例如在 BBEdit 中，你可以选取文字后然后从选单中选择增加引用阶层。 列表 Markdown 支持有序列表和无序列表。 无序列表使用星号、加号或是减号作为列表标记： * Red * Green * Blue 效果就是 red green blue 等同于： + Red + Green + Blue 也等同于： - Red - Green - Blue 有序列表则使用数字接着一个英文句点： 1. Bird 2. McHale 3. Parish 很重要的一点是，你在列表标记上使用的数字并不会影响输出的 HTML 结果，上面的列表所产生的 HTML 标记为： &lt;ol&gt; &lt;li&gt;Bird&lt;/li&gt; &lt;li&gt;McHale&lt;/li&gt; &lt;li&gt;Parish&lt;/li&gt; &lt;/ol&gt; 如果你的列表标记写成： 1. Bird 1. McHale 1. Parish 或甚至是： 3. Bird 1. McHale 8. Parish 你都会得到完全相同的 HTML 输出。重点在于，你可以让 Markdown 文件的列表数字和输出的结果相同，或是你懒一点，你可以完全不用在意数字的正确性。 如果你使用懒惰的写法，建议第一个项目最好还是从 1. 开始，因为 Markdown 未来可能会支持有序列表的 start 属性。 列表项目标记通常是放在最左边，但是其实也可以缩进，最多 3 个空格，项目标记后面则一定要接着至少一个空格或制表符。 要让列表看起来更漂亮，你可以把内容用固定的缩进整理好： * Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. * Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. 但是如果你懒，那也行： * Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. * Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. 如果列表项目间用空行分开，在输出 HTML 时 Markdown 就会将项目内容用 &lt;p&gt;标签包起来，举例来说： * Bird * Magic 会被转换为： &lt;ul&gt; &lt;li&gt;Bird&lt;/li&gt; &lt;li&gt;Magic&lt;/li&gt; &lt;/ul&gt; 但是这个： * Bird * Magic 会被转换为： &lt;ul&gt; &lt;li&gt;&lt;p&gt;Bird&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Magic&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; 列表项目可以包含多个段落，每个项目下的段落都必须缩进 4 个空格或是 1 个制表符： 1. This is a list item with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit. 2. Suspendisse id sem consectetuer libero luctus adipiscing. 如果你每行都有缩进，看起来会看好很多，当然，再次地，如果你很懒惰，Markdown 也允许： * This is a list item with two paragraphs. This is the second paragraph in the list item. You&apos;re only required to indent the first line. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. * Another item in the same list. 如果要在列表项目内放进引用，那 &gt; 就需要缩进： * A list item with a blockquote: &gt; This is a blockquote &gt; inside a list item. 如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符： * 一列表项包含一个列表区块： &lt;代码写在这&gt; 当然，项目列表很可能会不小心产生，像是下面这样的写法： 1986. What a great season. 换句话说，也就是在行首出现数字-句点-空白，要避免这样的状况，你可以在句点前面加上反斜杠。 1986\. What a great season. 代码区块 和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 &lt;pre&gt; 和 &lt;code&gt; 标签来把代码区块包起来。 要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以，例如，下面的输入： 这是一个普通段落： 这是一个代码区块。 Markdown 会转换成： &lt;p&gt;这是一个普通段落：&lt;/p&gt; &lt;pre&gt;&lt;code&gt;这是一个代码区块。 &lt;/code&gt;&lt;/pre&gt; 这个每行一阶的缩进（4 个空格或是 1 个制表符），都会被移除，例如： Here is an example of AppleScript: tell application &quot;Foo&quot; beep end tell 会被转换为： &lt;p&gt;Here is an example of AppleScript:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;tell application &quot;Foo&quot; beep end tell &lt;/code&gt;&lt;/pre&gt; 一个代码区块会一直持续到没有缩进的那一行（或是文件结尾）。 在代码区块里面， &amp; 、 &lt; 和 &gt; 会自动转成 HTML 实体，这样的方式让你非常容易使用 Markdown 插入范例用的 HTML 原始码，只需要复制贴上，再加上缩进就可以了，剩下的 Markdown 都会帮你处理，例如： &lt;div class=&quot;footer&quot;&gt; &amp;copy; 2004 Foo Corporation &lt;/div&gt; 会被转换为： &lt;pre&gt;&lt;code&gt;&amp;lt;div class=&quot;footer&quot;&amp;gt; &amp;amp;copy; 2004 Foo Corporation &amp;lt;/div&amp;gt; &lt;/code&gt;&lt;/pre&gt; 代码区块中，一般的 Markdown 语法不会被转换，像是星号便只是星号，这表示你可以很容易地以 Markdown 语法撰写 Markdown 语法相关的文件。 分隔线 你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线： * * * *** ***** - - - --------------------------------------- 区段元素 链接 Markdown 支持两种形式的链接语法： 行内式和参考式两种形式。 不管是哪一种，链接文字都是用 [方括号] 来标记。 要建立一个行内式的链接，只要在方块括号后面紧接着圆括号并插入网址链接即可，如果你还想要加上链接的 title 文字，只要在网址后面，用双引号把 title 文字包起来即可，例如： This is [an example](http://example.com/ &quot;Title&quot;) inline link. [This link](http://example.net/) has no title attribute. 会产生： &lt;p&gt;This is &lt;a href=&quot;http://example.com/&quot; title=&quot;Title&quot;&gt; an example&lt;/a&gt; inline link.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;http://example.net/&quot;&gt;This link&lt;/a&gt; has no title attribute.&lt;/p&gt; 如果你是要链接到同样主机的资源，你可以使用相对路径： See my [About](/about/) page for details. 参考式的链接是在链接文字的括号后面再接上另一个方括号，而在第二个方括号里面要填入用以辨识链接的标记： This is [an example][id] reference-style link. 你也可以选择性地在两个方括号中间加上一个空格： This is [an example] [id] reference-style link. 接着，在文件的任意处，你可以把这个标记的链接内容定义出来： [id]: http://example.com/ &quot;Optional Title Here&quot; 链接内容定义的形式为： 方括号（前面可以选择性地加上至多三个空格来缩进），里面输入链接文字 接着一个冒号 接着一个以上的空格或制表符 接着链接的网址 选择性地接着 title 内容，可以用单引号、双引号或是括弧包着 下面这三种链接的定义都是相同： [foo]: http://example.com/ &quot;Optional Title Here&quot; [foo]: http://example.com/ &apos;Optional Title Here&apos; [foo]: http://example.com/ (Optional Title Here) 请注意：有一个已知的问题是 Markdown.pl 1.0.1 会忽略单引号包起来的链接 title。 链接网址也可以用尖括号包起来： [id]: &lt;http://example.com/&gt; &quot;Optional Title Here&quot; 你也可以把 title 属性放到下一行，也可以加一些缩进，若网址太长的话，这样会比较好看： [id]: http://example.com/longish/path/to/resource/here &quot;Optional Title Here&quot; 网址定义只有在产生链接的时候用到，并不会直接出现在文件之中。 链接辨别标签可以有字母、数字、空白和标点符号，但是并不区分大小写，因此下面两个链接是一样的： [link text][a] [link text][A] 隐式链接标记功能让你可以省略指定链接标记，这种情形下，链接标记会视为等同于链接文字，要用隐式链接标记只要在链接文字后面加上一个空的方括号，如果你要让 “Google” 链接到 google.com，你可以简化成： [Google][] 然后定义链接内容： [Google]: http://google.com/ 由于链接文字可能包含空白，所以这种简化型的标记内也许包含多个单词： Visit [Daring Fireball][] for more information. 然后接着定义链接： [Daring Fireball]: http://daringfireball.net/ 链接的定义可以放在文件中的任何一个地方，我比较偏好直接放在链接出现段落的后面，你也可以把它放在文件最后面，就像是注解一样。 下面是一个参考式链接的范例： I get 10 times more traffic from [Google] [1] than from [Yahoo] [2] or [MSN] [3]. [1]: http://google.com/ &quot;Google&quot; [2]: http://search.yahoo.com/ &quot;Yahoo Search&quot; [3]: http://search.msn.com/ &quot;MSN Search&quot; 如果改成用链接名称的方式写： I get 10 times more traffic from [Google][] than from [Yahoo][] or [MSN][]. [google]: http://google.com/ &quot;Google&quot; [yahoo]: http://search.yahoo.com/ &quot;Yahoo Search&quot; [msn]: http://search.msn.com/ &quot;MSN Search&quot; 上面两种写法都会产生下面的 HTML。 &lt;p&gt;I get 10 times more traffic from &lt;a href=&quot;http://google.com/&quot; title=&quot;Google&quot;&gt;Google&lt;/a&gt; than from &lt;a href=&quot;http://search.yahoo.com/&quot; title=&quot;Yahoo Search&quot;&gt;Yahoo&lt;/a&gt; or &lt;a href=&quot;http://search.msn.com/&quot; title=&quot;MSN Search&quot;&gt;MSN&lt;/a&gt;.&lt;/p&gt; 下面是用行内式写的同样一段内容的 Markdown 文件，提供作为比较之用： I get 10 times more traffic from [Google](http://google.com/ &quot;Google&quot;) than from [Yahoo](http://search.yahoo.com/ &quot;Yahoo Search&quot;) or [MSN](http://search.msn.com/ &quot;MSN Search&quot;). 参考式的链接其实重点不在于它比较好写，而是它比较好读，比较一下上面的范例，使用参考式的文章本身只有 81 个字符，但是用行内形式的却会增加到 176 个字元，如果是用纯 HTML 格式来写，会有 234 个字元，在 HTML 格式中，标签比文本还要多。 使用 Markdown 的参考式链接，可以让文件更像是浏览器最后产生的结果，让你可以把一些标记相关的元数据移到段落文字之外，你就可以增加链接而不让文章的阅读感觉被打断。 强调 Markdown 使用星号（*）和底线（_）作为标记强调字词的符号，被 * 或 _ 包围的字词会被转成用 &lt;em&gt; 标签包围，用两个 * 或 _ 包起来的话，则会被转成 &lt;strong&gt;，例如： *single asterisks* _single underscores_ **double asterisks** __double underscores__ 会转成： &lt;em&gt;single asterisks&lt;/em&gt; &lt;em&gt;single underscores&lt;/em&gt; &lt;strong&gt;double asterisks&lt;/strong&gt; &lt;strong&gt;double underscores&lt;/strong&gt; 你可以随便用你喜欢的样式，唯一的限制是，你用什么符号开启标签，就要用什么符号结束。 强调也可以直接插在文字中间： un*frigging*believable 但是如果你的 * 和 _ 两边都有空白的话，它们就只会被当成普通的符号。 如果要在文字前后直接插入普通的星号或底线，你可以用反斜线： \*this text is surrounded by literal asterisks\* 代码 如果要标记一小段行内代码，你可以用反引号把它包起来（` ），例如： Use the `printf()` function. 会产生： &lt;p&gt;Use the &lt;code&gt;printf()&lt;/code&gt; function.&lt;/p&gt; 如果要在代码区段内插入反引号，你可以用多个反引号来开启和结束代码区段： ``There is a literal backtick (`) here.`` 这段语法会产生： &lt;p&gt;&lt;code&gt;There is a literal backtick (`) here.&lt;/code&gt;&lt;/p&gt; 代码区段的起始和结束端都可以放入一个空白，起始端后面一个，结束端前面一个，这样你就可以在区段的一开始就插入反引号： A single backtick in a code span: `` ` `` A backtick-delimited string in a code span: `` `foo` `` 会产生： &lt;p&gt;A single backtick in a code span: &lt;code&gt;`&lt;/code&gt;&lt;/p&gt; &lt;p&gt;A backtick-delimited string in a code span: &lt;code&gt;`foo`&lt;/code&gt;&lt;/p&gt; 在代码区段内，&amp; 和尖括号都会被自动地转成 HTML 实体，这使得插入 HTML 原始码变得很容易，Markdown 会把下面这段： Please don&apos;t use any `&lt;blink&gt;` tags. 转为： &lt;p&gt;Please don&apos;t use any &lt;code&gt;&amp;lt;blink&amp;gt;&lt;/code&gt; tags.&lt;/p&gt; 你也可以这样写： `&amp;#8212;` is the decimal-encoded equivalent of `&amp;mdash;`. 以产生： &lt;p&gt;&lt;code&gt;&amp;amp;#8212;&lt;/code&gt; is the decimal-encoded equivalent of &lt;code&gt;&amp;amp;mdash;&lt;/code&gt;.&lt;/p&gt; 图片 很明显地，要在纯文字应用中设计一个「自然」的语法来插入图片是有一定难度的。 Markdown 使用一种和链接很相似的语法来标记图片，同样也允许两种样式： 行内式和参考式。 行内式的图片语法看起来像是： ![Alt text](/path/to/img.jpg) ![Alt text](/path/to/img.jpg &quot;Optional title&quot;) 详细叙述如下： 一个惊叹号 ! 接着一个方括号，里面放上图片的替代文字 接着一个普通括号，里面放上图片的网址，最后还可以用引号包住并加上选择性的 ‘title’ 文字。 参考式的图片语法则长得像这样： ![Alt text][id] 「id」是图片参考的名称，图片参考的定义方式则和链接参考一样： [id]: url/to/image &quot;Optional title attribute&quot; 到目前为止， Markdown 还没有办法指定图片的宽高，如果你需要的话，你可以使用普通的 &lt;img&gt; 标签。 其它 自动链接 Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用尖括号包起来， Markdown 就会自动把它转成链接。一般网址的链接文字就和链接地址一样，例如： &lt;http://example.com/&gt; Markdown 会转为： &lt;a href=&quot;http://example.com/&quot;&gt;http://example.com/&lt;/a&gt; 邮址的自动链接也很类似，只是 Markdown 会先做一个编码转换的过程，把文字字符转成 16 进位码的 HTML 实体，这样的格式可以糊弄一些不好的邮址收集机器人，例如： &lt;address@example.com&gt; Markdown 会转成： &lt;a href=&quot;&amp;#x6D;&amp;#x61;i&amp;#x6C;&amp;#x74;&amp;#x6F;:&amp;#x61;&amp;#x64;&amp;#x64;&amp;#x72;&amp;#x65; &amp;#115;&amp;#115;&amp;#64;&amp;#101;&amp;#120;&amp;#x61;&amp;#109;&amp;#x70;&amp;#x6C;e&amp;#x2E;&amp;#99;&amp;#111; &amp;#109;&quot;&gt;&amp;#x61;&amp;#x64;&amp;#x64;&amp;#x72;&amp;#x65;&amp;#115;&amp;#115;&amp;#64;&amp;#101;&amp;#120;&amp;#x61; &amp;#109;&amp;#x70;&amp;#x6C;e&amp;#x2E;&amp;#99;&amp;#111;&amp;#109;&lt;/a&gt; 在浏览器里面，这段字串（其实是 &lt;a href=&quot;mailto:address@example.com&quot;&gt;address@example.com&lt;/a&gt;）会变成一个可以点击的「address@example.com」链接。 （这种作法虽然可以糊弄不少的机器人，但并不能全部挡下来，不过总比什么都不做好些。不管怎样，公开你的信箱终究会引来广告信件的。） 反斜杠 Markdown 可以利用反斜杠来插入一些在语法中有其它意义的符号，例如：如果你想要用星号加在文字旁边的方式来做出强调效果（但不用 &lt;em&gt; 标签），你可以在星号的前面加上反斜杠： \*literal asterisks\* Markdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号： \ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 # 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号 感谢 感谢 leafy7382 协助翻译，hlb、Randylien 帮忙润稿，ethantw 的汉字标准格式・CSS Reset， WM 回报文字错误。 感谢 fenprace，addv。 Markdown 免费编辑器 Windows 平台 MarkdownPad MarkPad Linux 平台 ReText Mac 平台 Mou 在线编辑器 Markable.in Dillinger.io 浏览器插件 MaDe (Chrome) 高级应用 Sublime Text 2 + MarkdownEditing / 教程 * 如有更好的 Markdown 免费编辑器推荐，请到这里反馈，谢谢！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SaltStack-target]]></title>
      <url>http://czero000.github.io/2016/03/31/saltstack-target.html</url>
      <content type="text"><![CDATA[本文总结了SaltStack如何定位目标主机，以及介绍一些常用的使用案例. SaltStack主机定位为什么需要定位主机作为自动化配置管理工具，首先要解决如何确定特定配置能够准确推送到一个或多个目标主机，否则又何谈自动化大批量主机的分类配置管理。 SaltStack的target机制SaltStack建立一套很完善的minion定位机制，叫“target minion‘。通过多种途径，指定minion具有的属性，来区分推送命令或者状态的对应目标。 globbing （默认匹配方式，linux shell风格的通配） Perl-compatible regular expressions （E，正则匹配方式，对象是minion id） Lists （L，直接跟一串minion id 列表） Grains （G，使用grains值匹配） NodeGroup （N，master配置文件中预定义好的组信息） Subnet （S，利用minion的ip属性来进行匹配） Range cluster （R，设置ranger服务器反馈值来匹配） Pillar （I，用pillar数据匹配） Compound （c，复合匹配，用上面一种或多钟方式联合匹配） 12345678910salt &apos;*&apos; test.ping salt \* test.ping salt &apos;172.1[1-7].*&apos; test.pingsalt -E &apos;172*&apos; test.ping salt -L &apos;Test01,Test02&apos; test.pingsalt -G &apos;os:CentOS&apos; test.pingsalt -N &apos;group1&apos; test.pingsalt -S &apos;172.16.11.0/24&apos; test.pingsalt -I &apos;key:value&apos; test.pingsalt -C &apos;E@Test0.* and G@os:CentOS&apos; test.ping 使用Batch选项进行分批次运行SaltStack提供了-b 选项，允许对target选中的所有主机分批次进行处理，每次只推送指定的数量或百分比，直至全部推送完毕。 12salt &apos;*&apos; -b 10 test.ping //一次10台salt -G &apos;os:RedHat&apos; --batch-size 25% test.ping //一次25%]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SaltStack安装]]></title>
      <url>http://czero000.github.io/2016/03/31/saltstack-install.html</url>
      <content type="text"><![CDATA[初识 SaltStack什么是 SaltStackSaltStack 是继 Puppet、Chef 之后新出现的配置管理及远程执行工具。SaltStack 是基于 Python 开发的一套 C/S 架构配置关机工具，底层使用 ZeroMQ 消息队列 pub/sub 方式通信，使用 SSL 证书剪发的方式进行认证管理。与 Puppet 相比，SaltStack 没有那么笨重，较为轻量，不想 Puppet 有一套自己的 DSL 用来编写配置。SaltStack 使用 YAML 作为配置文件格式，这样写起来既简单有容易，同时也便于动态生成；此外 SaltStack 在远程执行命令时的速度也非常快，并包含丰富的模块，SaltStack 很好的包含了状态管理的优点，大大提好运维人员的工作效率。简单总结有两大用处： 配置管理系统，能够维护预定义状态的远程节点（比如，确保指定的软件包被安装和特定的服务在运行） 一个分布式远程执行系统，用来在远程节点上执行命令和查询数据，可以单个节点，也可以是选定规则 SaltStack 特点 简单： 兼顾大规模部署和小规模系统环境，Salt 非常简单配置和维护，不管是本地网络系统，还是跨数据中心。salt 采用 C/S 架构，需要的功能内建到一组 daemon 中，只需要简单的配置就可以工作，也可以调整来满足自己特定需求。 并行执行： 通过并行方式让远程节点执行命令 采用安全的加密协议 最小、最快使用网络和负责 提供简单的编程接口 提供更细粒度的控制，使系统不止按照主机名，还允许按照系统属性来分类 成熟技术之上构建： 网络层采用优秀的 ZeroM Q库，salt的守护进程包含可行和透明的AMQ代理 使用公钥和 Master 端通信，使用更快的AES加密协议，集成认证和加密在Salt中 使用 msgpack 通讯，所以更快速和更轻量网络交换 Python 客户端接口： 允许简单的拓展，Salt 程序可以写成 Python 模块，Client 收集数据发送回 Master 或者其他程序 可以从简单的 Python API 调用或者从命令行调用，因此可以执行一次命令或者大型应用程序的一部分 快速、灵活、可扩展： 高速在一台或者一组服务器执行命令 速度快、配置简单、扩展性好，提供远程执行架构，可以管理任意数量的多样化需求的服务器 集成最好的远程执行工具，增强处理能力、拓展使用范围，可以使用多样化复杂的网络 开源： Salt 是在 Apache 2.0 Licence 下开发，可以用在开源或者私有项目 支持的系统常见的发行版都已被支持： Arch Linux Debian Fedora FreeBSD Gentoo OS X RHEL / CentOS / Scientific Linux / Amazon Linux / Oracle Linux（EPEL5、EPEL6、EPEL7） Sloaris Ubuntu Windows SUSE 安装 SaltStackSaltStack 软件依赖由于 SaltStack 是基于 Python 开发，对 Python 版本和 python 模块有一定要求。 Python：版本大于2.6、小于3.0 msgpack-python ：高性能消息交换格式 YAML：SaltStack 配置解析定义语法 Jinja2：SaltStac k配置模版 MarkupSafe：Python unicode 转换库 apache-libcloud：SaltStack 对云架构编排库 Requests：HTTP Python 库 ZeroMQ：SaltStack 消息系统 pyzmq：ZeroMQ Python 库 PyCrypto：Python 密码库 M2Crypto：Openssl Python 包装库 安装 SaltStackSaltStack提供了四种安装方式（yum、pip、源码、salt-bootstrap），部署环境为 CentOS Linux release 7.1.1503 (Core) Master（172.16.11.210） 123rpm -ivh http://mirrors.yun-idc.com/epel/7/x86_64/e/epel-release-7-5.noarch.rpmyum install salt-master -ysystemctl start salt-master Minion（172.16.11.211）12345rpm -ivh http://mirrors.yun-idc.com/epel/7/x86_64/e/epel-release-7-5.noarch.rpmyum install salt-minion -ysed -i &apos;s/#master: salt/master: 172.16.11.210/g&apos; /etc/salt/minion // 这里为 Master 的 ip 地址echo &quot;172.16.11.211&quot; &gt; /etc/salt/minion_id // 在 Master 认证是显示的 minion idsystemctl start salt-minion SaltStack 证书管理Salt 在 master 和 minion 通信使用AES加密，保证发给 minion 的指令安全，Master和minion之间认证采用信任接受的 Key，在发送命令到 minion 之前，minon 的 key 需要先被 master 所接受，运行 salt-key 可以列出当前 key 状态。 12345678910111213141516171819salt-key -L // 查看当前证书情况 Accepted Keys: Denied Keys: Unaccepted Keys: 172.16.11.211 Rejected Keys:salt-key -A -y // 同意签证所有没接受的请求 The following keys are going to be accepted: Unaccepted Keys: 172.16.11.211 Key for minion 172.16.11.211 accepted.salt-key -L Accepted Keys: 172.16.11.211 Denied Keys: Unaccepted Keys: Rejected Keys: 更多的证书管理通过salt-key -h查看。 配置SaltStackMaster端master端的配置文件是/etc/salt/master，其中的配置选项较多，在日常使用中，需要经常修改Master的配置文件。SaltStack的大部分配置都可以保持默认，只需根据自己的实际需求更改配置即可。其中下面几个在平时使用过程中，会经常能改。 max_open_files ： 根据Master将Minin数量进行适当的调整 timeout ： 可以根据Master 和Minion的网络状况调整 auto_accept和autosign_file： 在大规模部署Minion的时候可以设置为自动签证 master_tops和所有以external开头的参数： 这些参数是SaltStack与外部系统进行整合的相关配置参数 详细配置信息可以参考：http://arlen.blog.51cto.com/7175583/1423997 Minionmaster端的配置文件是/etc/salt/minion，大部分情况保持默认即可详细配置信息可以参考：http://arlen.blog.51cto.com/7175583/1424008 SaltStack常用命令操作Master端 salt // salt master核心操作命令 12salt [options] &apos;&lt;target&gt;&apos; &lt;function&gt; [arguments]salt &apos;*&apos; test.ping salt-cp // 文件传输命令 ，不支持目录分发 12salt-cp [options] &apos;&lt;target&gt;&apos; SOURCE DESTsalt-cp &apos;*&apos; test.txt /root/ salt-key // 证书管理 12salt-key [options]salt-key -L salt-master // 服务命令 12salt-master [options]salt-master -d //后台运行master salt-run // 执行 runner 12salt-run [options] [runner.func]salt-run manage.status salt-unity Minion端 salt-call // 拉取命令 12salt-call [options] &lt;function&gt; [arguments]salt-call test.ping //自己执行test.ping命令 salt-minion // 服务命令 12salt-minion [options]salt-minion -d //后台运行 SaltStack常用模块Saltstack通过模块来实现管理，具备丰富的模块功能，命令形式也较为自由。 sys.doc：类似Linux的man命令，可以显示minion支持的模块的详细操作说明 123456salt &apos;*&apos; sys.doc status.all_status //查询status.all_status模块函数的使用方法 &apos;status.all_status:&apos; Return a composite of all status data and info for this minion. Warning: There is a LOT here! CLI Example: salt &apos;*&apos; status.all_status status ：status模块是系统状态的常用信息模块，可以利用status模块查看系统信息 123456789salt &apos;172.16.11.211&apos; status.loadavg // 查询负载信息，还有status.[cpuinfo,diskstats,meminfo,w]172.16.11.211: ---------- 1-min: 0.05 15-min: 0.05 5-min: 0.07 test： 更多使用方法使用访问官方网站或者salt &#39;*&#39; sys.doc test 123salt &apos;172.16.11.211&apos; test.ping172.16.11.211: True state：是salt state的管理模块，可以通过state模块简单的对minin操作sls状态 12345salt &apos;172.16.11.211&apos; state.highstate //更新指定minons的所有sls状态salt &apos;172.16.11.211&apos; state.running //查看当前运行的sls状态salt &apos;172.16.11.211&apos; state.single pkg.installed name=vim //动态指定一个sls状态 saltutil ： SaltStack的一些辅助操作命令模块 12salt &apos;*&apos; saltutil.is_running state.highstate //判断一个函数是否正在使用salt &apos;*&apos; saltutil.kill_job &lt;job id&gt; // 强制关闭一个job进程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python学习--思维导图]]></title>
      <url>http://czero000.github.io/2016/03/30/learn-python-mindmap.html</url>
      <content type="text"><![CDATA[思维导图转自pythoner 第一部分 Python语言第一章 基本环境 第二章 内置类型 第三章 表达式 第四章 函数 第五章 迭代器 第六章 模块 第七章 类 第八章 异常 第九章 装饰器 第十章 描述符 第十一章 元类 第二部分 标准库标准库 第三部分 扩展库扩展库 附录]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[glibc再爆漏洞]]></title>
      <url>http://czero000.github.io/2016/02/18/glibc-getaddrinfo-repair.html</url>
      <content type="text"><![CDATA[漏洞详情近日，Google和Red Hat的安全人员发现GNU C Library (glibc)中存在严重的安全漏洞，可导致Linux软件被攻击者劫持，进而在Linux平台上执行任意代码，获取密码，监视用户，甚至控制计算机。CVE编号为CVE-2015-7547。 glibc是GNU发布的libc库，即c运行库。它是Linux系统中最底层的API，几乎其它运行库都会依赖于glibc。glibc应用于众多Linux发行版本中，所以此类漏洞影响范围十分广泛。 漏洞概述glibc的DNS客户端解析器中存在基于栈的缓冲区溢出漏洞。当软件用到getaddrinfo库函数(处理名字到地址以及服务到端口的转换)时，攻击者便可借助特制的域名、DNS服务器或中间人攻击利用该漏洞，控制软件，并试图控制整个系统。 攻击者使用恶意的DNS域名服务器创建类似于evildomain.com的域名，然后向目标用户发送带有指向该域名的链接的邮件，一旦用户点击该链接，客户端或浏览器将会开始查找ildomain.com，并最终得到恶意服务器的buffer-busting响应。该域名被嵌入服务器日志中，一旦解析就会触发远程代码执行，SH客户端也会因此被控制。或者，位于目标用户网络中的中间人攻击者可以篡改DNS响应，向恶意代码中动态注入负载。 据目前的调查情况，此漏洞影响自2.9之后的所有版本，其他旧版本也可能受到影响。 其他系统还包括1234567891011121314CentOS6 所有版本CentOS7所有版本SUSE Linux Enterprise Server 11 SP3SUSE Linux Enterprise Server 12Ubuntu Server 14.04.1 LTS 32位Ubuntu Server 14.04.1 LTS 64位Ubuntu Server 12.04 LTS 64位Ubuntu Server 12.04 LTS 64位（Docker）Debian8.2 32位Debian8.2 64位Debian7.8 32位Debian7.8 64位Debian7.4 64位CoreOS717.3.0 64位 技术细节glibc通过alloca()函数在栈中为_nss_dns_gethostbyname4_r函数2048字节的空间，用于托管DNS响应。若响应大于2048字节，程序会从堆中重新分配一个缓冲区，并更新所有信息(缓冲区指针，缓冲区大小和响应大小)。 在一定条件下，会出现栈缓冲区和新分配的堆内存的错误匹配，导致超过栈缓冲区大小的响应仍然存储在栈中，进而发生缓冲区溢出。触发该漏洞的利用向量十分普遍，并且ssh、sudo和curl等工具中。 缓解该漏洞存在于resolv/res_send.c文件中，当getaddrinfo()函数被调用时会触发该漏洞。技术人员可以通过将TCP DNS响应的大小限制为1024字节，并丢弃所有超过512字节的UDPDNS数据包来缓解该问题。值得庆幸的是，许多嵌入式Linux设备，例如家庭路由器，更倾向于使用uclibc库，因此可以免受该漏洞的影响。 漏洞的成因及POC使用测试据悉，漏洞的成因在于DNS Server Response返回过量的(2048 ) 字节, 导致接下来的response 触发栈溢出。目前，Google已提供了POC，据其博客中所述，该漏洞应该是可以绕过内存防护技术，从而形成代码执行漏洞。具体POC 地址如下：github.com/fjserna/CVE-2015-7547 对此，乌云白帽子路人甲在自己的本地lubuntu 上进行了测试，libc 版本为 2.19。lubuntu系列也属于Debian 的一个发行版，故理论上满足漏洞条件。测试过程如下：根据漏洞描述，我们可以做一个假的DNS Server 作为中间人，来验证该漏洞。更改DNS 解析为 127.0.0.1，刷新DNS 缓存 sudo /etc/init.d/nscd restart 执行 CVE-2015-7547-poc.py , 注意无需更改 ip_addr 。编译 CVE-2015-7547-client.c , 执行CVE-2015-7547-client若含有漏洞，会造成Segmentation Fault。 文件下载链接：CVE-2015-7547-master.zip 修复过程 更新glibc版本 1234567//rhel¢osyum -y update glibc* nscd//debian&amp;ubuntuapt-get updateapt-get install libc6; apt-get install libc-bin 重启服务由于本次漏洞为glibc的漏洞，涉及多种应用程序，最安全并且推荐的修复方法是重启系统生效。如果你的系统无法重启，请执行如下命令查询仍然在使用老版本glibc的程序。 1lsof +c0 -d DEL | awk &apos;NR==1 || /libc-/ &#123;print $2,$1,$4,$NF&#125;&apos; | column -t 根据查询的结果, 识别哪些是对外提供服务的程序，重启对应的服务。 解决公司大部分服务器都是centos 6.x和7.x ，CentOS 社区也在2016年2月17日 更新了最新的glibc版本，那么升级起来就很方便了，写了个升级脚本，内容如下，先让脚本跑一会。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566cat repair_glibc.sh #!/bin/bash######################################################## Title: Repair glibc getaddrinfo() Bug 18665 #### Version: 1.0 #### Date: 2016-02-18 #### Author: Charlie.Cui #### License: General Public License (GPL) #### Copyright© 2015, Charlie.Cui All Rights Reserved ########################################################system=`cat /etc/redhat-release| awk &apos;&#123;print $1&#125;&apos;`release=`rpm -qa | grep ^kernel-[0-9] |head -n 1 | awk -F&apos;.&apos; &apos;&#123;print $4&#125;&apos;`glibc_version=`rpm -qa glibc`FRed=&quot;\E[31;40m&quot;; FGreen=&quot;\E[32;40m&quot;; FBlue=&quot;\E[34;40m&quot;; St0=&quot;\033[1m&quot;; St1=&quot;\033[5m&quot;; Ed=&quot;\033[0m&quot; # el6 Update glibcel6() &#123;wget http://172.16.6.18/resource/files/CentOS6.x/local_mirror.repo -O /etc/yum.repos.d/local_mirror.repowget http://172.16.6.18/resource/files/CentOS6.x/epel.repo -O /etc/yum.repos.d/epel.repoyum clean all;yum makecacheyum update glibc -yif [ $glibc_version = glibc-2.12-1.166.el6_7.7.x86_64 ];then echo -e &quot; $FGreen $glibc_version Update Sucesed! $Ed&quot;else echo -e &quot; $FRed $glibc_version Update Faild! $Ed&quot;fi&#125;# el7 Update glibcel7() &#123;wget http://172.16.6.18/resource/files/CentOS7.x/local_mirror.repo -O /etc/yum.repos.d/local_mirror.repowget http://172.16.6.18/resource/files/CentOS7.x/epel.repo -O /etc/yum.repos.d/epel.repoyum clean all;yum makecacheyum update glibc -yif [ $glibc_version = glbc-2.17-106.el7_2.4.x86_64 ];then echo -e &quot; $FGreen $glibc_version Update Sucesed! $Ed&quot;else echo -e &quot; $FRed $glibc_version Update Faild! $Ed&quot;fi&#125;# Check System if [ $system = CentOS ];then echo -e &quot;$FGreen This System Version Is: $system continue update glibc version... $Ed&quot; # Check release if [ $release = el6 ];then if [ `rpm -qa glibc` = glibc-2.12-1.166.el6_7.7.x86_64 ];then echo -e &quot; $FGreen $glibc_version is the latest version $Ed&quot; else el6 fi elif [ $release = el7 ];then if [ `rpm -qa glibc` = glibc-2.17-106.el7_2.4.x86_64 ];then echo -e &quot; $FGreen $glibc_version is the latest version $Ed&quot; else el7 fi else echo -e &quot;$FRed Unknow Error $Ed&quot; exit; fielse echo -e &quot;$FRed This System Version Is Not CentOS $Ed&quot; exit;fi]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx玩转反向代理]]></title>
      <url>http://czero000.github.io/2016/02/16/how-to-setup-reverse-proxy-by-nginx.html</url>
      <content type="text"><![CDATA[反向代理初识反向代理反向代理 (Reverse Proxy) 是指以代理服务器来接受 Internet 的连接请求，然后将请求转发给内部服务器，并将从服务器得到的结构返回给 Internet 请求客户端，喜事的代理服务器对外表现为一个反向代理服务器。 反向代理作用 保护网站安全 – 任何来自 Internet 的请求都必须先经过代理服务器 通过配置缓存功能加速 Web 请求 – 可以缓存后端 Web 服务器的某些静态资源，减轻 Web 服务器的负载 实现负载均衡 – 充当负载均衡服务器均衡的分发请求，平衡集群中各个服务器的负载压力 安装 Nginx安装过程参考 nginx+php-fpm 这篇文章的安装过程 配置反向代理简单的反向代理就是 http，不需要缓存控制等高级功能，仅仅一个简单的代理，比如 nginx+php-fpm 也是一种反向代理 12345location ~ .*\.(php|php5)$ &#123; fastcgi_pass 127.0.0.1:9000; include fastcgi.conf; try_files $uri =404;&#125; 而相对复杂一些的就是反向代理一些网站，会应用到缓存控制机制。 简单反向代理 在 nginx.conf 配置文件中的 http 块中添加下面内容 1234567891011121314151617181920// 反向代理参数proxy_connect_timeout 5; // nginx 跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 60;proxy_read_timeout 5; // 连接成功后，后端服务器响应时间(代理接收超时)proxy_buffer_size 32k; // 设置代理服务器（nginx）保存用户头信息的缓冲区大小proxy_buffers 4 64k; // proxy_buffers 缓冲区proxy_busy_buffers_size 128k; // 高负荷下缓冲大小（proxy_buffers*2）proxy_temp_file_write_size 128k; proxy_ignore_client_abort on; // 不允许代理端主动关闭连接proxy_headers_hash_max_size 51200;proxy_headers_hash_bucket_size 6400;// 配置临时目录、缓存路径(同一个硬盘分区，注意权限)proxy_temp_path /cache/proxy_temp 1 2;proxy_cache_path /cache/proxy_cache levels=1:2 keys_zone=cache_one:200m inactive=1d max_size=10g;// keys_zone=cache_one:200m 表示这个 zone 名称为 cache_one，分配的内存大小为 200MB// levels=1:2 表示缓存目录的第一级目录是 1 个字符，第二级目录是 2 个字符// inactive=1d 表示这个 zone 中的缓存文件如果在 1 天内都没有被访问，那么文件会被 cache manager 进程删除// max_size=10G 表示这个 zone 的硬盘容量为 10G 在虚拟主机配置文件 proxy.zerounix.com.conf 文件中添加下面内容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647server &#123; listen 80; server_name proxy.zerounix.com; index index.html index.htm index.php; access_log logs/proxy.zerounix.com_access.log access; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-For $remote_addr; proxy_pass http://172.16.11.211; &#125;// 只对图片、js、css 等静态文件进行缓存 location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|js|css)$ &#123; proxy_next_upstream http_502 http_504 error timeout invalid_header; proxy_cache cache_one; proxy_cache_valid 200 304 12h; proxy_cache_valid 301 302 1m; proxy_cache_valid any 1m; proxy_cache_key $host$uri$is_args$args; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Accept-Encoding &quot;none&quot;; proxy_ignore_headers &quot;Cache-Control&quot; &quot;Expires&quot;; proxy_pass http://172.16.11.211; expires 1h; &#125; location ~ .*\.(php|jsp|cgi)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_pass http://172.16.11.211; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 使用SSL的反向代理 安装nginx 需要将将 ‘–with-http_sub_module、ngx_cache_purge-2.3’ 编译到 nginx 中下载链接http://labs.frickle.com/files/ 1234// 编译参数./configure --prefix=/usr/local/nginx --add-module=../ngx_cache_purge-2.3 \--with-http_sub_module --with-http_stub_status_module --with-http_ssl_module --with-http_flv_module \--with-http_gzip_static_module --with-ld-opt=-ljemalloc 签发证书 自己签发免费 ssl 证书，为 nginx 生成自签名 ss l证书(访问时需添加信任。也可以使用第三方签名后的证书，如免费的 startssl)1234cd /usr/local/nginx/confopenssl genrsa -out server.key 1024openssl req -new -key server.key -out server.csropenssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt 配置反向代理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748proxy_temp_path /cache/proxy_temp 1 2;proxy_cache_path /cache/proxy_cache levels=1:2 keys_zone=cache_one:200m inactive=1d max_size=10g;proxy_cache_key &quot;$host$request_uri&quot;;server &#123;listen 80;server_name proxy.zerounix.com;rewrite ^(.*) http://proxy.zerounix.com$1 permanent;&#125;server &#123; listen 443; server_name proxy.zerounix.com; upstream google &#123; server 173.194.127.144:80 max_fails=3; server 173.194.127.147:80 max_fails=3; server 173.194.127.148:80 max_fails=3; server 173.194.127.145:80 max_fails=3; server 173.194.127.146:80 max_fails=3; &#125; ssl on; ssl_certificate /usr/local/nginx/ssl/nginx.crt; ssl_certificate_key /usr/local/nginx/ssl/nginx.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-RC4-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:RC4-SHA:!aNULL:!eNULL:!EXPORT:!DES:!3DES:!MD5:!DSS:!PKS; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_session_timeout 5m; location / &#123; proxy_cache one; proxy_cache_valid 200 302 1h; proxy_cache_valid 404 1m; proxy_redirect http://www.google.com/ /; proxy_cookie_domain google.com proxy.zerounix.com; proxy_pass http://google; proxy_set_header Host &quot;www.google.com&quot;; proxy_set_header Accept-Encoding &quot;&quot;; proxy_set_header User-Agent $http_user_agent; proxy_set_header Accept-Language &quot;zh-CN&quot;; proxy_set_header Cookie &quot;PREF=ID=047808f19f6de346:U=0f62f33dd8549d11:FF=2:LD=zh-CN:NW=1:TM=1325338577:LM=1332142444:GM=1:SG=2:S=rE0SyJh2w1IQ-Maw&quot;; sub_filter www.google.com proxy.zerounix.com; sub_filter_once off &#125; &#125; 1 监听了 80 和 443 端口，可以在 Linux自己生成证书。2 定义了个 upstream google，放了 5 个谷歌的 ip（通过 nslookup www.google.com 命令获取（yum -y install bind-utils）），如果不这样做，就等着被谷歌的验证码搞崩溃吧。3 也设置了反向代理缓存，某些资源不用重复去请求谷歌获取，加快搜索速度4 proxy_redirect http://www.google.com/ /; 这行的作用是把谷歌服务器返回的302响应头里的域名替换成我们的，不然浏览器还是会直接请求 www.google.com，那样反向代理就失效了。5 proxy_cookie_domain google.com proxy.zerounix.com; 把 cookie 的作用域替换成我们的域名6 proxy_pass http://google; 反向代理到 upstream google7 proxy_set_header Accept-Encoding “”; 防止谷歌返回压缩的内容，因为压缩的内容我们无法作域名替换8 proxy_set_header Accept-Language “zh-CN”;设置语言为中文9 proxy_set_header Cookie “PREF=ID=047808f19f6de346:U=0f62f33dd8549d11:FF=2:LD=zh-CN:NW=1:TM=1325338577:LM=1332142444:GM=1:SG=2:S=rE0SyJh2w1IQ-Maw”; 这行很关键，传固定的 cookie 给谷歌，是为了禁止即时搜索，因为开启即时搜索无法替换内容。还有设置为新窗口打开网站，这个符合我们打开链接的习惯10 sub_filter www.google.com proxy.zerounix.com当然是把谷歌的域名替换成我们的了，注意需要安装 nginx 的 sub_filter 模块(编译加上–with-http_sub_module参数)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[通过HTTPS访问Web]]></title>
      <url>http://czero000.github.io/2016/02/16/nginx-support-https.html</url>
      <content type="text"><![CDATA[HTTPSHTTPS 目前已经是所有重视隐私和安全性的网站的首选，例如国外的 Google、Facebook、Twitter，国内则是淘宝、百度、京东等都已都支持了全站 HTTPS，可以想象以下，如果一个网站没有加密，那么你的所有账户密码都是通过明文来传输，当涉及到隐私和金融问题，不加密是多么可怕的事情。 随着技术的发展，HTTPS 网站已不再是大型网站的专利，所有普通的个人站点和blog可以以自己动手搭建一个安全加密的网站。 什么是 HTTPS、SSL 证书 HTTPS 超文本传输安全协议（缩写：HTTPS，英语：Hypertext Transfer Protocol Secure）是超文本传输协议和 SSL/TLS 的组合，用以提供加密通讯及对网络服务器身份的鉴定。HTTPS 连接经常被用于万维网上的交易支付和企业信息系统中敏感信息的传输。HTTPS 不应与在 RFC 2660 中定义的安全超文本传输协议 （S-HTTP） 相混。 SSL 证书 SSL 证书是数字证书的一种，遵守 SSL 协议，使用 Secure Socket Layer 协议在浏览器和 Web 服务器之间建立一条安全通道，从而实现数据信息在客户端和服务器之间的加密传输，保证双方传递信息的安全性，不可被第三方窃听；用户可以通过服务器证书验证他所访问的网站是否真实可靠。 等多关于 HTTPS、SSl 证书的信息，请 Google. 使用 OpenSSL 生成自签名证书制作 CA 证书 修改 CA 配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041vim /etc/pki/tls/openssl.conf[ CA_default ]dir = /etc/pki/CA # Where everything is keptcerts = $dir/certs # Where the issued certs are keptcrl_dir = $dir/crl # Where the issued crl are keptdatabase = $dir/index.txt # database index file.#unique_subject = no # Set to &apos;no&apos; to allow creation of # several ctificates with same subject.new_certs_dir = $dir/newcerts # default place for new certs.certificate = $dir/cacert.pem # The CA certificateserial = $dir/serial # The current serial numbercrlnumber = $dir/crlnumber # the current crl number # must be commented out to leave a V1 CRLcrl = $dir/crl.pem # The current CRLprivate_key = $dir/private/cakey.pem# The private keyRANDFILE = $dir/private/.rand # private random number filedefault_days = 3650 # how long to certify for[ policy_match ]countryName = matchstateOrProvinceName = optionallocalityName = optionalorganizationName = optionalorganizationalUnitName = optionalcommonName = suppliedemailAddress = optional[ req_distinguished_name ]countryName = Country Name (2 letter code)countryName_default = CNcountryName_min = 2countryName_max = 2stateOrProvinceName = State or Province Name (full name)stateOrProvinceName_default = BJ 在 CA 目录下创建两个初始文件 12touch index.txt serialecho 01 &gt; serial 生成根密钥 12cd /etc/pki/CA/(umask 077; openssl genrsa -out private/cakey.pem 2048 ) 生成根证书 1(umask 077;openssl req -new -x509 -key private/cakey.pem -out cacert.pem) 会提示输入一些内容，因为是私有的，所以可以随便输入（之前修改的 openssl.cnf 会在这里呈现），最好记住能与后面保持一致。上面的自签证书 cacert.pem 应该生成在 /etc/pki/CA 下 制作服务器证书 生成服务器 ssl 密钥 123mkdir /usr/local/nginx/sslcd /usr/local/nginx/sslopenssl genrsa -out nginx.key 2048 为 ningx 生成证书签署请求 12// 同样会提示输入一些内容，其它随便，除了 `Commone Name` 一定要是你要授予证书的服务器域名或主机名，challenge password 不填。openssl req -new -key nginx.key -out nginx.csr 用私有 CA 来签署证书 1234567891011121314151617181920212223242526272829303132333435openssl ca -in nginx.csr -out nginx.crtUsing configuration from /etc/pki/tls/openssl.cnfCheck that the request matches the signatureSignature okCertificate Details: Serial Number: 1 (0x1) Validity Not Before: Feb 5 07:17:48 2016 GMT Not After : Feb 2 07:17:48 2026 GMT Subject: countryName = CN stateOrProvinceName = BJ localityName = BJ organizationName = Default Company Ltd commonName = *.zerounix.com X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: 18:A2:A4:B8:69:03:23:FE:94:7C:D8:95:A8:B9:95:B6:E7:28:D7:58 X509v3 Authority Key Identifier: keyid:0D:01:60:ED:AF:82:A6:DB:46:42:BB:D7:F5:BD:4C:22:B8:6E:9F:33Certificate is to be certified until Feb 2 07:17:48 2026 GMT (3650 days)Sign the certificate? [y/n]:y1 out of 1 certificate requests certified, commit? [y/n]yWrite out database with 1 new entriesData Base Updated另外在极少数情况下，上面的命令生成的证书不能识别，试试下面的命令：openssl x509 -req -in server.csr -CA /etc/pki/CA/cacert.pem -CAkey /etc/pki/CA/private/cakey.pem -CAcreateserial -out server.crt 上面签发过程其实默认使用了 -cert cacert.pem -keyfile cakey.pem ，这两个文件就是前两步生成的位于 /etc/pki/CA 下的根密钥和根证书。将生成的 crt 证书发回 nginx 服务器使用。 精简上面的步骤如下 12345678910111213141516171819mkdir /usr/local/ngnix/sslcd /usr/lcoal/nginx/ssl// 创建根证书私钥openssl genrsa -des3 -out ca.key 2048// 创建根证书 (这里 /C 表示国家 (Country)，只能是国家字母缩写，如 CN、US 等； /ST 表示州或者省 (State/Provice)； /L 表示城市或者地区(Locality)；/O 表示组织名 (Organization Name)；/OU 其他显示内容，一般会显示在颁发者这栏)openssl req -new -x509 -days 36500 -key ca.key -out ca.crt -subj &quot;/C=CN/ST=BeiJing/L=BeiJing/O=Your Company Name/OU=Your Root CA&quot;// 创建服务器 ssl 证书私钥openssl genrsa -des3 -out server.key 2048// 建立 SSL 证书( /O 字段内容必须与刚才的 CA 根证书相同；/CN 字段为公用名称 (Common Name) ，必须为网站的域名(不带 www)；/OU 字段最好也与为网站域名，当然选择其他名字也没关系)openssl req -new -key server.key -out server.csr -subj &quot;/C=CN/ST=BeiJing/L=BeiJing/O=Your Company Name/OU=zerounix.com/CN=zerounix.com&quot;// 准备mkdir demoCAcd demoCAmkdir newcertstouch index.txtecho &apos;01&apos; &gt; serialcd ..// 自签名证书openssl ca -in server.csr -out server.crt -cert ca.crt -keyfile ca.key 更为简单的步骤12openssl genrsa -des3 -out server.key 2048openssl req -new -key server.key -out server.csr 配置 Nginx 支持 SSL编辑配置文件123456789101112131415161718192021222324252627server &#123; listen 443 ssl; server_name www.zerounix.com; root /data/website/www.zerounix.com; charset utf-8; index index.php index.html; ssl on; // 开启 ssl 支持 ssl_certificate /usr/local/nginx/ssl/nginx.crt; // 证书位置 ssl_certificate_key /usr/local/nginx/ssl/nginx.key; // 私钥 ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; // 指定密码为 openssl 支持的格式 ssl_ciphers HIGH:!aNULL:!MD5; // 加密方法 ssl_prefer_server_ciphers on; access_log logs/www.zerounix.com_access.log access; error_log logs/www.zerounix.com_error.log; location / &#123; try_files $uri $uri/ /index.php$is_args$args; &#125; location ~ .*\.(php|php5)$ &#123; #fastcgi_pass 127.0.0.1:9000; fastcgi_pass unix:/dev/shm/php-fpm.socket; include fastcgi.conf; try_files $uri =404; &#125;&#125; 通过第三方 SSL 签发机构签发SSL证书使用 OpenSSL 生成 SSL Key 和 CSR由于只有浏览器或者系统信赖的 CA 才可以让所有的访问者通畅的访问你的加密网站，而不是出现证书错误的提示。所以我们跳过自签证书的步骤，直接开始签署第三方可信任的 SSL 证书吧。OpenSSL 在 Linux、OS X 等常规的系统下默认都安装了，因为一些安全问题，一般现在的第三方 SSL 证书签发机构都要求起码 2048 位的 RSA 加密的私钥。同时，普通的 SSL 证书认证分两种形式，一种是 DV（Domain Validated），还有一种是 OV （Organization Validated），前者只需要验证域名，后者需要验证你的组织或公司，在安全性方面，肯定是后者要好。无论你用 DV 还是 OV 生成私钥，都需要填写一些基本信息，这里我们假设如下：域名，也称为 Common Name，因为特殊的证书不一定是域名：example.com 组织或公司名字 （Organization）：Example, Inc. 部门（Department）：可以不填写，这里我们写 Web Security 城市（City）：Beijing 省份（State / Province）：Beijing 国家（Country）：CN 加密强度：2048 位，如果你的机器性能强劲，也可以选择 4096 位 按照以上信息，使用 OpenSSL 生成 key 和 csr 的命令如下1openssl req -new -newkey rsa:2048 -sha256 -nodes -out example_com.csr -keyout example_com.key -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=Example Inc./OU=Web Security/CN=example.com&quot; PS：如果是泛域名证书，则应该填写 *.example.com你可以在系统的任何地方运行这个命令，会自动在当前目录生成 example_com.csr 和 example_com.key 这两个文件接下来你可以查看一下 example_com.csr，得到类似这么一长串的文字1234567891011121314151617-----BEGIN CERTIFICATE REQUEST-----MIICujCCAaICAQAwdTELMAkGA1UEBhMCQ04xEDAOBgNVBAgTB0JlaWppbmcxEDAO BgNVBAcTB0JlaWppbmcxFTATBgNVBAoTDEV4YW1wbGUgSW5jLjEVMBMGA1UECxMM V2ViIFNlY3VyaXR5MRQwEgYDVQQDEwtleGFtcGxlLmNvbTCCASIwDQYJKoZIhvcN AQEBBQADggEPADCCAQoCggEBAPME+nvVCdGN9VWn+vp7JkMoOdpOurYMPvclIbsI iD7mGN982Ocl22O9wCV/4tL6DpTcXfNX+eWd7CNEKT4i+JYGqllqP3/CojhkemiY SF3jwncvP6VoST/HsZeMyNB71XwYnxFCGqSyE3QjxmQ9ae38H2LIpCllfd1l7iVp AX4i2+HvGTHFzb0XnmMLzq4HyVuEIMoYwiZX8hq+kwEAhKpBdfawkOcIRkbOlFew SEjLyHY+nruXutmQx1d7lzZCxut5Sm5At9al0bf5FOaaJylTEwNEpFkP3L29GtoU qg1t9Q8WufIfK9vXqQqwg8J1muK7kksnbYcoPnNgPx36kZsCAwEAAaAAMA0GCSqG SIb3DQEBBQUAA4IBAQCHgIuhpcgrsNwDuW6731/DeVwq2x3ZRqRBuj9/M8oONQen 1QIacBifEMr+Ma+C+wIpt3bHvtXEF8cCAJAR9sQ4Svy7M0w25DwrwaWIjxcf/J8U audL/029CkAuewFCdBILTRAAeDqxsAsUyiBIGTIT+uqi+EpGG4OlyKK/MF13FxDj /oKyrSJDtp1Xr9R7iqGCs/Zl5qWmDaLN7/qxBK6vX2R/HLhOK0aKi1ZQ4cZeP7Mr8EzjDIAko87Nb/aIsFyKrt6Ze3jOF0/vnnpw7pMvhq+folWdTVXddjd9Dpr2x1nc y5hnop4k6kVRXDjQ4OTduQq4P+SzU4hb41GIQEz4 -----END CERTIFICATE REQUEST----- 这个 CSR 文件就是你需要提交给 SSL 认证机构的，当你的域名或组织通过验证后，认证机构就会颁发给你一个 example_com.crt 而 example_com.key 是需要用在 Nginx 配置里和 example_com.crt 配合使用的，需要好好保管，千万别泄露给任何第三方 Nginx 配置 HTTPS 网站以及增加安全的配置你需要提交 CSR 文件给第三方 SSL 认证机构，通过认证后，他们会颁发给你一个 CRT 文件，我们命名为 example_com.crt同时，为了统一，你可以把这三个文件都移动到 /etc/ssl/private/ 目录。然后可以修改 Nginx 配置文件1234567891011server &#123; listen 80; listen [::]:80 ssl ipv6only=on; listen 443 ssl; listen [::]:443 ssl ipv6only=on; server_name example.com; ssl on; ssl_certificate /etc/ssl/private/example_com.crt; ssl_certificate_key /etc/ssl/private/example_com.key;&#125; 检测配置文件没问题后重新读取 Nginx 即可1nginx -t &amp;&amp; nginx -s reload 但是这么做并不安全，默认是 SHA-1 形式，而现在主流的方案应该都避免 SHA-1，为了确保更强的安全性，我们可以采取迪菲－赫尔曼密钥交换 首先，进入 /etc/ssl/certs 目录并生成一个 dhparam.pem12cd /etc/ssl/certs openssl dhparam -out dhparam.pem 2048 # 如果你的机器性能足够强大，可以用 4096 位加密 生成完毕后，在 Nginx 的 SSL 配置后面加入1234567ssl_prefer_server_ciphers on;ssl_dhparam /etc/ssl/certs/dhparam.pem;ssl_protocols TLSv1 TLSv1.1 TLSv1.2;ssl_ciphers &quot;EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH+aRSA+RC4 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4&quot;;keepalive_timeout 70;ssl_session_cache shared:SSL:10m;ssl_session_timeout 10m; 同时，如果是全站 HTTPS 并且不考虑 HTTP 的话，可以加入 HSTS 告诉你的浏览器本网站全站加密，并且强制用 HTTPS 访问123add_header Strict-Transport-Security max-age=63072000;add_header X-Frame-Options DENY;add_header X-Content-Type-Options nosniff; 同时也可以单独开一个 Nginx 配置，把 HTTP 的访问请求都用 301 跳转到 HTTPS123456server &#123; listen 80; listen [::]:80 ipv6only=on; server_name example.com; return 301 http://example.com$request_uri;&#125; 可靠的第三方 SSL 签发机构众所周知，前段时间某 NIC 机构爆出过针对 Google 域名的证书签发的丑闻，所以可见选择一家靠谱的第三方 SSL 签发机构是多么的重要。 目前一般市面上针对中小站长和企业的 SSL 证书颁发机构有： StartSSL Comodo / 子品牌 Positive SSL GlobalSign / 子品牌AlphaSSL GeoTrust / 子品牌 RapidSSL 其中 Postivie SSL、AlphaSSL、RapidSSL 等都是子品牌，一般都是三级四级证书，所以你会需要增加 CA 证书链到你的 CRT 文件里。 以 Comodo Positive SSL 为例，需要串联 CA 证书，假设你的域名是 example.com 那么，串联的命令是1cat example_com.crt COMODORSADomainValidationSecureServerCA.crt COMODORSAAddTrustCA.crt AddTrustExternalCARoot.crt &gt; example_com.signed.crt 在 Nginx 配置里使用 example_com.signed.crt 即可 如果是一般常见的 AplhaSSL 泛域名证书，他们是不会发给你 CA 证书链的，那么在你的 CRT 文件后面需要加入 AlphaSSL 的 CA 证书链 AlphaSSL Intermediate CA]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[如何正确配置Nginx+PHP（转载）]]></title>
      <url>http://czero000.github.io/2016/02/04/how-to-properly-configure-nginx-php.html</url>
      <content type="text"><![CDATA[对很多人而言，配置Nginx+PHP无外乎就是搜索一篇教程，然后拷贝粘贴。听上去似乎也没什么问题，可惜实际上网络上很多资料本身年久失修，漏洞百出，如果大家不求甚解，一味的拷贝粘贴，早晚有一天会为此付出代价。 假设我们用PHP实现了一个前端控制器，或者直白点说就是统一入口：把PHP请求都发送到同一个文件上，然后在此文件里通过解析REQUEST_URI实现路由。 此时很多教程会教大家这样配置Nginx+PHP123456789101112131415161718192021server &#123; listen 80; server_name foo.com; root /path; location / &#123; index index.html index.htm index.php; if (!-e $request_filename) &#123; rewrite . /index.php last; &#125; &#125; location ~ \.php$ &#123; include fastcgi_params; fastcgi_param SCRIPT_FILENAME /path$fastcgi_script_name; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; &#125;&#125; 这里面有很多错误，或者说至少是坏味道的地方，大家看看能发现几个。 我们有必要先了解一下Nginx配置文件里指令的继承关系：Nginx配置文件分为好多块，常见的从外到内依次是http、server、location等等，缺省的继承关系是从外到内，也就是说内层块会自动获取外层块的值作为缺省值（有例外，详见参考）。 参考：UNDERSTANDING THE NGINX CONFIGURATION INHERITANCE MODEL 让我们先从index」指令入手吧，在问题配置中它是在[location]中定义的123location / &#123; index index.html index.htm index.php;&#125; 一旦未来需要加入新的[location]，必然会出现重复定义的index指令，这是因为多个location是平级的关系，不存在继承，此时应该在server里定义index，借助继承关系，index指令在所有的location中都能生效。 参考：Nginx Pitfalls 接下来看看「if」指令，说它是大家误解最深的Nginx指令毫不为过：123if (!-e $request_filename) &#123; rewrite . /index.php last;&#125; 很多人喜欢用「if」指令做一系列的检查，不过这实际上是try_files」指令的职责1try_files $uri $uri/ /index.php; 除此以外，初学者往往会认为if」指令是内核级的指令，但是实际上它是rewrite模块的一部分，加上Nginx配置实际上是声明式的，而非过程式的，所以当其和非rewrite模块的指令混用时，结果可能会非你所愿。 参考：IfIsEvil and How nginx “location if” works 下面看看「fastcgi_params」配置文件：1include fastcgi_params; Nginx有两份fastcgi配置文件，分别是fastcgi_params和fastcgi.conf，它们没有太大的差异，唯一的区别是后者比前者多了一行SCRIPT_FILENAME的定义：1fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; 注意：$document_root 和 $fastcgi_script_name 之间没有 /。 原本Nginx只有fastcgi_params，后来发现很多人在定义SCRIPT_FILENAME时使用了硬编码的方式，于是为了规范用法便引入了fastcgi.conf。 不过这样的话就产生一个疑问：为什么一定要引入一个新的配置文件，而不是修改旧的配置文件？这是因为「fastcgi_param」指令是数组型的，和普通指令相同的是：内层替换外层；和普通指令不同的是：当在同级多次使用的时候，是新增而不是替换。换句话说，如果在同级定义两次「SCRIPT_FILENAME」，那么它们都会被发送到后端，这可能会导致一些潜在的问题，为了避免此类情况，便引入了一个新的配置文件。 参考：FASTCGI_PARAMS VERSUS FASTCGI.CONF – NGINX CONFIG HISTORY 此外，我们还需要考虑一个安全问题：在PHP开启「cgi.fix_pathinfo」的情况下，PHP可能会把错误的文件类型当作PHP文件来解析。如果Nginx和PHP安装在同一台服务器上的话，那么最简单的解决方法是用try_files指令做一次过滤： 1try_files $uri =404; 参考：Nginx文件类型错误解析漏洞 依照前面的分析，给出一份改良后的版本，是不是比开始的版本清爽了很多：123456789101112131415161718server &#123; listen 80; server_name foo.com; root /path; index index.html index.htm index.php; location / &#123; try_files $uri $uri/ /index.php$is_args$args; &#125; location ~ \.php$ &#123; try_files $uri =404; include fastcgi.conf; fastcgi_pass 127.0.0.1:9000; &#125;&#125; 实际上还有一些瑕疵，主要是try_files和fastcgi_split_path_info不够兼容，虽然能够解决，但方案比较丑陋，具体就不多说了，有兴趣的可以参考问题描述。 补充：因为location已经做了限定，所以fastcgi_index其实也没有必要。 希望大家以后不要再拷贝粘贴了，如果实在改不了，那么就请拷贝粘贴本文。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx+PHP-FPM]]></title>
      <url>http://czero000.github.io/2016/02/04/nginx-php-fpm.html</url>
      <content type="text"><![CDATA[Nginx + PHP-FPM(FastCGI Process Manager)简介Apache的效率和承载能力受到大多人的诟病，Nginx 藉由 Nob-blocking 与 epool 这些特性，大幅提高了并发数和处理速度，愈发收到人们的喜爱，但由于 Nginx 本身只是单纯的 HTTP Server，如果执行 php，需要配合 CGI 来完成，Nginx 把请求转发给 fastcig 管理进程，处理之后在将结果返回给 Nginx。 什么是 PHP-FPM相对于 Spawn-FCGI，PHP-FPM 在内存和CPU方面的控制更胜一筹，PHP-FPM 提供了更好的PHP进程管理方式。PHP-FPM 对于 PHP5.3 之前来说就是一个补丁，将 FastCGI 进程管理整合到PHP中，在 PHP 5.4 之后，PHP-FPM 已经集成到 PHP 的软件包中，在编译 PHP 过程中，增加 --enable-fpm 参数即可开启 PHP-FPM 环境介绍系统环境本文的安装环境采用：CentOS Linux release 7.1.1503 (Core) 软件获取 Nginx 官方网站：http://nginx.org最新稳定版本：nginx-1.8.1.tar.gz帮助文档：http://nginx.org/en/docs编译参数说明：http://nginx.org/en/docs/configure.html PHP 官方网站：http://www.php.net稳定版：php-5.6.17.tar.gz 软件仓库 yum 仓库包含 CentOS 官方和 EPEL 两个安装源1rpm -ivh http://mirrors.yun-idc.com/epel/7/x86_64/e/epel-release-7-5.noarch.rpm 安装 Nginx安装模块依赖包Nginx 的 gzip、rewrite、ssl 模块分别需要 zlib、pcre、openssl 的支持，可以通过源码或 yum 工具来安装 安装zlib 12\\ 使用 gzip 压缩yum install zlib zlib-devel -y 安装 pcre 12\\ 使用 rewrite 功能yum install pcre pcre-devel 安装 openssl 12\\ 如果需要 ssl 支持,不需要可以不安装yum install openssl openssl-devel 安装 Nginx1234wget http://nginx.org/download/nginx-1.8.1.tar.gztar zxf nginx-1.8.1.tar.gz./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_stub_status_module --with-pcremake &amp;&amp; make install 启动 Nginx，测试安装Nginx 的默认端口是 80，启动之前要确保 80 端口没有被占用，如果想保留 80 端口，只需要在 Nginx 配置文件中，listen 80；中80换成其他端口。12345678910//启动 nginx/usr/local/nginx/sbin/nginx// 检查80端口是否启动netstat -ntplActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 28608/nginx: master tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 917/sshd tcp6 0 0 :::22 :::* LISTEN 917/sshd 通过浏览器访问 Nginx Server 会出现欢迎页面，说明 nginx 安装正常 安装 PHP 及 PHP-FPM 安装依赖软件包 确保安装之前有安装 gd、png、curl、xml 等 lib 开发库1yum install gd-devel libjpeg-devel libpng-devel libxml2-devel bzip2-devel libcurl-devel -y 下载软件包 123wget http://cn2.php.net/distributions/php-5.6.17.tar.gztar zxf php-5.6.17.tar.gz cd php-5.6.17/ 编译安装 php5.6 以下参数支持，ftp、图片函数、pdo 等，因为使用了 php 自带的 mysqlnd，所以不需要额外安装 mysql 的 lib 库，如果是 64 位系统，参数后面需要添加 –wtih-libdir=lib6412./configure --prefix=/usr/local/php --with-config-file-path=/usr/local/php/etc --with-bz2 --with-curl --enable-ftp --enable-sockets --disable-ipv6 --with-gd --with-jpeg-dir=/usr/local --with-png-dir=/usr/local --with-freetype-dir=/usr/local --enable-gd-native-ttf --with-iconv-dir=/usr/local --enable-mbstring --enable-calendar --with-gettext --with-libxml-dir=/usr/local --with-zlib --with-pdo-mysql=mysqlnd --with-mysqli=mysqlnd --with-mysql=mysqlnd --enable-dom --enable-xml --enable-fpm --with-libdir=lib64make &amp;&amp; make install 注： 编译参数可以根据实际需求，增加或者删减 配置 php-fpm 12cp php.ini-production /usr/local/php/etc/php.inicp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf 启动 PHP-FPM 1234567891011121314systemctl start php-fpm// init方式cp /usr/local/src/php-5.6.17/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpmchmod +x /etc/init.d/php-fpm/etc/init.d/php-fpm start//执行没有报错，说明启动成功，还可以通过端口检查服务是否启动,9000 端口是 fpm 的服务端口netstat -ntplActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN 23723/php-fpm tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1423/sshd tcp 0 0 :::22 :::* LISTEN 1423/sshd 配置 Nginxnginx主配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960cat nginx.confuser nobody;worker_processes 8; worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 1000000;worker_rlimit_nofile 65535;error_log logs/error.log notice;#error_log logs/error.log info;pid logs/nginx.pid;events &#123; use epoll; worker_connections 10240;&#125;http &#123; include mime.types; default_type application/octet-stream; server_names_hash_bucket_size 128; client_header_buffer_size 32k; client_body_buffer_size 32k; client_max_body_size 8m; large_client_header_buffers 4 32k; log_format access &apos;$http_host $remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot;&apos;; index index.php index.html; autoindex off; fastcgi_intercept_errors on; #access_log logs/access.log main; sendfile on; tcp_nopush on; tcp_nodelay off; keepalive_timeout 65; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; gzip on; gzip_min_length 1k; gzip_http_version 1.0; gzip_comp_level 2; gzip_buffers 4 16k; gzip_proxied any; gzip_disable &quot;MSIE [1-6]\.&quot;; gzip_types text/plain text/css application/x-javascript application/xml application/xml+rss text/javascript; gzip_vary on; server_name_in_redirect off; include /usr/local/nginx/conf/vhost/*.conf;&#125; 虚拟主机配置文件增加测试站点www.zerounix.com 12345678910111213141516171819server &#123; listen 80; server_name www.zerounix.com; root /data/website/www.zerounix.com; charset utf-8; index index.php index.html index.htm ; access_log logs/www.zerounix.com_access.log access; error_log logs/www.zerounix.com_error.log; location / &#123; try_files $uri $uri/ /index.php$is_args$args; &#125; location ~ .*\.(php|php5)$ &#123; fastcgi_pass 127.0.0.1:9000; include fastcgi.conf; try_files $uri =404; &#125;&#125; Nginx 将会连接回环地址 9000 端口执行 php 文件，需要使用 tcp/ip 协议，速度较慢，建议设置为 socket 方式连接。将 fastcgi_pass 127.0.0.1:9000 变更为 fastcgi_pass unix:/dev/shm/php-fpm.socket; 同时变更 php-fpm 配置文件，在 listen = 127.0.0.1:9000 添加 listen = /dev/shm/php5-fpm.socket;分别重启 nginx 和 php-fpm 服务 启动 Nginx1/usr/local/nginx/sbin/nginx 创建 PHP 测试文件在/data/website/www.zerounix.com/phpinfo.php 添加123&lt;?php var_export($_SERVER)?&gt; 测试访问12345678910111213141516171819202122232425262728293031curl -x 172.16.11.210:80 www.zerounix.com/phpinfo.phparray ( &apos;USER&apos; =&gt; &apos;nobody&apos;, &apos;HOME&apos; =&gt; &apos;/&apos;, &apos;FCGI_ROLE&apos; =&gt; &apos;RESPONDER&apos;, &apos;SCRIPT_FILENAME&apos; =&gt; &apos;/data/website/www.zerounix.com/phpinfo.php&apos;, &apos;QUERY_STRING&apos; =&gt; &apos;&apos;, &apos;REQUEST_METHOD&apos; =&gt; &apos;GET&apos;, &apos;CONTENT_TYPE&apos; =&gt; &apos;&apos;, &apos;CONTENT_LENGTH&apos; =&gt; &apos;&apos;, &apos;SCRIPT_NAME&apos; =&gt; &apos;/phpinfo.php&apos;, &apos;REQUEST_URI&apos; =&gt; &apos;/phpinfo.php&apos;, &apos;DOCUMENT_URI&apos; =&gt; &apos;/phpinfo.php&apos;, &apos;DOCUMENT_ROOT&apos; =&gt; &apos;/data/website/www.zerounix.com&apos;, &apos;SERVER_PROTOCOL&apos; =&gt; &apos;HTTP/1.1&apos;, &apos;GATEWAY_INTERFACE&apos; =&gt; &apos;CGI/1.1&apos;, &apos;SERVER_SOFTWARE&apos; =&gt; &apos;nginx/1.8.1&apos;, &apos;REMOTE_ADDR&apos; =&gt; &apos;172.16.11.210&apos;, &apos;REMOTE_PORT&apos; =&gt; &apos;55060&apos;, &apos;SERVER_ADDR&apos; =&gt; &apos;172.16.11.210&apos;, &apos;SERVER_PORT&apos; =&gt; &apos;80&apos;, &apos;SERVER_NAME&apos; =&gt; &apos;www.zerounix.com&apos;, &apos;REDIRECT_STATUS&apos; =&gt; &apos;200&apos;, &apos;HTTP_USER_AGENT&apos; =&gt; &apos;curl/7.29.0&apos;, &apos;HTTP_HOST&apos; =&gt; &apos;www.zerounix.com&apos;, &apos;HTTP_ACCEPT&apos; =&gt; &apos;*/*&apos;, &apos;HTTP_PROXY_CONNECTION&apos; =&gt; &apos;Keep-Alive&apos;, &apos;PHP_SELF&apos; =&gt; &apos;/phpinfo.php&apos;, &apos;REQUEST_TIME_FLOAT&apos; =&gt; 1454568561.60866, &apos;REQUEST_TIME&apos; =&gt; 1454568561, ) 说明 php 解析正常 总结Nginx 安装配置相对容易，但是要调优就是另外一件事了，如果设定的不恰当，在高并发的时候，经常会出现 502 Bad Gateway。之后会研究下调优的为问题。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx配置文件详解]]></title>
      <url>http://czero000.github.io/2016/02/04/nginx-configfile-detail.html</url>
      <content type="text"><![CDATA[nginx 主配置文件详解安装 nginx 后，会在安装目录下生成 conf 目录，目录中 nginx.conf 便是 nginx 的主配置文件，nginx 是基于模块化的构建方式，在 ningx 配置文件中也有体现，可以分为核心模块、事件模块、邮件模块、HTTP 模块。 核心模块123456789user nobody; // 指定 nginx 运行的用户和组，默认为 nobodyworker_processes 8; // 开启 nginx 的进程数，与 cpu 核数一致worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 1000000; // 将每个 nginx 进程绑定到一个CPU上worker_rlimit_nofile 65535; // 指定 nginx 进程打开的最多文件描述符数量，受系统的最大文件打开数限制error_log logs/error.log; notice; // 设定全局错误日志文件，以什么级别显示，有 [debug、info、warn、error、crit] 模式可选，按照实际情况设定#error_log logs/error.log info; pid logs/nginx.pid; // 指定进程 id 的存储文件位置 事件模块1234events &#123; use epoll; // 工作模式设定为 epoll，还有 select、poll、kqueue、rtsig 和 /dev/poll 模式可选 worker_connections 65535; // 定义每个进程的最大连接数，受系统的最大文件打开数限制&#125; http 模块12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364http &#123; include mime.types; // 文件拓展名与文件类型映射表 default_type application/octet-stream; // 默认文件类型 charset utf-8; // 默认编码 #autoindex on ; // 关闭目录别表访问，默认关闭 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; // 设置日志格式 &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; sendfile on; //开启高效文件传输模式，如果进行下载等磁盘 IO 重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成 off。 #tcp_nopush on; // 开启防止网络阻塞 #keepalive_timeout 0; keepalive_timeout 65; // 设置客户端连接报错活动的超时时间 tcp_nodelay on; // 反向代理设置 proxy_connect_timeout 30; proxy_send_timeout 30; proxy_read_timeout 30; proxy_buffer_size 32k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 128k; proxy_ignore_client_abort on; proxy_headers_hash_max_size 51200; proxy_headers_hash_bucket_size 6400; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header x-forwarded-for $proxy_add_x_forwarded_for; //后端的Web服务器可以通过 X-Forwarded-For 获取用户真实IP server_names_hash_bucket_size 128; // 服务器名字的 hash 表大小 client_header_buffer_size 32k; // 指定 client 请求头的 hearder buffers 大小 large_client_header_buffers 4 32k; // 大请求缓冲区数量和大小 client_max_body_size 8m; // 设置 client 请求的最大单个文件字节数 client_body_temp_path /dev/shm/client_body_temp; // 指定连接请求试图写入缓存文件的目录路径 // FastCGI 相关参数设定 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; // Gzip 相关参数设定 gzip on; // 开启 gzip 压缩 gzip_min_length 1k; // 设置允许压缩的页面最小字节 gzip_http_version 1.0; // 设置识别 http 协议的版本，默认是 1.1 gzip_comp_level 2; // 设置压缩比，1-9 gzip_buffers 4 16k; // 设置 4 个单位 16k 的内存作为压缩结果流缓存 gzip_proxied any; // nginx 做前端代理时启用该选项，表示无论后端服务器的 headers 头返回什么信息，都无条件启用压缩 gzip_disable &quot;MSIE [1-6]\.&quot;; // 禁用 IE1-6 的 gzip 压缩 gzip_types text/plain text/css application/x-javascript application/xml application/xml+rss text/javascript; // 什么类型的页面或文档启用压缩 gzip_vary on; server_name_in_redirect off; // nginx 在处理自己内部重定向时不默认使用 server_name 设置中的第一个域名 include vhost/*.conf;&#125; 虚拟主机文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667server &#123; listen 80; // 监听端口 server_name www.zerounix.com // 域名，可以多个，用空格分隔 root /data/htdocs/www.zerounix.com; // 虚拟主机根目录 charset uft-8; // 访问编码 access_log logs/www.zerounix.com_access.log access; //设置虚拟主机访问日志的存放路径和格式main error_log logs/www.zerounix.com_error.log; // 错误日志 location / &#123; index index.php index.htm // 甚至首页索引文件类型 &#125; error_page 404 /404.html; // 定义 404 页面 error_page 500 502 503 504 /50x.html; // 定义 50x 页面 location = /50x.html &#123; root html; &#125; // php 请求转发到本地 9000，交给 fastcig 处理 location ~.*\.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; // 设置 nginx status 页面 location /status &#123; stub_status on; access_log logs/www.zerounix.com_status.log; auth_basic &quot;NginxStatus&quot; auth_baaic_user_file conf/htpasswd; // apache 提供的 htpasswd 工具 &#125; // 图片缓存时间 location ~ .*\.(gif|jpg|jpeg|png|bmp|sfw)$ &#123; expires 10d; &#125; // JS 和 CSS 缓存时间 location ~ .*\.&#123;js|css&#125;$ &#123; expires 1h; &#125; //所有静态文件由nginx直接读取不经过 tomcat 或 resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$ &#123; expires 15d; &#125; // 本地动静分离反向代理配置，所有 jsp 的页面均交由 tomcat 或 resin 处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; #对 &quot;/&quot; 启用反向代理 location / &#123; proxy_pass http://18.26.154.72:8090; proxy_redirect off; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx负载均衡]]></title>
      <url>http://czero000.github.io/2016/02/04/nginx-loadbalance.html</url>
      <content type="text"><![CDATA[Nginx负载均衡nginx不单可以作为强大的 web 服务器，也可以作为一个反向代理服务器，而且nginx还可以按照调度规则实现动态、静态页面的分离，可以按照轮询、 ip 哈希、 URL 哈希、权重等多种方式对后端服务器做负载均衡，同时还支持后端服务器的健康检查。 如果只有一台服务器时,这个服务器挂了,那么对于网站来说是个灾难.因此，这时候的负载均衡就会大显身手了,它会自动剔除挂掉的服务器. 安装Nginx略 Nginx 负载均衡一些基础知识nginx 的 upstream 目前支持 4 种方式的分配 轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 ip_hash 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 fair（第三方） 按后端服务器的响应时间来分配请求，响应时间短的优先分配。 url_hash（第三方） 配置：在http节点里添加1234567定义负载均衡设备的 IP及设备状态upstream myServer &#123; server 127.0.0.19090 down; server 127.0.0.18080 weight=2; server 127.0.0.16060; server 127.0.0.17070 backup;&#125; 在需要使用负载的 Server节点下添加1proxy_pass httpmyServer; 1 upstream 每个设备的状态2 down 表示单前 的server 暂时不参与负载3 weight 默认为1. weight 越大，负载的权重就越大。4 max_fails ：允许请求失败的次数默认为 1.当超过最大次数时，返回 proxy_next_upstream 模块定义的错误5 fail_timeoutmax_fails 次失败后，暂停的时间。6 backup： 其它所有的非 backup 机器 down 或者忙的时候，请求 backup 机器。所以这台机器压力会最轻。 Nginx 还支持多组的负载均衡,可以配置多个 upstream 来服务于不同的 Server.配置负载均衡比较简单,但是最关键的一个问题是怎么实现多台服务器之间 session 的共享下面有几种方法(以下内容来源于网络,第四种方法没有实践.) 不使用 session，换作 cookie能把 session改成 cookie，就能避开 session 的一些弊端，在从前看的一本 J2EE 的书上，也指明在集群系统中不能用 session，否则惹出祸端来就不好办。如果系统不复杂，就优先考虑能否将 session 去掉，改动起来非常麻烦的话，再用下面的办法。 应用服务器自行实现共享asp.net 可以用数据库或 memcached 来保存 session，从而在 asp.net 本身建立了一个session 集群，用这样的方式可以令 session 保证稳定，即使某个节点有故障，session也不会丢失，适用于较为严格但请求量不高的场合。但是它的效率是不会很高的，不适用于对效率 要求高的场合。 以上两个办法都跟 nginx 没什么关系，下面来说说用 nginx 该如何处理： ip_hashnginx 中的 ip_hash 技术能够将某个 ip 的请求定向到同一台后端，这样一来这个 ip 下的某个客户端和某个后端就能建立起稳固的 session，ip_hash 是在 upstream配置中定义的12345upstream backend &#123; server 127.0.0.18080 ; server 127.0.0.19090 ; ip_hash;&#125; ip_hash 是容易理解的，但是因为仅仅能用 ip 这个因子来分配后端，因此 ip_hash是有缺陷的，不能在一些情况下使用 nginx 不是最前端的服务器。ip_hash 要求 nginx 一定是最前端的服务器，否则 nginx 得不到正确 ip，就不能根据 ip 作 hash。譬如使用的是squid为最前端，那么 nginx 取 i p时只能得到 squid 的服务器 ip 地址，用这个地址来作分流是肯定错乱的。 nginx 的后端还有其它方式的负载均衡。假如 nginx 后端又有其它负载均衡，将请求又通过另外的方式分流了，那么某个客户端的请求肯定不能定位到同一台 session应用服务器上。这么算起来，nginx 后端只能直接指向应用服务器，或者再搭一个 squid，然后指向应用服务器。最好的办法是用location 作一次分流，将需要 session 的部分请求通过 ip_hash 分流，剩下的走其它后端去。 upstream_hash为了解决 ip_hash 的一些问题，可以使用 upstream_hash 这个第三方模块，这个模块多数情况下是用作 url_hash 的，但是并不妨碍将它用来做 session 共享： 假如前端是 squid，他会将 ip 加入 x_forwarded_for 这个 http_header 里，用upstream_hash 可以用这个头做因子，将请求定向到指定的后端： 可见这篇文档：httpwww.sudone.comnginxnginx_url_hash.html在文档中是使用 $request_uri 做因子，稍微改一下：1hash $http_x_forwarded_for; 这样就改成了利用 x_forwarded_for 这个头作因子，在 nginx 新版本中可支持读取 cookie 值，所以也可以改成：1hash $cookie_jsessionid; 假如在php中配置的 session 为无 cookie方式，配合nginx自己的一个 userid_module 模块就可以用nginx自发一个 cookie，可参见 userid模块的英文文档： httpwiki.nginx.orgNginxHttpUserIdModule 另可用姚伟斌编写的模块 upstream_jvm_route：httpcode.google.compnginx-upstream-jvm-route]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx编译参数详解]]></title>
      <url>http://czero000.github.io/2016/02/04/nginx-compiler-parameters.html</url>
      <content type="text"><![CDATA[编译参数 说明 –prefix= 指向安装目录 –sbin-path 指向（执行）程序文件（nginx） –conf-path= 指向配置文件（nginx.conf） –error-log-path= 指向错误日志目录 –pid-path= 指向 pid 文件（nginx.pid） –lock-path= 指向 lock 文件（nginx.lock）（安装文件锁定，防止安装文件被别人利用，或自己误操作） –user= 指定程序运行时的非特权用户 –group= 指定程序运行时的非特权用户组 –builddir= 指向编译目录 –with-rtsig_module 启用 rtsig 模块支持（实时信号） –with-select_module 启用 select 模块支持（一种轮询模式,不推荐在高载环境下使用）禁用：–without-select_module –with-poll_module 启用 poll 模块支持（功能与 select 相同，与select特性相同，为一种轮询模式,不推荐在高载环境下使用） –with-file-aio 启用 file aio 支持（一种APL文件传输格式） –with-ipv6 启用ipv6支持 –with-http_ssl_module 启用ngx_http_ssl_module支持（使支持https请求，需已安装openssl） –with-http_realip_module 启用ngx_http_realip_module支持（这个模块允许从请求标头更改客户端的IP地址值，默认为关） –with-http_addition_module 启用ngx_http_addition_module支持（作为一个输出过滤器，支持不完全缓冲，分部分响应请求） –with-http_xslt_module 启用ngx_http_xslt_module支持（过滤转换XML请求） –with-http_image_filter_module 启用 ngx_http_image_filter_module支持（传输JPEG/GIF/PNG 图片的一个过滤器）（默认为不启用。gd库要用到） –with-http_geoip_module 启用 ngx_http_geoip_module支持（该模块创建基于与MaxMind GeoIP二进制文件相配的客户端IP地址的ngx_http_geoip_module变量） –with-http_sub_module 启用 ngx_http_sub_module支持（允许用一些其他文本替换nginx响应中的一些文本） –with-http_dav_module 启用 ngx_http_dav_module支持（增加PUT,DELETE,MKCOL：创建集合,COPY和MOVE方法）默认情况下为关闭，需编译开启 –with-http_flv_module 启用 ngx_http_flv_module支持（提供寻求内存使用基于时间的偏移量文件） –with-http_gzip_static_module 启用 ngx_http_gzip_static_module支持（在线实时压缩输出数据流） –with-http_random_index_module 启用ngx_http_random_index_module支持（从目录中随机挑选一个目录索引） –with-http_secure_link_module 启用ngx_http_secure_link_module支持（计算和检查要求所需的安全链接网址） –with-http_degradation_module 启用ngx_http_degradation_module支持（允许在内存不足的情况下返回204或444码） –with-http_stub_status_module 启用ngx_http_stub_status_module支持（获取nginx自上次启动以来的工作状态） –without-http_charset_module 禁用ngx_http_charset_module支持（重新编码web页面，但只能是一个方向–服务器端到客户端，并且只有一个字节的编码可以被重新编码） –without-http_gzip_module 禁用ngx_http_gzip_module支持（该模块同-with-http_gzip_static_module功能一样） –without-http_ssi_module 禁用ngx_http_ssi_module支持（该模块提供了一个在输入端处理处理服务器包含文件（SSI）的过滤器，目前支持SSI命令的列表是不完整的） –without-http_userid_module 禁用ngx_http_userid_module支持（该模块用来处理用来确定客户端后续请求的cookies） –without-http_access_module 禁用ngx_http_access_module支持（该模块提供了一个简单的基于主机的访问控制。允许/拒绝基于ip地址） –without-http_auth_basic_module 禁用ngx_http_auth_basic_module（该模块是可以使用用户名和密码基于http基本认证方法来保护你的站点或其部分内容） –without-http_autoindex_module 禁用disable ngx_http_autoindex_module支持（该模块用于自动生成目录列表，只在ngx_http_index_module模块未找到索引文件时发出请求。） –without-http_geo_module 禁用ngx_http_geo_module支持（创建一些变量，其值依赖于客户端的IP地址） –without-http_map_module 禁用ngx_http_map_module支持（使用任意的键/值对设置配置变量） –without-http_split_clients_module 禁用ngx_http_split_clients_module支持（该模块用来基于某些条件划分用户。条件如：ip地址、报头、cookies等等） –without-http_referer_module 禁用disable ngx_http_referer_module支持（该模块用来过滤请求，拒绝报头中Referer值不正确的请求） –without-http_rewrite_module 禁用ngx_http_rewrite_module支持（该模块允许使用正则表达式改变URI，并且根据变量来转向以及选择配置。如果在server级别设置该选项，那么他们将在 location之前生效。如果在location还有更进一步的重写规则，location部分的规则依然会被执行。如果这个URI重写是因为location部分的规则造成的，那么 location部分会再次被执行作为新的URI。 这个循环会执行10次，然后Nginx会返回一个500错误。） –without-http_proxy_module 禁用ngx_http_proxy_module支持（有关代理服务器） –without-http_fastcgi_module 禁用ngx_http_fastcgi_module支持（该模块允许Nginx 与FastCGI 进程交互，并通过传递参数来控制FastCGI 进程工作。 ）FastCGI一个常驻型的公共网关接口。 –without-http_uwsgi_module 禁用ngx_http_uwsgi_module支持（该模块用来医用uwsgi协议，uWSGI服务器相关） –without-http_scgi_module 禁用ngx_http_scgi_module支持（该模块用来启用SCGI协议支持，SCGI协议是CGI协议的替代。它是一种应用程序与HTTP服务接口标准。它有些像FastCGI但他的设计 更容易实现。） –without-http_memcached_module 禁用ngx_http_memcached_module支持（该模块用来提供简单的缓存，以提高系统效率） -without-http_limit_zone_module 禁用ngx_http_limit_zone_module支持（该模块可以针对条件，进行会话的并发连接数控制） –without-http_limit_req_module 禁用ngx_http_limit_req_module支持（该模块允许你对于一个地址进行请求数量的限制用一个给定的session或一个特定的事件） –without-http_empty_gif_module 禁用ngx_http_empty_gif_module支持（该模块在内存中常驻了一个1*1的透明GIF图像，可以被非常快速的调用） –without-http_browser_module 禁用ngx_http_browser_module支持（该模块用来创建依赖于请求报头的值。如果浏览器为modern ，则$modern_browser等于modern_browser_value指令分配的值；如 果浏览器为old，则$ancient_browser等于 ancient_browser_value指令分配的值；如果浏览器为 MSIE中的任意版本，则 $msie等于1） –without-http_upstream_ip_hash_module 禁用ngx_http_upstream_ip_hash_module支持（该模块用于简单的负载均衡） –with-http_perl_module 启用ngx_http_perl_module支持（该模块使nginx可以直接使用perl或通过ssi调用perl） –with-perl_modules_path= 设定perl模块路径 –with-perl= 设定perl库文件路径 –http-log-path= 设定access log路径 –http-client-body-temp-path= 设定http客户端请求临时文件路径 –http-proxy-temp-path= 设定http代理临时文件路径 –http-fastcgi-temp-path= 设定http fastcgi临时文件路径 –http-uwsgi-temp-path= 设定http uwsgi临时文件路径 –http-scgi-temp-path= 设定http scgi临时文件路径 -without-http 禁用http server功能 –without-http-cache 禁用http cache功能 –with-mail 启用POP3/IMAP4/SMTP代理模块支持 –with-mail_ssl_module 启用ngx_mail_ssl_module支持 –without-mail_pop3_module 禁用pop3协议（POP3即邮局协议的第3个版本,它是规定个人计算机如何连接到互联网上的邮件服务器进行收发邮件的协议。是因特网电子邮件的第一个离线协议标 准,POP3协议允许用户从服务器上把邮件存储到本地主机上,同时根据客户端的操作删除或保存在邮件服务器上的邮件。POP3协议是TCP/IP协议族中的一员，主要用于 支持使用客户端远程管理在服务器上的电子邮件） –without-mail_imap_module 禁用imap协议（一种邮件获取协议。它的主要作用是邮件客户端可以通过这种协议从邮件服务器上获取邮件的信息，下载邮件等。IMAP协议运行在TCP/IP协议之上， 使用的端口是143。它与POP3协议的主要区别是用户可以不用把所有的邮件全部下载，可以通过客户端直接对服务器上的邮件进行操作。） –without-mail_smtp_module 禁用smtp协议（SMTP即简单邮件传输协议,它是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式。SMTP协议属于TCP/IP协议族，它帮助每台计算机在发送或中转信件时找到下一个目的地。） –with-google_perftools_module 启用ngx_google_perftools_module支持（调试用，剖析程序性能瓶颈） –with-cpp_test_module 启用ngx_cpp_test_module支持 –add-module= 启用外部模块支持 –with-cc= 指向C编译器路径 –with-cpp= 指向C预处理路径 –with-cc-opt= 设置C编译器参数（PCRE库，需要指定–with-cc-opt=”-I /usr/local/include”，如果使用select()函数则需要同时增加文件描述符数量，可以通过–with-cc- opt=”-D FD_SETSIZE=2048”指定。） –with-ld-opt= 设置连接文件参数。（PCRE库，需要指定–with-ld-opt=”-L /usr/local/lib”。） –with-cpu-opt= 指定编译的CPU，可用的值为: pentium, pentiumpro, pentium3, pentium4, athlon, opteron, amd64, sparc32, sparc64, ppc64 –without-pcre 禁用pcre库 –with-pcre 启用pcre库 –with-pcre= 指向pcre库文件目录 –with-pcre-opt= 在编译时为pcre库设置附加参数 –with-md5= 指向md5库文件目录（消息摘要算法第五版，用以提供消息的完整性保护） –with-md5-opt= 在编译时为md5库设置附加参数 –with-md5-asm 使用md5汇编源 –with-sha1= 指向sha1库目录（数字签名算法，主要用于数字签名） –with-sha1-opt= 在编译时为sha1库设置附加参数 –with-sha1-asm 使用sha1汇编源 –with-zlib= 指向zlib库目录 –with-zlib-opt= 在编译时为zlib设置附加参数 –with-zlib-asm= 为指定的CPU使用zlib汇编源进行优化，CPU类型为pentium, pentiumpro –with-libatomic 为原子内存的更新操作的实现提供一个架构 –with-libatomic= 指向libatomic_ops安装目录 –with-openssl= 指向openssl安装目录 –with-openssl-opt 在编译时为openssl设置附加参数 –with-debug 启用debug日志]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx源码安装]]></title>
      <url>http://czero000.github.io/2016/01/27/source-buile-nginx.html</url>
      <content type="text"><![CDATA[环境介绍系统版本系统环境默认采用 CentOS Linux release 7.1.1503 (Core)， 软件获取官方网站：http://nginx.org最新稳定版本：nginx-1.8.1.tar.gz帮助文档：http://nginx.org/en/docs编译参数说明：http://nginx.org/en/docs/configure.html 软件仓库yum 仓库包含 centos 官方和 epel 两个安装源1rpm -ivh http://mirrors.yun-idc.com/epel/7/x86_64/e/epel-release-7-5.noarch.rpm Nginx 安装安装依赖软件 安装 pcre 12\\ 使用 rewrite 功能yum install pcre pcre-devel 安装 openssl 12\\ 如果需要 ssl 支持,不需要可以不安装yum install openssl openssl-devel 安装 nginx1234tar -zxf nginx-1.8.1.tar.gz cd nginx-1.8.1/./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_stub_status_module --with-pcremake &amp;&amp; make install –with-http_ssl_module —支持 https –with-http_stub_status_module —支持 nginx 状态查询 –with-pcre —支持 rewrite nginx启动、停止、重启启动现在 nginx 就可以启动，不需要更改任何配置文件。12\\-c 参数指定了配置文件的路径，如果不加 -c，nginx 就会默认加载其安装目录下面的 conf 目录下面的 nginx.conf 文件/usr/local/nginx/sbin/nginx 停止1/usr/local/nginx/sbin/nginx -s stop[quit,reopen,reload] Nginx 的停止命令有很多，一般都是通过发送系统信号给 nginx 的主进程来停止 nginx,例如：12345678910111213\\停止 nginxkill –QUIT `主进程号`kill -QUIT `cat /usr/local/nginx/logs/nginx.pid` \\快速停止 nginxkill –TERM `主进程号`kill –TERM `cat /usr/local/nginx/logs/nginx.pid`kill –INT `主进程号`kill –INT`cat /usr/local/nginx/logs/nginx.pid`\\强制停止 nginxKill -9 nginx 重启1/usr/local/nginx/sbin/nginx -s reload[stop,quit,reopen] 同样可以通过信号来重启 nginx12Kill –HUB `主进程号`kill –HUB `cat /usr/local/nginx/logs/nginx.pid`]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[常用正则速查]]></title>
      <url>http://czero000.github.io/2016/01/22/regex_fast_reference.html</url>
      <content type="text"><![CDATA[常用正则匹配12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&quot;^\d+$&quot; // 非负整数（正整数 + 0）&quot;^[0-9]*[1-9][0-9]*$&quot; // 正整数&quot;^((-\d+)|(0+))$&quot; // 非正整数（负整数 + 0）&quot;^-[0-9]*[1-9][0-9]*$&quot; // 负整数&quot;^-?\d+$&quot;// 整数&quot;^\d+(\.\d+)?$&quot; //非负浮点数（正浮点数 + 0）&quot;^(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*))$&quot; //正浮点数&quot;^((-\d+(\.\d+)?)|(0+(\.0+)?))$&quot; //非正浮点数（负浮点数 + 0）&quot;^(-(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*)))$&quot;//负浮点数&quot;^(-?\d+)(\.\d+)?$&quot; //浮点数&quot;^[A-Za-z]+$&quot; //英文字母字符串&quot;^[A-Z]+$&quot; //英文大写字符串&quot;^[a-z]+$&quot; //英文小写字符串&quot;^[A-Za-z0-9]+$&quot; //数字和26个英文字符串&quot;^\w+$&quot; //数字、英文或者下划线字符串&quot;^[\w-]+(\.[\w-]+)*@[\w-]+(\.[\w-]+)+$&quot; //email地址&quot;^[a-zA-z]+://(\w+(-\w+)*)(\.(\w+(-\w+)*))*(\?\S*)?$&quot; //url/^(d&#123;2&#125;|d&#123;4&#125;)-((0([1-9]&#123;1&#125;))|(1[1|2]))-(([0-2]([1-9]&#123;1&#125;))|(3[0|1]))$/ // 年-月-日/^((0([1-9]&#123;1&#125;))|(1[1|2]))/(([0-2]([1-9]&#123;1&#125;))|(3[0|1]))/(d&#123;2&#125;|d&#123;4&#125;)$/ // 月/日/年&quot;^([w-.]+)@(([[0-9]&#123;1,3&#125;.[0-9]&#123;1,3&#125;.[0-9]&#123;1,3&#125;.)|(([w-]+.)+))([a-zA-Z]&#123;2,4&#125;|[0-9]&#123;1,3&#125;)(]?)$&quot; // Emil/^((\+?[0-9]&#123;2,4&#125;\-[0-9]&#123;3,4&#125;\-)|([0-9]&#123;3,4&#125;\-))?([0-9]&#123;7,8&#125;)(\-[0-9]+)?$/ // 电话号码&quot;^(d&#123;1,2&#125;|1dd|2[0-4]d|25[0-5]).(d&#123;1,2&#125;|1dd|2[0-4]d|25[0-5]).(d&#123;1,2&#125;|1dd|2[0-4]d|25[0-5]).(d&#123;1,2&#125;|1dd|2[0-4]d|25[0-5])$&quot; // IP地址匹配中文字符的正则表达式：[\u4e00-\u9fa5]匹配双字节字符(包括汉字在内)：[^\x00-\xff]匹配空行的正则表达式：\n[\s| ]*\r匹配HTML标记的正则表达式：/&lt;(.*)&gt;.*&lt;\/\1&gt;|&lt;(.*) \/&gt;/匹配首尾空格的正则表达式：(^\s*)|(\s*$)匹配Email地址的正则表达式：\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*匹配网址URL的正则表达式：^[a-zA-z]+://(\\w+(-\\w+)*)(\\.(\\w+(-\\w+)*))*(\\?\\S*)?$匹配帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]&#123;4,15&#125;$匹配国内电话号码：(\d&#123;3&#125;-|\d&#123;4&#125;-)?(\d&#123;8&#125;|\d&#123;7&#125;)?匹配腾讯QQ号：^[1-9]*[1-9][0-9]*$ 元字符及其在正则表达式上下文中的行为12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个后向引用、或一个八进制转义符。^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的Multiline 属性，^ 也匹配 ’\n’ 或 ’\r’ 之后的位置。$ 匹配输入字符串的结束位置。如果设置了 RegExp 对象的Multiline 属性，$ 也匹配 ’\n’ 或 ’\r’ 之前的位置。* 匹配前面的子表达式零次或多次。+ 匹配前面的子表达式一次或多次。+ 等价于 &#123;1,&#125;。? 匹配前面的子表达式零次或一次。? 等价于 &#123;0,1&#125;。&#123;n&#125; n 是一个非负整数，匹配确定的n 次。&#123;n,&#125; n 是一个非负整数，至少匹配n 次。&#123;n,m&#125; m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。在逗号和两个数之间不能有空格。? 当该字符紧跟在任何一个其他限制符 (*, +, ?, &#123;n&#125;, &#123;n,&#125;, &#123;n,m&#125;) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。. 匹配除 “\n” 之外的任何单个字符。要匹配包括 ’\n’ 在内的任何字符，请使用象 ’[.\n]’ 的模式。(pattern) 匹配pattern 并获取这一匹配。(?:pattern) 匹配pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。(?=pattern) 正向预查，在任何匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。(?!pattern) 负向预查，与(?=pattern)作用相反x|y 匹配 x 或 y。[xyz] 字符集合。[^xyz] 负值字符集合。[a-z] 字符范围，匹配指定范围内的任意字符。[^a-z] 负值字符范围，匹配任何不在指定范围内的任意字符。\b 匹配一个单词边界，也就是指单词和空格间的位置。\B 匹配非单词边界。\cx 匹配由x指明的控制字符。\d 匹配一个数字字符。等价于 [0-9]。\D 匹配一个非数字字符。等价于 [^0-9]。\f 匹配一个换页符。等价于 \x0c 和 \cL。\n 匹配一个换行符。等价于 \x0a 和 \cJ。\r 匹配一个回车符。等价于 \x0d 和 \cM。\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]。\S 匹配任何非空白字符。等价于 [^ \f\n\r\t\v]。\t 匹配一个制表符。等价于 \x09 和 \cI。\v 匹配一个垂直制表符。等价于 \x0b 和 \cK。\w 匹配包括下划线的任何单词字符。等价于’[A-Za-z0-9_]’。\W 匹配任何非单词字符。等价于 ’[^A-Za-z0-9_]’。\xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。\num 匹配 num，其中num是一个正整数。对所获取的匹配的引用。\n 标识一个八进制转义值或一个后向引用。如果 \n 之前至少 n 个获取的子表达式，则 n 为后向引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。\nm 标识一个八进制转义值或一个后向引用。如果 \nm 之前至少有is preceded by at least nm 个获取得子表达式，则 nm 为后向引用。如果 \nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的后向引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 \nm 将匹配八进制转义值 nm。\nml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。\un 匹配 n，其中 n 是一个用四个十六进制数字表示的Unicode字符。匹配中文字符的正则表达式：[u4e00-u9fa5]匹配双字节字符(包括汉字在内)：[^x00-xff]匹配空行的正则表达式：n[s| ]*r匹配HTML标记的正则表达式：/&lt;(.*)&gt;.*&lt;/1&gt;|&lt;(.*) /&gt;/匹配首尾空格的正则表达式：(^s*)|(s*$)匹配Email地址的正则表达式：w+([-+.]w+)*@w+([-.]w+)*.w+([-.]w+)*匹配网址URL的正则表达式：http://([w-]+.)+[w-]+(/[w- ./?%&amp;=]*)?利用正则表达式限制网页表单里的文本框输入内容：用 正则表达式限制只能输入中文：onkeyup=”value=value.replace(/[^u4E00-u9FA5]/g,”)” onbeforepaste=”clipboardData.setData(‘text’,clipboardData.getData(‘text’).replace(/[^u4E00-u9FA5]/g,”))”用 正则表达式限制只能输入全角字符： onkeyup=”value=value.replace(/[^uFF00-uFFFF]/g,”)” onbeforepaste=”clipboardData.setData(‘text’,clipboardData.getData(‘text’).replace(/[^uFF00-uFFFF]/g,”))”用 正则表达式限制只能输入数字：onkeyup=”value=value.replace(/[^d]/g,”) “onbeforepaste=”clipboardData.setData(‘text’,clipboardData.getData(‘text’).replace(/[^d]/g,”))”用 正则表达式限制只能输入数字和英文：onkeyup=”value=value.replace(/[W]/g,”) “onbeforepaste=”clipboardData.setData(‘text’,clipboardData.getData(‘text’).replace(/[^d]/g,”))” 常用正则式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051匹配中文字符的正则表达式：[\u4e00-\u9fa5]匹配双字节字符(包括汉字在内)：[^\x00-\xff]匹配空行的正则表达式：\n[\s| ]*\r匹配HTML标记的正则表达式：/&lt;(.*)&gt;.*&lt;\/\1&gt;|&lt;(.*) \/&gt;/匹配首尾空格的正则表达式：(^\s*)|(\s*$)匹配IP地址的正则表达式：/(\d+)\.(\d+)\.(\d+)\.(\d+)/g //匹配Email地址的正则表达式：\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*匹配网址URL的正则表达式：http://(/[\w-]+\.)+[\w-]+(/[\w- ./?%&amp;=]*)?sql语句：^(select|drop|delete|create|update|insert).*$1、非负整数：^\d+$2、正整数：^[0-9]*[1-9][0-9]*$3、非正整数：^((-\d+)|(0+))$4、负整数：^-[0-9]*[1-9][0-9]*$5、整数：^-?\d+$6、非负浮点数：^\d+(\.\d+)?$7、正浮点数：^((0-9)+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*))$8、非正浮点数：^((-\d+\.\d+)?)|(0+(\.0+)?))$9、负浮点数：^(-((正浮点数正则式)))$10、英文字符串：^[A-Za-z]+$11、英文大写串：^[A-Z]+$12、英文小写串：^[a-z]+$13、英文字符数字串：^[A-Za-z0-9]+$14、英数字加下划线串：^\w+$15、E-mail地址：^[\w-]+(\.[\w-]+)*@[\w-]+(\.[\w-]+)+$16、URL：^[a-zA-Z]+://(\w+(-\w+)*)(\.(\w+(-\w+)*))*(\?\s*)?$17、邮政编码：^[1-9]\d&#123;5&#125;$18、中文：^[\u0391-\uFFE5]+$19、电话号码：^((\(\d&#123;2,3&#125;\))|(\d&#123;3&#125;\-))?(\(0\d&#123;2,3&#125;\)|0\d&#123;2,3&#125;-)?[1-9]\d&#123;6,7&#125;(\-\d&#123;1,4&#125;)?$20、手机号码：^((\(\d&#123;2,3&#125;\))|(\d&#123;3&#125;\-))?13\d&#123;9&#125;$21、双字节字符(包括汉字在内)：^\x00-\xff22、匹配首尾空格：(^\s*)|(\s*$)（像vbscript那样的trim函数）23、匹配HTML标记：&lt;(.*)&gt;.*&lt;\/\1&gt;|&lt;(.*) \/&gt;24、匹配空行：\n[\s| ]*\r25、提取信息中的网络链接：(h|H)(r|R)(e|E)(f|F) *= *(‘|”)?(\w|\\|\/|\.)+(‘|”| *|&gt;)?26、提取信息中的邮件地址：\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*27、提取信息中的图片链接：(s|S)(r|R)(c|C) *= *(‘|”)?(\w|\\|\/|\.)+(‘|”| *|&gt;)?28、提取信息中的IP地址：(\d+)\.(\d+)\.(\d+)\.(\d+)29、提取信息中的中国手机号码：(86)*0*13\d&#123;9&#125;30、提取信息中的中国固定电话号码：(\(\d&#123;3,4&#125;\)|\d&#123;3,4&#125;-|\s)?\d&#123;8&#125;31、提取信息中的中国电话号码（包括移动和固定电话）：(\(\d&#123;3,4&#125;\)|\d&#123;3,4&#125;-|\s)?\d&#123;7,14&#125;32、提取信息中的中国邮政编码：[1-9]&#123;1&#125;(\d+)&#123;5&#125;33、提取信息中的浮点数（即小数）：(-?\d*)\.?\d+34、提取信息中的任何数字：(-?\d*)(\.\d+)?35、IP：(\d+)\.(\d+)\.(\d+)\.(\d+)36、电话区号：/^0\d&#123;2,3&#125;$/37、腾讯QQ号：^[1-9]*[1-9][0-9]*$38、帐号(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]&#123;4,15&#125;$39、中文、英文、数字及下划线：^[\u4e00-\u9fa5_a-zA-Z0-9]+$]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HTTP状态码详解]]></title>
      <url>http://czero000.github.io/2016/01/21/http-status-code.html</url>
      <content type="text"><![CDATA[什么是 HTTP 状态码HTTP 状态码 （HTTP Status Code）是用以表示网页服务器 HTTP 响应状态的 3 位数字代码。它由 RFC 2616 规范定义的，并得到 「RFC 2518、RFC 2817、RFC 2295、RFC 2774、RFC 4918」等规范扩展。所有状态码的第一个数字代表了响应的五种状态之一。 状态码具体含义消息 (1xx)这一类型的状态码，代表请求已被接受，需要继续处理。这类响应是临时响应，只包含状态行和某些可选的响应头信息，并以空行结束。由于 HTTP/1.0 协议中没有定义任何 1xx 状态码，所以除非在某些试验条件下，服务器禁止向此类客户端发送 1xx 响应。 100客户端应当继续发送请求。这个临时响应是用来通知客户端它的部分请求已经被服务器接收，且仍未被拒绝。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。服务器必须在请求完成后向客户端发送一个最终响应。 101服务器已经理解了客户端的请求，并将通过Upgrade 消息头通知客户端采用不同的协议来完成这个请求。在发送完这个响应最后的空行后，服务器将会切换到在Upgrade 消息头中定义的那些协议。 只有在切换新的协议更有好处的时候才应该采取类似措施。例如，切换到新的HTTP 版本比旧版本更有优势，或者切换到一个实时且同步的协议以传送利用此类特性的资源。 102由 WebDAV（RFC 2518）扩展的状态码，代表处理将被继续执行。 成功 (2xx)这一类型的状态码，代表请求已成功被服务器接收、理解、并接受。 200请求已成功，请求所希望的响应头或数据体将随此响应返回。 201请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随 Location 头信息返回。假如需要的资源无法及时建立的话，应当返回 ‘202 Accepted’。 202服务器已接受请求，但尚未处理。正如它可能被拒绝一样，最终该请求可能会也可能不会被执行。在异步操作的场合下，没有比发送这个状态码更方便的做法了。 返回 202 状态码的响应的目的是允许服务器接受其他过程的请求（例如某个每天只执行一次的基于批处理的操作），而不必让客户端一直保持与服务器的连接直到批处理操作全部完成。在接受请求处理并返回 202 状态码的响应应当在返回的实体中包含一些指示处理当前状态的信息，以及指向处理状态监视器或状态预测的指针，以便用户能够估计操作是否已经完成。 203服务器已成功处理了请求，但返回的实体头部元信息不是在原始服务器上有效的确定集合，而是来自本地或者第三方的拷贝。当前的信息可能是原始版本的子集或者超集。例如，包含资源的元数据可能导致原始服务器知道元信息的超级。使用此状态码不是必须的，而且只有在响应不使用此状态码便会返回 200 OK 的情况下才是合适的。 204服务器成功处理了请求，但不需要返回任何实体内容，并且希望返回更新了的元信息。响应可能通过实体头部的形式，返回新的或更新后的元信息。如果存在这些头部信息，则应当与所请求的变量相呼应。 如果客户端是浏览器的话，那么用户浏览器应保留发送了该请求的页面，而不产生任何文档视图上的变化，即使按照规范新的或更新后的元信息应当被应用到用户浏览器活动视图中的文档。 由于 204 响应被禁止包含任何消息体，因此它始终以消息头后的第一个空行结尾。 205服务器成功处理了请求，且没有返回任何内容。但是与 204 响应不同，返回此状态码的响应要求请求者重置文档视图。该响应主要是被用于接受用户输入后，立即重置表单，以便用户能够轻松地开始另一次输入。 与 204 响应一样，该响应也被禁止包含任何消息体，且以消息头后的第一个空行结束。 206服务器已经成功处理了部分 GET 请求。类似于 FlashGet 或者迅雷这类的 HTTP 下载工具都是使用此类响应实现断点续传或者将一个大文档分解为多个下载段同时下载。 该请求必须包含 Range 头信息来指示客户端希望得到的内容范围，并且可能包含 If-Range 来作为请求条件。 响应必须包含如下的头部域： Content-Range 用以指示本次响应中返回的内容的范围；如果是 Content-Type 为 multipart/byteranges 的多段下载，则每一 multipart 段中都应包含 Content-Range 域用以指示本段的内容范围。假如响应中包含 Content-Length，那么它的数值必须匹配它返回的内容范围的真实字节数。 Date ETag 和/或 Content-Location，假如同样的请求本应该返回200响应。 Expires, Cache-Control，和/或 Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 假如本响应请求使用了 If-Range 强缓存验证，那么本次响应不应该包含其他实体头；假如本响应的请求使用了 If-Range 弱缓存验证，那么本次响应禁止包含其他实体头；这避免了缓存的实体内容和更新了的实体头信息之间的不一致。否则，本响应就应当包含所有本应该返回200响应中应当返回的所有实体头部域。 假如 ETag 或 Last-Modified 头部不能精确匹配的话，则客户端缓存应禁止将206响应返回的内容与之前任何缓存过的内容组合在一起。 任何不支持 Range 以及 Content-Range 头的缓存都禁止缓存206响应返回的内容。 207由 WebDAV(RFC 2518) 扩展的状态码，代表之后的消息体将是一个 XML 消息，并且可能依照之前子请求数量的不同，包含一系列独立的响应代码。 重定向 (3xx)这类状态码代表需要客户端采取进一步的操作才能完成请求。通常，这些状态码用来重定向，后续的请求地址（重定向目标）在本次响应的 Location 域中指明。 当且仅当后续的请求所使用的方法是 GET 或者 HEAD 时，用户浏览器才可以在没有用户介入的情况下自动提交所需要的后续请求。客户端应当自动监测无限循环重定向（例如：A-&gt;A，或者A-&gt;B-&gt;C-&gt;A），因为这会导致服务器和客户端大量不必要的资源消耗。按照 HTTP/1.0 版规范的建议，浏览器不应自动访问超过5次的重定向。 300被请求的资源有一系列可供选择的回馈信息，每个都有自己特定的地址和浏览器驱动的商议信息。用户或浏览器能够自行选择一个首选的地址进行重定向。 除非这是一个 HEAD 请求，否则该响应应当包括一个资源特性及地址的列表的实体，以便用户或浏览器从中选择最合适的重定向地址。这个实体的格式由 Content-Type 定义的格式所决定。浏览器可能根据响应的格式以及浏览器自身能力，自动作出最合适的选择。当然，RFC 2616规范并没有规定这样的自动选择该如何进行。 如果服务器本身已经有了首选的回馈选择，那么在 Location 中应当指明这个回馈的 URI；浏览器可能会将这个 Location 值作为自动重定向的地址。此外，除非额外指定，否则这个响应也是可缓存的。 301被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个 URI 之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的。 新的永久性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 如果这不是一个 GET 或者 HEAD 请求，因此浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 注意：对于某些使用 HTTP/1.0 协议的浏览器，当它们发送的 POST 请求得到了一个 301 响应的话，接下来的重定向请求将会变成 GET 方式。 302请求的资源现在临时从不同的 URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 新的临时性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 如果这不是一个 GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 注意：虽然 RFC 1945 和 RFC 2068 规范不允许客户端在重定向时改变请求的方法，但是很多现存的浏览器将 302 响应视作为 303 响应，并且使用 GET 方式访问在 Location 中规定的 URI，而无视原先请求的方法。状态码 303 和 307 被添加了进来，用以明确服务器期待客户端进行何种反应。 303对应当前请求的响应可以在另一个 URI 上被找到，而且客户端应当采用 GET 的方式访问那个资源。这个方法的存在主要是为了允许由脚本激活的POST请求输出重定向到一个新的资源。这个新的 URI 不是原始资源的替代引用。同时，303 响应禁止被缓存。当然，第二个请求（重定向）可能被缓存。 新的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 注意：许多 HTTP/1.1 版以前的 浏览器不能正确理解303 状态。如果需要考虑与这些浏览器之间的互动，302 状态码应该可以胜任，因为大多数的浏览器处理 302 响应时的方式恰恰就是上述规范要求客户端处理 303 响应时应当做的。 304如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304 响应禁止包含消息体，因此始终以消息头后的第一个空行结尾。 该响应必须包含以下的头信息： Date，除非这个服务器没有时钟。假如没有时钟的服务器也遵守这些规则，那么代理服务器以及客户端可以自行将 Date 字段添加到接收到的响应头中去（正如RFC 2068 中规定的一样），缓存机制将会正常工作。 ETag 和/或 Content-Location，假如同样的请求本应返回200响应。 Expires, Cache-Control，和/或Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 假如本响应请求使用了强缓存验证，那么本次响应不应该包含其他实体头；否则（例如，某个带条件的 GET 请求使用了弱缓存验证），本次响应禁止包含其他实体头；这避免了缓存了的实体内容和更新了的实体头信息之间的不一致。 假如某个 304 响应指明了当前某个实体没有缓存，那么缓存系统必须忽视这个响应，并且重复发送不包含限制条件的请求。 假如接收到一个要求更新某个缓存条目的 304 响应，那么缓存系统必须更新整个条目以反映所有在响应中被更新的字段的值。 305被请求的资源必须通过指定的代理才能被访问。Location 域中将给出指定的代理所在的 URI 信息，接收者需要重复发送一个单独的请求，通过这个代理才能访问相应资源。只有原始服务器才能建立305响应。 注意：RFC 2068中没有明确305响应是为了重定向一个单独的请求，而且只能被原始服务器建立。忽视这些限制可能导致严重的安全后果。 306在最新版的规范中，306 状态码已经不再被使用。 307请求的资源现在临时从不同的 URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在 Cache-Control 或 Expires 中进行了指定的情况下，这个响应才是可缓存的。 新的临时性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。因为部分浏览器不能识别 307 响应，因此需要添加上述必要信息以便用户能够理解并向新的 URI 发出访问请求。 如果这不是一个GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 请求错误 (4xx)这类的状态码代表了客户端看起来可能发生了错误，妨碍了服务器的处理。除非响应的是一个 HEAD 请求，否则服务器就应该返回一个解释当前错误状况的实体，以及这是临时的还是永久性的状况。这些状态码适用于任何请求方法。浏览器应当向用户显示任何包含在此类错误响应中的实体内容。 如果错误发生时客户端正在传送数据，那么使用TCP的服务器实现应当仔细确保在关闭客户端与服务器之间的连接之前，客户端已经收到了包含错误信息的数据包。如果客户端在收到错误信息后继续向服务器发送数据，服务器的TCP栈将向客户端发送一个重置数据包，以清除该客户端所有还未识别的输入缓冲，以免这些数据被服务器上的应用程序读取并干扰后者。 4001、语义有误，当前请求无法被服务器理解。除非进行修改，否则客户端不应该重复提交这个请求。2、请求参数有误。 401当前请求需要用户验证。该响应必须包含一个适用于被请求资源的 WWW-Authenticate 信息头用以询问用户信息。客户端可以重复提交一个包含恰当的 Authorization 头信息的请求。如果当前请求已经包含了 Authorization 证书，那么401响应代表着服务器验证已经拒绝了那些证书。如果 401 响应包含了与前一个响应相同的身份验证询问，且浏览器已经至少尝试了一次验证，那么浏览器应当向用户展示响应中包含的实体信息，因为这个实体信息中可能包含了相关诊断信息。参见 RFC 2617。 402该状态码是为了将来可能的需求而预留的。 403服务器已经理解请求，但是拒绝执行它。与401响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交。如果这不是一个 HEAD 请求，而且服务器希望能够讲清楚为何请求不能被执行，那么就应该在实体内描述拒绝的原因。当然服务器也可以返回一个 404 响应，假如它不希望让客户端获得任何信息。 404请求失败，请求所希望得到的资源未被在服务器上发现。没有信息能够告诉用户这个状况到底是暂时的还是永久的。假如服务器知道情况的话，应当使用410状态码来告知旧资源因为某些内部的配置机制问题，已经永久的不可用，而且没有任何可以跳转的地址。404 这个状态码被广泛应用于当服务器不想揭示到底为何请求被拒绝或者没有其他适合的响应可用的情况下。 405请求行中指定的请求方法不能被用于请求相应的资源。该响应必须返回一个 Allow 头信息用以表示出当前资源能够接受的请求方法的列表。 鉴于 PUT，DELETE 方法会对服务器上的资源进行写操作，因而绝大部分的网页服务器都不支持或者在默认配置下不允许上述请求方法，对于此类请求均会返回 405 错误。 406请求的资源的内容特性无法满足请求头中的条件，因而无法生成响应实体。 除非这是一个 HEAD 请求，否则该响应就应当返回一个包含可以让用户或者浏览器从中选择最合适的实体特性以及地址列表的实体。实体的格式由 Content-Type 头中定义的媒体类型决定。浏览器可以根据格式及自身能力自行作出最佳选择。但是，规范中并没有定义任何作出此类自动选择的标准。 407与401响应类似，只不过客户端必须在代理服务器上进行身份验证。代理服务器必须返回一个 Proxy-Authenticate 用以进行身份询问。客户端可以返回一个 Proxy-Authorization 信息头用以验证。参见 RFC 2617。 408请求超时。客户端没有在服务器预备等待的时间内完成一个请求的发送。客户端可以随时再次提交这一请求而无需进行任何更改。 409由于和被请求的资源的当前状态之间存在冲突，请求无法完成。这个代码只允许用在这样的情况下才能被使用：用户被认为能够解决冲突，并且会重新提交新的请求。该响应应当包含足够的信息以便用户发现冲突的源头。 冲突通常发生于对 PUT 请求的处理中。例如，在采用版本检查的环境下，某次 PUT 提交的对特定资源的修改请求所附带的版本信息与之前的某个（第三方）请求向冲突，那么此时服务器就应该返回一个 409 错误，告知用户请求无法完成。此时，响应实体中很可能会包含两个冲突版本之间的差异比较，以便用户重新提交归并以后的新版本。 410被请求的资源在服务器上已经不再可用，而且没有任何已知的转发地址。这样的状况应当被认为是永久性的。如果可能，拥有链接编辑功能的客户端应当在获得用户许可后删除所有指向这个地址的引用。如果服务器不知道或者无法确定这个状况是否是永久的，那么就应该使用 404 状态码。除非额外说明，否则这个响应是可缓存的。 410响应的目的主要是帮助网站管理员维护网站，通知用户该资源已经不再可用，并且服务器拥有者希望所有指向这个资源的远端连接也被删除。这类事件在限时、增值服务中很普遍。同样，410 响应也被用于通知客户端在当前服务器站点上，原本属于某个个人的资源已经不再可用。当然，是否需要把所有永久不可用的资源标记为 ‘410 Gone’，以及是否需要保持此标记多长时间，完全取决于服务器拥有者。 411服务器拒绝在没有定义 Content-Length 头的情况下接受请求。在添加了表明请求消息体长度的有效 Content-Length 头之后，客户端可以再次提交该请求。 412服务器在验证在请求的头字段中给出先决条件时，没能满足其中的一个或多个。这个状态码允许客户端在获取资源时在请求的元信息（请求头字段数据）中设置先决条件，以此避免该请求方法被应用到其希望的内容以外的资源上。 413服务器拒绝处理当前请求，因为该请求提交的实体数据大小超过了服务器愿意或者能够处理的范围。此种情况下，服务器可以关闭连接以免客户端继续发送此请求。 如果这个状况是临时的，服务器应当返回一个 Retry-After 的响应头，以告知客户端可以在多少时间以后重新尝试。 414请求的URI 长度超过了服务器能够解释的长度，因此服务器拒绝对该请求提供服务。这比较少见，通常的情况包括： 本应使用POST方法的表单提交变成了GET方法，导致查询字符串 （Query String） 过长。 重定向URI “黑洞”，例如每次重定向把旧的 URI 作为新的 URI 的一部分，导致在若干次重定向后 URI 超长。 客户端正在尝试利用某些服务器中存在的安全漏洞攻击服务器。这类服务器使用固定长度的缓冲读取或操作请求的 URI，当 GET 后的参数超过某个数值后，可能会产生缓冲区溢出，导致任意代码被执行[1]。没有此类漏洞的服务器，应当返回414状态码。 415对于当前请求的方法和所请求的资源，请求中提交的实体并不是服务器中所支持的格式，因此请求被拒绝。 416如果请求中包含了 Range 请求头，并且 Range 中指定的任何数据范围都与当前资源的可用范围不重合，同时请求中又没有定义 If-Range 请求头，那么服务器就应当返回 416 状态码。 假如 Range 使用的是字节范围，那么这种情况就是指请求指定的所有数据范围的首字节位置都超过了当前资源的长度。服务器也应当在返回416状态码的同时，包含一个 Content-Range 实体头，用以指明当前资源的长度。这个响应也被禁止使用 multipart/byteranges 作为其 Content-Type。 417在请求头 Expect 中指定的预期内容无法被服务器满足，或者这个服务器是一个代理服务器，它有明显的证据证明在当前路由的下一个节点上，Expect 的内容无法被满足。 421从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。 422请求格式正确，但是由于含有语义错误，无法响应。（RFC 4918 WebDAV）423 Locked 当前资源被锁定。（RFC 4918 WebDAV） 424由于之前的某个请求发生的错误，导致当前请求失败，例如 PROPPATCH。（RFC 4918 WebDAV） 425在WebDav Advanced Collections 草案中定义，但是未出现在「WebDAV 顺序集协议」（RFC 3658）中。 426客户端应当切换到 TLS/1.0。（RFC 2817） 449由微软扩展，代表请求应当在执行完适当的操作后进行重试。 服务器错误 (5xx)这类状态码代表了服务器在处理请求的过程中有错误或者异常状态发生，也有可能是服务器意识到以当前的软硬件资源无法完成对请求的处理。除非这是一个 HEAD 请求，否则服务器应当包含一个解释当前错误状态以及这个状况是临时的还是永久的解释信息实体。浏览器应当向用户展示任何在当前响应中被包含的实体。 这些状态码适用于任何响应方法。 500服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器的程序码出错时出现。 501服务器不支持当前请求所需要的某个功能。当服务器无法识别请求的方法，并且无法支持其对任何资源的请求。 502作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 503由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。如果能够预计延迟时间，那么响应中可以包含一个 Retry-After 头用以标明这个延迟时间。如果没有给出这个 Retry-After 信息，那么客户端应当以处理 500 响应的方式处理它。 注意： 503 状态码的存在并不意味着服务器在过载的时候必须使用它。某些服务器只不过是希望拒绝客户端的连接。 504作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（ URI 标识出的服务器，例如 HTTP、FTP、LDAP）或者辅助服务器（例如 DNS）收到响应。 注意：某些代理服务器在 DNS 查询超时时会返回 400 或者 500 错误 505服务器不支持，或者拒绝支持在请求中使用的 HTTP 版本。这暗示着服务器不能或不愿使用与客户端相同的版本。响应中应当包含一个描述了为何版本不被支持以及服务器支持哪些协议的实体。 506由『透明内容协商协议』 （RFC 2295） 扩展，代表服务器存在内部配置错误：被请求的协商变元资源被配置为在透明内容协商中使用自己，因此在一个协商处理中不是一个合适的重点。 507服务器无法存储完成请求所必须的内容。这个状况被认为是临时的。WebDAV (RFC 4918) 509服务器达到带宽限制。这不是一个官方的状态码，但是仍被广泛使用。 510获取资源所需要的策略并没有没满足。（RFC 2774）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用glances监控系统]]></title>
      <url>http://czero000.github.io/2016/01/19/glances-monitor-system.html</url>
      <content type="text"><![CDATA[使用Glances监控系统Glances 是一个用于监控系统的跨平台、基于文本模式的命令行工具。它是用 Python 编写的，使用 psutil 库从系统获取信息。你可以用它来监控 CPU、平均负载、内存、网络接口、磁盘 I/O，文件系统空间利用率、挂载的设备、所有活动进程以及消耗资源最多的进程。Glances 有很多有趣的选项。它的主要特性之一是可以在配置文件中设置阀值(careful小心、warning警告、critical致命)，然后它会用不同颜色显示信息以表明系统的瓶颈。 Glances的功能 CPU 平均负载 不同状态(如活动、休眠)进程的数量 所有内存信息，如物理内存、交换空间、空闲内存 CPU 信息 网络连接的上行/下行速度 磁盘 I/O 读/写速度详细信息 当前挂载设备的磁盘使用情况 消耗资源最多的进程和他们的 CPU/内存使用情况 安装 GlancesGlances 在 Ubuntu 的软件仓库中，所以安装很简单。执行下面的命令安装 Glances1234sudo apt-get install glances //若安装后无法正常使用，可考虑使用 pip 安装/升级 glances：sudo pip install --upgrade glances Glances 使用方法安装完成后，可以执行下面的命令启动 Glances：1glances 你将看到类似下图的输出： 要退出Glances终端，按 ESC 键或 Ctrl + C。 默认情况下，时间间隔(显示数据刷新的时间间隔)是 1 秒，不过你可以在从终端启动 Glances 时自定义时间间隔。 要把时间间隔设为 5 秒，执行下面的命令：1glances -t 5 Glances 中不同颜色含义 绿色：正常(OK) 蓝色：小心(careful) 紫色：警告(warning) 红色：致命(critical) 默认设置下，Glances的阀值设置是：careful=50，warning=70，critical=90。你可以通过 “/etc/glances/” 目录下的默认配置文件 glances.conf 来自定义这些阀值。 Glances 的选项Glances 提供了很多快捷键，可以在它运行时，用来查找输出信息。 下面是一些常用的热键列表： m：按内存占用排序进程 p：按进程名称排序进程 c：按 CPU 占用率排序进程 i：按 I/O 频率排序进程 a：自动排序进程 d：显示/隐藏磁盘 I/O 统计信息 f：显示/隐藏文件系统统计信息 s：显示/隐藏传感器统计信息 y：显示/隐藏硬盘温度统计信息 l：显示/隐藏日志 n：显示/隐藏网络统计信息 x：删除警告和严重日志 h：显示/隐藏帮助界面 q：退出 w：删除警告记录 使用 Glances 监控远程系统你也可以使用 Glances 监控远程系统。要在远程系统上使用它，使用下面的命令：1glances -s 你会看到类似下面的输出： 如你所见，Glances 运行在 61209 端口。 现在，到远程机器上执行下面的命令以连接到指定 IP 地址的 Glances 服务器上。假设 192.168.1.10 是你的 Glances 服务器 IP 地址。 glances -c 192.168.1.10结论 对于每个 Linux 系统管理员来说，Glances 都是一个非常有用的工具。使用它，你可以轻松、高效地监控 Linux 系统。如果你有什么问题，自由地评论吧！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS6.5安装kvm]]></title>
      <url>http://czero000.github.io/2016/01/06/kvm-pool-manage.html</url>
      <content type="text"><![CDATA[什么是KVM KVM 是指基于 Linux 内核的虚拟机（Kernel-based Virtual Machine）。 2006 年 10 月，由以色列的Qumranet 组织开发的一种新的“虚拟机”实现方案。 2007 年 2 月发布的 Linux 2.6.20 内核第一次包含了 KVM 。增加 KVM 到 Linux 内核是 Linux 发展的一个重要里程碑，这也是第一个整合到 Linux 主线内核的虚拟化技术。 KVM 在标准的 Linux 内核中增加了虚拟技术，从而我们可以通过优化的内核来使用虚拟技术。在 KVM 模型中，每一个虚拟机都是一个由 Linux 调度程序管理的标准进程，你可以在用户空间启动客户机操作系统。一个普通的 Linux 进程有两种运行模式：内核和用户。 KVM 增加了第三种模式：客户模式（有自己的内核和用户模式）。 一个典型的 KVM 安装包括以下部件： 一个管理虚拟硬件的设备驱动，这个驱动通过一个字符设备 /dev/kvm 导出它的功能。通过 /dev/kvm每一个客户机拥有其自身的地址空间，这个地址空间与内核的地址空间相分离或与任何一个正运行着的客户机相分离。 一个模拟硬件的用户空间部件，它是一个稍微改动过的 QEMU 进程。从客户机操作系统执行 I/O 会拥有QEMU。QEMU 是一个平台虚拟化方案，它允许整个 PC 环境（包括磁盘、显示卡（图形卡）、网络设备）的虚拟化。任何客户机操作系统所发出的 I/O 请求都被拦截，并被路由到用户模式用以被 QEMU 过程模拟仿真。 安装KVM系统要求KVM 需要有CPU的支持(Intel VT 或 AMD SVM)，在安装 KVM 之前检查一下 CPU 是否提供了虚拟技术的支持 基于Intel处理器的系统，运行grep vmx /proc/cpuinfo查找 CPU flags 是否包括vmx关键词 基于AMD处理器的系统，运行grep svm /proc/cpuinfo查找 CPU flags 是否包括svm关键词 检查BIOS，确保BIOS里开启VT选项 注: 一些厂商禁止了机器 BIOS 中的 VT 选项 , 这种方式下 VT 不能被重新打开 /proc/cpuinfo 仅从 Linux 2.6.15(Intel) 和 Linux 2.6.16(AMD) 开始显示虚拟化方面的信息。请使用 uname -r 命令查询您的内核版本。如有疑问，请联系硬件厂商 123456789egrep &quot;(vmx|svm)&quot; /proc/cpuinfoflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm dca sse4_1 sse4_2 popcnt lahf_lm dts tpr_shadow vnmi flexpriority ept vpidflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm dca sse4_1 sse4_2 popcnt lahf_lm dts tpr_shadow vnmi flexpriority ept vpidflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm dca sse4_1 sse4_2 popcnt lahf_lm dts tpr_shadow vnmi flexpriority ept vpidflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm dca sse4_1 sse4_2 popcnt lahf_lm dts tpr_shadow vnmi flexpriority ept vpidflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm dca sse4_1 sse4_2 popcnt lahf_lm dts tpr_shadow vnmi flexpriority ept vpidflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm dca sse4_1 sse4_2 popcnt lahf_lm dts tpr_shadow vnmi flexpriority ept vpidflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm dca sse4_1 sse4_2 popcnt lahf_lm dts tpr_shadow vnmi flexpriority ept vpidflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm dca sse4_1 sse4_2 popcnt lahf_lm dts tpr_shadow vnmi flexpriority ept vpid 安装kvm软件安装KVM模块、管理工具和libvirt (一个创建虚拟机的工具)123yum install -y qemu-kvm libvirt virt-install virt-manager bridge-utils/etc/init.d/libvirtd startchkconfig libvirtd on 确保正确加载kvm模块123lsmod | grep kvmkvm_intel 54285 0 kvm 333172 1 kvm_intel 检查kvm是否正确安装123virsh -c qemu:///system list Id Name State---------------------------------------------------- 如果这里是错误信息，说明安装出现问题 配置网络kvm上网有两种配置，一种是default，它支持主机和虚拟机的互访，同时也支持虚拟机访问互联网，但不支持外界访问虚拟机，另外一种是bridge方式，可以使虚拟机成为网络中具有独立Ip的主机。 默认网络virbro默认的网络连接是virbr0，它的配置文件在/var/lib/libvirt/network目录下，默认配置为1234cat /var/lib/libvirt/network/default.xml default 77094b31-b7eb-46ca-930e-e0be9715a5ce 桥接网络配置桥接网卡，配置如下 12345678910111213141516171819202122232425262728293031323334353637more /etc/sysconfig/network-scripts/ifcfg-\*::::::::::::::/etc/sysconfig/network-scripts/ifcfg-br0::::::::::::::DEVICE=br0ONBOOT=yesTYPE=BridgeBOOTPROTO=staticIPADDR=192.168.39.20NETMASK=255.255.255.0GATEWAY=192.168.39.1DNS1=8.8.8.8::::::::::::::/etc/sysconfig/network-scripts/ifcfg-br1::::::::::::::DEVICE=br1ONBOOT=yesTYPE=BridgeBOOTPROTO=staticIPADDR=10.10.39.8NETMASK=255.255.255.0::::::::::::::/etc/sysconfig/network-scripts/ifcfg-em1::::::::::::::DEVICE=em1TYPE=EthernetONBOOT=yesBOOTPROTO=staticBRIDGE=br0::::::::::::::/etc/sysconfig/network-scripts/ifcfg-em2::::::::::::::DEVICE=em2TYPE=EthernetONBOOT=yesBOOTPROTO=staticBRIDGE=br1 使用virt-manager安装建立虚拟机virt-manager 是基于 libvirt 的图像化虚拟机管理软件，操作类似vmware，不做详细介绍。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[gulsterfs系统管理]]></title>
      <url>http://czero000.github.io/2016/01/04/glusterfs-administrator-guide.html</url>
      <content type="text"><![CDATA[glusterfs 系统部署系统环境介绍 OS版本：CentOS 6.5 x86_64 软件版本： 3.7.3 系统节点 ip地址 挂载路径 172.161.8.241 /export/brick1/gv0 172.161.8.242 /export/brick1/gv0 172.161.8.243 /export/brick1/gv0 172.161.8.244 /export/brick1/gv0 gluster 安装部署安装 GlusterFS 软件包12345// 安装软件包yum install -y glusterfs glusterfs-fuse glusterfs-server xfsprogs// 启动服务，添加自启动/etc/init.d/glusterd start chkconfig glusterfsd on 添加节点到 GlusterFS 集群12345678910111213141516171819202122232425//添加节点到存储池，在其中一个节点上操作 gluster peer probe 172.16.18.241peer probe: success: on localhost not needed gluster peer probe 172.16.18.242peer probe: successgluster peer probe 172.16.18.243peer probe: success gluster peer probe 172.16.18.244peer probe: success//查看各个节点状态gluster peer statusNumber of Peers: 3Hostname: 172.16.18.242Uuid: beb0aae7-a939-45ec-a273-0c21c2f59546State: Peer in Cluster (Connected)Hostname: 172.16.18.243Uuid: eab486b3-d1a1-4851-b9ec-45aab1ef9a66State: Peer in Cluster (Connected)Hostname: 172.16.18.244Uuid: 3108764d-d6b3-4356-810d-88872d56ceb6State: Peer in Cluster (Connected) 创建数据存放目录123456parted /dev/sdb rm 1mkfs.xfs -i size=512 /dev/sdb -fmkdir -p /export/brick1/bin/mount -t xfs /dev/sdb /export/brick1mkdir /export/brick1/gv0echo &quot;/dev/sdb /export/brick1 xfs defaults 1 2&quot; &gt;&gt; /etc/fstab 创建 GlusterFS 磁盘123456789101112131415161718192021222324// 创建系统卷 gv0（副本卷）gluster volume create gv0 replica 2 172.16.18.241:/export/brick1/gv0 172.16.18.242:/export/brick1/gv0 172.16.18.243:/export/brick1/gv0 172.16.18.244:/export/brick1/gv0 force//启动系统卷 gv0 gluster volume start gv0volume create: gv0: success: please start the volume to access data//查看系统卷信息gluster volume info Volume Name: gv0Type: Distributed-ReplicateVolume ID: e64cb61c-0f18-41b5-bf4d-c45ee085ca3bStatus: StartedNumber of Bricks: 2 x 2 = 4Transport-type: tcpBricks:Brick1: 172.16.18.241:/export/brick1/gv0Brick2: 172.16.18.242:/export/brick1/gv0Brick3: 172.16.18.243:/export/brick1/gv0Brick4: 172.16.18.244:/export/brick1/gv0Options Reconfigured:performance.readdir-ahead: on 安装客户端并 mount GlusterFS 文件系统1234567891011// 下载仓库文件wget -P /etc/yum.repos.d http://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-epel.repo//安装软件yum install glusterfs glusterfs-fuse glusterfs-server//创建挂载点mkdir -p /opt/vmx/gv0//client挂载/bin/mount -t glusterfs 172.16.18.241:/gv0 /opt/vmx/gv0 基本系统管理节点管理1gluster peer command 节点状态123456789101112// 在任意节点操作，可以看到其他节点与本节点的连接状态gluster peer statusNumber of Peers: 3Hostname: 172.16.18.242Uuid: beb0aae7-a939-45ec-a273-0c21c2f59546State: Peer in Cluster (Connected)Hostname: 172.16.18.243Uuid: eab486b3-d1a1-4851-b9ec-45aab1ef9a66State: Peer in Cluster (Connected)Hostname: 172.16.18.244Uuid: 3108764d-d6b3-4356-810d-88872d56ceb6State: Peer in Cluster (Connected) 添加节点命令：gluster peer HostName 12// 将节点server添加到存储池中gluster peer prober server 删除节点命令： gluster peer detach HostName 12// 将节点server从存储池中移除，移除节点时要保证节点上没有brick，需要提前移除brickgluster peer detch server 卷管理创建卷命令：gluster volume create NEW-VOLNAME [transport[tcp|rdma|tcp,rdma]] NEW_BRICK… 创建分布式卷(DHT) 12// DHT卷将数据以哈希计算方式分布到各个brick上，数据是以文件为单位存取，基本达到分布均衡，提供的容量为各个brick的容量总和gluster volume create dht_vol 172.16.18.&#123;241,242,243,244&#125;:/export/brick1/gv0 创建副本卷(AFR) 12// AFR提供数据副本，副本数为replica，即每个文件存储replica份数，文件不分割，以文件为存储单位：副本数需要等于brick数；当brick数是副本的倍数时，则自动变化为Replicated-Distributed卷gluster volume create afr_vol replica 2 172.16.18.&#123;241,242,243,244&#125;:/export/brick/gv0 每两个brick组成一组，每组两个副本，文件又以DHT分布在三个组上，这样是副本卷和分布式卷的组合 创建条带卷 12//stripe卷类似raid0，将数据条带化，分布在不同的brick，该方式将文件分块，将文件分成stripe块，分别进行存储，在大文件读取是有优势。stripe需要等于brick数；当brick数等于stripe数的倍数时，则自动变化为stripe-distributed卷。gluster volume create str_vol stripe 2 172.16.18.&#123;241,242,243,244&#125;:/export/brick1/gv0 每2个brick组成一组，每组2个brick，文件以DHT分布在两个组中，每个组中将文件条带成2块 创建Replicated-Stripe-Distributed卷 12//使用8个brick创建一个组合卷，即brick数是stripe*replica的倍数，则创建三种基本卷的组合卷，若刚好等于stripe*replica则为stript-Distrubted卷gluster volume create str_afr_dht_vol stripe 2 replica 2 172.16.18.&#123;241,242,243,244&#125;:/export/brick1/gv0 172.16.18.&#123;241,242,243,244&#125;:/export/brick1/gv1 卷信息命令：gluster volume info12345678910111213141516// 该命令能够查看存储池中当前卷的信息，包括卷方式、包含的brick、卷的当期状态、卷名及UUID等gluster volume info Volume Name: gv0Type: Distributed-ReplicateVolume ID: e64cb61c-0f18-41b5-bf4d-c45ee085ca3bStatus: StartedNumber of Bricks: 2 x 2 = 4Transport-type: tcpBricks:Brick1: 172.16.18.241:/export/brick1/gv0Brick2: 172.16.18.242:/export/brick1/gv0Brick3: 172.16.18.243:/export/brick1/gv0Brick4: 172.16.18.244:/export/brick1/gv0Options Reconfigured:performance.readdir-ahead: on 卷状态命令： gluster volume status1234567891011121314151617181920212223// 该命令能够查看当前卷的状态，包括其中各个brick的状态、NFS的服务状态及当前task执行情况和一些系统设置状态等gluster volume statusStatus of volume: gv0Gluster process TCP Port RDMA Port Online Pid------------------------------------------------------------------------------Brick 172.16.18.241:/export/brick1/gv0 49152 0 Y 1970 Brick 172.16.18.242:/export/brick1/gv0 49152 0 Y 9547 Brick 172.16.18.243:/export/brick1/gv0 49152 0 Y 1800 Brick 172.16.18.244:/export/brick1/gv0 49152 0 Y 9741 NFS Server on localhost N/A N/A N N/A Self-heal Daemon on localhost N/A N/A Y 2605 NFS Server on 172.16.18.244 N/A N/A N N/A Self-heal Daemon on 172.16.18.244 N/A N/A Y 15386NFS Server on 172.16.18.243 N/A N/A N N/A Self-heal Daemon on 172.16.18.243 N/A N/A Y 1794 NFS Server on 172.16.18.242 N/A N/A N N/A Self-heal Daemon on 172.16.18.242 N/A N/A Y 1966 Task Status of Volume gv0------------------------------------------------------------------------------Task : Rebalance ID : fad4f770-87dd-4248-b41e-733641c8bccaStatus : completed 启动、停止卷命令： gluster volume start/stop VOLNAME123// 将创建的卷启动，才能进行客户端挂载；stop能够将系统将停止；此外gluster并未提供restart的重启命令gluster volume start gv0volume create: gv0: success: please start the volume to access data 删除卷命令：gluster volume delete VOLNAME 123// 删除卷的操作能够将整个卷删除，操作前需要将卷先停止gluster volume stop gv0gluster volume delete gv0 Brick管理添加brick命令：gluster volume add-brick VOLNAME NEW-BRICK1234//添加两个brick到存储gv0，副本卷则要一次添加的bricks数是replica的整数倍；stripe同样要求gluster peer probe 172.16.18.245gluster peer probe 172.16.18.246gluster volume add-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 移除brick命令： gluster volume remove-brick VOLNAME BRICK start/status/commit12345678// 若是副本卷，则要移除的Brick是replica的整数倍，stripe具有同样的要求，副本卷要移除一对Brick，在执行移除操作时，数据会移到其他节点。gluster volume remove-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 start// 在执行移除操作后，可以使用status命令进行task状态查看gluster volume remove-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 status// 使用commit命令执行brick移除，则不会进行数据迁移而直接删除brick，符合不需要数据迁移的用户需求gluster volume remove-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 commit ps：系统的扩容及缩减可以通过如上的节点、brick管理组合达到目的1. 扩容时，可以下增加系统节点，然后添加新增节点上的brick即可2. 缩减时，可以先移除brick，然后在进行节点删除达到缩减的目的，并保证不丢失数据 替换brick 命令：gluster volume replace-brick VOLNAME BRICKNEW-BRICK start/pause/sbort/status/commit 1234567891011// 将172.16.18.244：/export/brick1/gv0替换为172.16.18.245:/export/brick1/gv0。在执行replcase-brick，使用start启动命令之后，开始将原始brick的数据迁移到即将需要替换的brick上gluster volume replace-brick gv0 172.16.18.244:/export/brick1/gv0 172.16.18.245:/export/brick1/gv0 start force//在数据迁移过程中，可以查看替换状态gluster volume replace-brick gv0 172.16.18.244:/export/brick1/gv0 172.16.18.245:/export/brick1/gv0 status// 在数据迁移的过程中，可以执行abort命令终止brick替换gluster volume replace-brick gv0 172.16.18.244:/export/brick1/gv0 172.16.18.245:/export/brick1/gv0 abort//当数据迁移结束之后，执行commit命令结束任务，则进行brick替换。使用volume info命令可以查看到brick已经被替换gluster volume replace-brick gv0 172.16.18.244:/export/brick1/gv0 172.16.18.245:/export/brick1/gv0 start 系统拓展系统配额开启、关闭系统配额12//在使用系统配额功能时，需要使用enable将其开启；disable为关闭命令gluster volume quota VOLNAME enable/disable 设置目录配额1234gluster volume quota VOLNAME limit-usage /directory limit-value//设置gv0卷下quota子目录目录限额为10GB，这个目录是以系统挂载目录为根目录，所以/quota即客户端挂载目录下的子目录gluster volume quota gv0 limit-usage /quota 10GB 配额查看1234gluster volume quota VOLNAME listgluster volume quota VOLNAME list /directory_name//可以使用上面命令查看卷的配额，第一个查看全部配额设置，第二个可以根据目录查看，显示配额大小及当前使用容量，如无使用容量则说明设置的目录有误(不存在)gluster volume quota gv0 list 地域复制(geo-replication)123456gluster volume geo-replication MASTER SLAVE start/status/stop//地域复制是系统提供的灾备功能，能够将系统的全部数据进行异步的增量备份到另外的磁盘中gluster volume geo-replication gv0 172.16.18.250:/export/brick/gv0 start//当开始执行gv0卷的所有内容备份到18.250下的/export/brick/gv0中的task，值得注意的是，这个备份目标不能是系统中的brick I/O信息查看profile command提供了一个接口查看每个卷中的每个brick的io信息12345678// 启动profiling，之后便可以进行io查看gluster volume profile VOLNAME start// 查看io信息，可以查看到每个brick的io信息gluster volume profile VOLNAME info// 管理profilinig功能gluster volume profile VOLNAME stop top监控top command允许你查看bricks的性能，read、write、file open calls、file read caclls、file write calls、directory open calls、directory read calls。所有的查看都可以设置top数，默认是1000123456789101112131415161718// 查看打开的fdgluster volume top VOLNAME open [brick BRICK-NAME] [list-cnt cnt]// 查看调用次数最多的读调用gluster volume top VOLNAME read [brick BRICK-NAME] [list-cnt cnt]// 查看调用次数最多的写调用gluster volume top VOLNAME write [brick BRICK-NAME] [list-cnt cnt]// 查看次数最多的目录调用gluster volume top opendir [brick BRICK-NAME] [list-cnt cnt]gluster volume top readdir [brick BRICK-NAME] [list-cnt cnt]//查看每个brick的读性能gluster volume top VOLNAME read-perf [bs blk-size count count] [brick BRICK-NAME] [list-cnt cnt]//查看每个brick的写性能gluster volume top VOLNAME write-perf [bs blk-size count count] [brick BRICK-NAME] [list-cnt cnt]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Apache添加cgi模块]]></title>
      <url>http://czero000.github.io/2015/12/29/apache-add-moudle-cgi.html</url>
      <content type="text"><![CDATA[apache 添加 cgi 模块Apache 需要运行 cgi 程序的，却发现先前编译安装 Apache 的时候，没有安装 Apache 的 cgi 模块。12cd /usr/local/src/httpd-2.2.25/modules/generators/usr/local/apache/bin/apxs -i -a -c mod_cgi.c 省略部分内容12chmod 755 /usr/local/apache/modules/mod_cgi.so[activating module `cgi&apos; in /usr/local/apache/conf/httpd.conf]ap apxs参数介绍： -i：表示要执行安装操作 -a：自动添加一个 LoadModule 行到 httpd.conf 文件中，使模块激活]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ubuntu安装Megacli]]></title>
      <url>http://czero000.github.io/2015/12/29/ubuntu-install-megacli.html</url>
      <content type="text"><![CDATA[MegaCli这个命令可以用来监控raid状态、磁盘状况等，最近上了一批ubuntu系统，问题是MegaCli在官网上只有rpm格式的包，没有deb的包，但是还是有办法解决的，rpm包也是可以在debian&amp;&amp;ubuntu上安装的。 下载最新的zip文件1http://www.lsi.com/Search/Pages/results.aspx?k=MegaCLI&amp;r=productfacet%3D%22AQxNZWdhUkFJRCBTQVMMcHJvZHVjdGZhY2V0AQJeIgIiJA%3D%3D%22%20os%3D%22AQVMaW51eAJvcwEBXgEk%22 我下载的是8.00.48_Linux_MegaCLI.zip 预先安装需要的其他包1apt-get -y install rpm2cpio libsysfs2 libsysfs-dev unzip 安装完成后执行如下命令12cd /lib/x86_64-linux-gnu/ln -s libsysfs.so.2.0.1 libsysfs.so.2.0.2 进入 8.00.48_Linux_MegaCLI.zip包所在的目录，执行如下命令123456unzip 8.00.48_Linux_MegaCLI.zipunzip MegaCliLin.ziprpm2cpio Lib_Utils-1.00-09.noarch.rpm | cpio -idmvrpm2cpio MegaCli-8.00.48-1.i386.rpm | cpio -idmvcp opt/MegaRAID/MegaCli/MegaCli64 /sbin/cp opt/MegaRAID/MegaCli/MegaCli /sbin/ MegaCli不但能查询raid的状态，还能设置raid的状态，所以还是由管理员掌握比较好，这样就安装完毕了。 下面几个是常用的检查raid状态的命令： MegaCli64 -LDInfo -Lall -aALL 可以检查raid级别 MegaCli64 -PDList -aALL 可以检查所有物理盘的状态 MegaCli64 -AdpAllInfo -aALL 显示所有的raid信息 MegaCli64 -cfgdsply -aALL 显示所有的磁盘信息 MegaCli64 -FwTermLog -Dsply -aALL 这个包含一些用于的日志 MegaCli的其他强大功能还请查看官方文档。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[debian添加中文支持]]></title>
      <url>http://czero000.github.io/2015/12/29/debian-support-chinese.html</url>
      <content type="text"><![CDATA[debian与ubuntu有很大的相似性，但是debian相对更原始，比如在语言支持这一块，如果在安装ubuntu的时候，选择的系统语言是英文，那么系统显示的肯定是英文，但是查看中文文件的时候，肯定还是能查看的，因为系统默认支持了中文，中文字体，语言包等已经安装好了，但是 debian不同，如果你安装的时候选择了英文，那么进入系统之后，只要查看不是英文的东西都是乱码，就连网页上的汉字都是一个个的方块。 要解决这个问题，只能自己手动添加中文支持： 生成locales:运行 dpkg-reconfigure locales，选择上以下选项：123456en_US ISO-8859-1zh_CN GB2312zh_CN.GBK GBKzh_CN.UTF-8 UTF-8zh_TW BIG5zh_TW.UTF-8 UTF-8 接下来要安装中文字体，一共有以下几个包需要安装：1234ttf-arphic-gbsn00lp (AR PL SungtiL GB)ttf-arphic-gkai00mp (AR PL KaitiM GB)ttf-arphic-bsmi00lp (AR PL Mingti2L Big5)ttf-arphic-bkai00mp (AR PL KaitiM Big5) 前面两个是简体的，后面两个是繁体的，但是最好都装上，否则到时候很可能乱码。 执行：1sudo apt-get install ttf-arphic-gbsn00lp ttf-arphic-gkai00mp ttf-arphic-bsmi00lp ttf-arphic-bkai00mp PS:这些只是基本字体，只能保证中文正常显示，如果要说好看那是谈不上的。如果要好看一点的话，可以在软件中心搜索安装xfonts 接下来就是安装中文输入法，个人推荐使用ibus，比较好用而且兼容性也还行，可以参考http://www.cnblogs.com/pengdonglin137/p/3280520.html 当然，在X环境下还要设置locale变量： 可以在/etc/X11/Xsession.d/95xinput这个文件里写上如下语句：1export LANG=zh_CN.gb2312 PS:如果你在启动之后执行这条命令不会有效，只能重启并在加载X window之前执行才有效，这就是为什么把它写入文件的原因（这个文件在X window启动前被加载。） 这样一来，你的系统菜单等也会变成中文，如果你还是想要英文菜单，但是只要能显示中文，那么就要多设置几个变量：1234567891011121314ENCODING=&quot;en_US&quot;#export LC_ALL=$ENCODINGexport LC_MESSAGES=$ENCODING#export LC_COLLATE=$ENCODING#export LC_CTYPE=$ENCODINGexport LC_TIME=$ENCODINGexport LC_NUMERIC=$ENCODING#export LC_MONETARY=$ENCODING#export LC_PAPER=$ENCODING#export LC_NAME=$ENCODINGexport LC_ADDRESS=$ENCODINGexport LC_TELEPHONE=$ENCODINGexport LC_MEASUREMENT=$ENCODINGexport LC_IDENTIFICATION=$ENCODING 同样把这些写入/etc/X11/Xsession.d/95xinput文件，重启就行了。最后要说一下终端对中文的支持：KDE默认的终端是konsole, 默认就支持中文，而且还支持得不错，gnome默认的终端是gnome-terminal, 要支持中文的话只要在菜单里选上中文相应的编码就行了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[脚本描述头信息]]></title>
      <url>http://czero000.github.io/2015/12/29/scripts-heard-info.html</url>
      <content type="text"><![CDATA[添加脚本描述头信息当编写脚本或者其他程序是，在脚本开头添加脚本描述信息，更方便的向阅读脚本的人来解释脚本用途并提供他们需要了解的其他信息123456789#!/bin/bash######################################################## Description: CentOS5.4 Initialization Script #### Version: 1.0 #### Date: 2015-09-01 #### Author: Charlie.Cui #### Mail: Charlie.cui127@gmail.com ## ## License: General Public License (GPL) ######################################################## 通过脚本生成脚本描述头1234567891011121314151617#!/bin/bashif ! grep &quot;^#!&quot; $1 &amp;&gt;/dev/nullthencat &gt;&gt; $1 &lt;&lt; EOF#!/bin/bash###################################################### Title: $1 ## Description: Please Write Scripts Describing## Version: 1.0 ## Date: `date +%F` ## Author: Charlie.Cui ## Mail: Charlie.cui127@gmail.com ## License: General Public License (GPL) ####################################################EOFfivim +4 $1 增加执行权限，然后通过./makescripts scriptsname.sh生成脚本。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CetnOS各个版本下载]]></title>
      <url>http://czero000.github.io/2015/12/29/download-centos-iso.html</url>
      <content type="text"><![CDATA[CentOS 官方镜像源中镜像版本并不完全，只有各个系列较新的版本iso提供下载，下面网站提供各个版本的iso下载，网站为国外网站，下载较慢 http://archive.kernel.org/centos-vault/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[网卡em恢复为eth]]></title>
      <url>http://czero000.github.io/2015/12/29/change-em1-to-eth0.html</url>
      <content type="text"><![CDATA[随之服务器系统从CentOS5.x逐步升级到CentOS6.x，发现原来熟悉的eth0、eth1全部变成了em1、em2。接口名变化并不会对平时的运维工作有影响，不过某些应用可能会收到影响，所以还是改过来，比较好。经过资料整理，有两种方式： 更改配置文件dmesg中看到如下一行信息：kernel: udev: renamed network interface eth0 to em1 原来是udev这个设备管理进程在开机过程中将系统默认的eth0改名为em1了，其实em1对应的就是系统原本的eth0网卡；由于我在mini安装过程中没有对网络进行配置，所以系统默认没有将网卡激活导致ifconfig看不到任何网卡；只需要在/etc/sysconfig/network-scripts/ifcfg-em1中将参数ONBOOT=no改为yes，然后service network restart 网卡em1就出现了！ 总觉得Linux的网卡代号变成了em1不习惯，想还原为一直以来熟悉的eth0也是可以的，调整udev的网卡命名规则配置文件/etc/udev/rules.d/70-persistent-net.rules,将文件中em2 替换为eth1，em1替换为eth0，这样系统就会把网卡命名还原回来，还要把网卡配置文件中的设备名改回来。重启系统，这样熟悉的eth0、eth1就回来了 修改系统grub 增加biosdevname=0 启动参数 123 kernel /vmlinuz-2.6.32-431.el6.i686 ro root=UUID=84316edf-b537-486c-bf2e-616aa51ede2f rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM biosdevname=0 rhgb quiet 删除udev的配置文件 1rm -f /etc/udev/rules.d/70-persistent-net.rules 重命名当前网卡配置文件 1mv ifcfg-em1 ifcfg-eth0 修改网卡配置文件内容，将em1替换为eth0 重启服务器，这样熟悉的eth0、eth1就回来了]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[安装XZ解压工具]]></title>
      <url>http://czero000.github.io/2015/12/29/centos-install-xz.html</url>
      <content type="text"><![CDATA[从www.kernel.org下载内核安装包，准备CentOS6.5内核升级到3.x，下载后发现是一个以.xz结尾的压缩包。 xz 是一个使用 LZMA压缩算法的无损数据压缩文件格式。 和gzip与bzip2一样，同样支持多文件压缩，但是约定不能将多于一个的目标文件压缩进同一个档案文件。 相反，xz通常作为一种归档文件自身的压缩格式，例如使用tar或cpioUnix程序创建的归档。 xz 在GNU coreutils（版本 7.1 或更新）[1]中被使用。 xz 作为压缩软件包被收录在 Fedora (自Fedora 12起)[2], Arch Linux[3], FreeBSD、 Slackware Linux、CRUX和 Funtoo Linux中。xz 以其优异的性能和压缩比[4]成为了不少开源软件（例如 Linux 内核源码、Debian deb[5] 和 Fedora rpm）的压缩方式之一，甚至是默认压缩方式。xz 命令行程序曾有过一个名为 pxz 的分支，提供多线程压缩功能，后来 xz 在 5.2 时本身就直接提供多线程了. XZ Utils官方网站 下载软件包1wget http://tukaani.org/xz/xz-5.2.2.tar.gz 解压1tar -zxf xz-5.2.2.tar.gz 编译安装12./configure make &amp;&amp; make install 使用方法123456789101112131415161718192021222324252627 xz --helpUsage: xz [OPTION]... [FILE]...Compress or decompress FILEs in the .xz format. -z, --compress force compression -d, --decompress force decompression -t, --test test compressed file integrity -l, --list list information about .xz files -k, --keep keep (don&apos;t delete) input files -f, --force force overwrite of output file and (de)compress links -c, --stdout write to standard output and don&apos;t delete input files -0 ... -9 compression preset; default is 6; take compressor *and* decompressor memory usage into account before using 7-9! -e, --extreme try to improve compression ratio by using more CPU time; does not affect decompressor memory requirements -T, --threads=NUM use at most NUM threads; the default is 1; set to 0 to use as many threads as there are processor cores -q, --quiet suppress warnings; specify twice to suppress errors too -v, --verbose be verbose; specify twice for even more verbose -h, --help display this short help and exit -H, --long-help display the long help (lists also the advanced options) -V, --version display the version number and exitWith no FILE, or when FILE is -, read standard input.Report bugs to (in English or Finnish).XZ Utils home page: 12解压： xz -d linux-3.12.50.tar.xz 压缩： xz -z linux-3.12.50.tar]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[安装Chromium浏览器]]></title>
      <url>http://czero000.github.io/2015/12/29/centos-install-chromium.html</url>
      <content type="text"><![CDATA[之前Google就说了，由于CentOS/RHEL 6已经是过期的系统，所以不再会有Chrome了。 虽然后来由于引起了社区的抗议，从而改口，不再提CentOS/RHEL 6是过期系统了；但是，目前在CentOS/RHEL 6上已经没有Chrome可以下载使用了。 其实，根本的原因不是CentOS/RHEL 6有多老，连Windows XP和停止更新的Ubuntu 10.04都能继续使用Chrome呢。实际的原因是，Chrome由于种种考虑，使用了CentOS/RHEL 6中所不支持的C++ 11，所以才不能继续更新CentOS/RHEL 6上的Chrome。 那么，如果希望在CentOS/RHEL 7出来之前继续使用Chrome怎么办？使用Chrome的开源版本：Chromium 切换到root1su - 或者 sudo -i 下载新的软件源定义12cd /etc/yum.repos.dwget http://people.centos.org/hughesjr/chromium/6/chromium-el6.repo 安装Chromium1yum install -y chromium 这样就安装完成了。可以通过菜单来启动浏览器 启动后 如果需要查看Flash和PDF，可以继续下面两步来安装插件。 安装Pepper Flash插件：下载 hughesjr 辅助安装脚本12cd /tmpwget http://raw.github.com/hughesjr/chromium_el_builder/master/chrome_pepperflash_copy.sh 设置 chrome_pepperflash_copy.sh 为可执行1chmod +x chrome_pepperflash_copy.sh 安装（你可以查看一下脚本内容来了解发生了什么）1./chrome_pepperflash_copy.sh 安装后，如果需要通过命令行方式启动（带有Flash支持），可以输入以下命令： 1/opt/chromium/chrome-wrapper %U --ppapi-flash-path=/opt/chromium/PepperFlash/libpepflashplayer.so --ppapi-flash-version=$(grep &apos;&quot;version&quot;:&apos; /opt/chromium/PepperFlash/manifest.json | grep -Po &apos;(?&lt;=version&quot;: &quot;)(?:\d|\.)*&apos;) 也可以修改系统菜单中的对应命令 安装Google Chrome PDF Viewer插件：下载 hughesjr 辅助安装脚本12cd /tmpwget http://raw.github.com/hughesjr/chromium_el_builder/master/chrome_libpdf_copy.sh 设置 chrome_libpdf_copy.sh 为可执行1chmod +x chrome_libpdf_copy.sh 执行脚本进行安装（你可以查看一下脚本内容来了解发生了什么）1./chrome_libpdf_copy.sh]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[安装BT软件Transmission]]></title>
      <url>http://czero000.github.io/2015/12/29/centos-install-transmission.html</url>
      <content type="text"><![CDATA[安装依赖包1yum -y install gcc gcc-c++ m4 make automake libtool gettext openssl-devel pkgconfig perl-libwww-perl perl-XML-Parser curl curl-devel vsftpd libevent-devel libevent libidn-devel zlib-devel 下载transmission及必要软件1234wget http://download-origin.transmissionbt.com/files/transmission-2.84.tar.xzwget http://ftp.acc.umu.se/pub/gnome/sources/intltool/0.40/intltool-0.40.6.tar.gzwget http://ftp.gnu.org/gnu/libiconv/libiconv-1.14.tar.gzwget http://cloud.github.com/downloads/libevent/libevent/libevent-2.0.21-stable.tar.gz 安装软件包12345678910111213141516171819202122tar -zxf intltool-0.40.6.tar.gz cd intltool-0.40.6./configure make &amp;&amp; make install cd ..tar -zxf libiconv-1.14.tar.gz ./configure make &amp;&amp; make install echo &quot;/usr/local/lib&quot; &gt;&gt; /etc/ld.so.conf ldconfig cd ..tar -zxf libevent-2.0.21-stable.tar.gz cd libevent-2.0.21-stable./configure make &amp;&amp; make install export PKG_CONFIG_PATH=/usr/local/lib/pkgconfigcd ..xz -d transmission-2.84.tar.xz tar -xf transmission-2.84.tar cd transmission-2.84./configure --prefix=/usr/local/transmission CFLAGS=-liconvmake &amp;&amp; make install 配置12transmission-daemon -g /usr/local/transmissionkillall transmission-daemon 以上命令需执行两次 然后就可以进行配置了123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960cat /usr/local/transmission/settings.json&#123; &quot;alt-speed-down&quot;: 50, &quot;alt-speed-enabled&quot;: false, &quot;alt-speed-time-begin&quot;: 540, &quot;alt-speed-time-day&quot;: 127, &quot;alt-speed-time-enabled&quot;: false, &quot;alt-speed-time-end&quot;: 1020, &quot;alt-speed-up&quot;: 50, &quot;bind-address-ipv4&quot;: &quot;0.0.0.0&quot;, &quot;bind-address-ipv6&quot;: &quot;::&quot;, &quot;blocklist-enabled&quot;: true, &quot;blocklist-url&quot;: &quot;http://www.example.com/blocklist&quot;, &quot;cache-size-mb&quot;: 4, &quot;dht-enabled&quot;: true, //DHT支持 &quot;download-dir&quot;: &quot;/data/transmission/Downloads&quot;, //下载完成的保存路径 &quot;encryption&quot;: 1, &quot;idle-seeding-limit&quot;: 30, &quot;idle-seeding-limit-enabled&quot;: false, &quot;incomplete-dir&quot;: &quot;/data/transmission/Downloads&quot;, //未下载完成的保存路径 &quot;incomplete-dir-enabled&quot;: false, &quot;lazy-bitfield-enabled&quot;: true, &quot;lpd-enabled&quot;: false, &quot;message-level&quot;: 2, &quot;open-file-limit&quot;: 32, &quot;peer-congestion-algorithm&quot;: &quot;&quot;, &quot;peer-limit-global&quot;: 240, //全局种子最大连接数 &quot;peer-limit-per-torrent&quot;: 60, //单一种子最大连接数 &quot;peer-port&quot;: 51413, &quot;peer-port-random-high&quot;: 65535, &quot;peer-port-random-low&quot;: 49152, &quot;peer-port-random-on-start&quot;: false, &quot;peer-socket-tos&quot;: &quot;default&quot;, &quot;pex-enabled&quot;: true, &quot;port-forwarding-enabled&quot;: true, &quot;preallocation&quot;: 1, &quot;prefetch-enabled&quot;: 1, &quot;ratio-limit&quot;: 2, &quot;ratio-limit-enabled&quot;: false, &quot;rename-partial-files&quot;: true, &quot;rpc-authentication-required&quot;: true, &quot;rpc-bind-address&quot;: &quot;0.0.0.0&quot;, &quot;rpc-enabled&quot;: true, &quot;rpc-password&quot;: &quot;&#123;096110376f678fa59ac93b4ba2ef383fba6a9edcBELB4tYF&quot;, //密码 &quot;rpc-port&quot;: 9091, //网页GUI使用的端口 &quot;rpc-url&quot;: &quot;/transmission/&quot;, &quot;rpc-username&quot;: &quot;&quot;, //用户名 &quot;rpc-whitelist&quot;: &quot;*.*.*.*&quot;, &quot;rpc-whitelist-enabled&quot;: true, &quot;script-torrent-done-enabled&quot;: false, &quot;script-torrent-done-filename&quot;: &quot;&quot;, &quot;speed-limit-down&quot;: 100, &quot;speed-limit-down-enabled&quot;: false, &quot;speed-limit-up&quot;: 100, &quot;speed-limit-up-enabled&quot;: false, &quot;start-added-torrents&quot;: true, &quot;trash-original-torrent-files&quot;: false, &quot;umask&quot;: 18, //这里改为0，可以控制默认下载文件权限为777 &quot;upload-slots-per-torrent&quot;: 14 //每个种子上传连接数&#125; 执行transmission-daemon -g /usr/local/transmission，通过浏览器登陆（http://yourIP:9091/）就可以控制了。yum安装Transmission以前装在VPS上安装Transmission当Seedbox使大多使用一些一键包，或者使用rpm包的方式安装，一键包的方式我一直不喜欢，经常出问题，而且一般版本都很旧。rpm包的方式可以参考这篇文章，不过这里的版本也已经很旧了，geekery现在提供更加方便yum repo的方式安装，自动解决依赖问题，版本很新(目前是2.71)，并可通过yum更新。 安装方法非常简单，简单翻译了一下，原文可以参考这里:12345678910111213cd /etc/yum.repos.d/CentOS 5 x86wget http://geekery.altervista.org/geekery-el5-i386.repoCentOS 5 x86_64wget http://geekery.altervista.org/geekery-el5-x86_64.repoCentOS 6 x86wget http://geekery.altervista.org/geekery-el6-i686.repoCentOS 6 x86_64wget http://geekery.altervista.org/geekery-el6-x86_64.repo 然后:1yum install -y transmission transmission-daemon 提示导入GPG Key的时候输y同意即可 注意：如果之前通过RPM包的方式安装过Transmission，需要卸载后再用yum安装。装好后可以通过1service transmission-daemon start 来启动Transmission 配置文件位于/var/lib/transmission/.config/transmission-daemon/settings.json(CentOS 5)或/var/lib/transmission/settings.json(CentOS 6)修改配置文件前要先用1service transmission-daemon stop 关掉Transmission，否则配置不会生效。具体的配置网上有很多，就不详细说了12345 &quot;rpc-authentication-required&quot;: true, &quot;rpc-enabled&quot;: true, &quot;rpc-password&quot;: &quot;管理密码密码&quot;, &quot;rpc-username&quot;: &quot;管理用户名&quot;, &quot;rpc-whitelist-enabled&quot;: false, 主要是把这几项改成我上面的样子就可以了，然后你就可以通过http://你的IP地址:9091的方式连接了。远程管理建议使用Transmission-Remote-GUI]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS6.5升级内核]]></title>
      <url>http://czero000.github.io/2015/12/29/update-kernel.html</url>
      <content type="text"><![CDATA[查看当前系统内核12uname -r2.6.32-431.el6.x86_64 下载linux内核包123wget http://www.kernel.org/pub/linux/kernel/v3.0/linux-3.18.20.tar.gztar -zxf linux-3.18.20.tar.gz cd linux-3.18.20 配置内核并安装12345678make mrproper //清除环境变量，清除配置文件cp /boot/config-2.6.32-431.el6.x86_64 .config //复制原有系统的内核配置文件make oldconfig //读取当前目录下的.config文件，在.config文件里没有找到的选项则提示用户填写 sh -c &apos;yes &quot;&quot; | make oldconfig&apos;make menuconfig //在菜单模式下选择需要编译的内核模块（未选择此类型）make clean //确保所有都是最新状态make bzImage //生成内核文件make modules //编译模块make modules_install //安装模块 修改grub引导，重启服务器修改grub引导顺序，让新安装的内核作为默认内核，新安装的内核在第一位置，所以default=012345678910111213141516171819202122cat /boot/grub/grub.conf # grub.conf generated by anaconda## Note that you do not have to rerun grub after making changes to this file# NOTICE: You have a /boot partition. This means that# all kernel and initrd paths are relative to /boot/, eg.# root (hd0,0)# kernel /vmlinuz-version ro root=/dev/sda5# initrd /initrd-[generic-]version.img#boot=/dev/sdadefault=0timeout=5splashimage=(hd0,0)/grub/splash.xpm.gzhiddenmenutitle CentOS (3.18.20) root (hd0,0) kernel /vmlinuz-3.18.20 ro root=UUID=0303a1aa-552b-4de9-ac52-6bc95361d832 rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet initrd /initramfs-3.18.20.imgtitle CentOS (2.6.32-431.el6.x86_64) root (hd0,0) kernel /vmlinuz-2.6.32-431.el6.x86_64 ro root=UUID=304a1aa-552b-4de9-ac52-6bc95361d832 rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet initrd /initramfs-2.6.32-431.el6.x86_64.img 重启系统1reboot 确认当前内核版本12uname -r3.18.20]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[epel安装地址]]></title>
      <url>http://czero000.github.io/2015/12/29/install-epel.html</url>
      <content type="text"><![CDATA[CentOS71rpm -Uvh http://mirrors.yun-idc.com/epel/7/x86_64/e/epel-release-7-5.noarch.rpm CentOS61234\\ 32位rpm -Uvh http://mirrors.yun-idc.com/epel/6/i386/epel-release-6-8.noarch.rpm\\ 64位rpm -Uvh http://mirrors.yun-idc.com/epel/6/x86_64/epel-release-6-8.noarch.rpm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS7安装中文支持]]></title>
      <url>http://czero000.github.io/2015/12/29/centos7-support-chinese.html</url>
      <content type="text"><![CDATA[Centos7是Centos系列的最新版本，与老版本出现了较大操作差异，下面是安装中文支持 ###中文支持 安装语言包 1yum install kde-l10n-Chinese -y 修改系统默认语言 1localectl set-locale LANG=zh_CN.utf8 安装中文字体 1yum install ibus-table-chinese* 查看已安装的字体 123456789101112fc-list :lang=zh/usr/share/fonts/cjkuni-ukai/ukai.ttc: AR PL UKai TW:style=Book/usr/share/fonts/cjkuni-ukai/ukai.ttc: AR PL UKai HK:style=Book/usr/share/fonts/cjkuni-ukai/ukai.ttc: AR PL UKai CN:style=Book/usr/share/fonts/wqy-zenhei/wqy-zenhei.ttc: 文泉驿点阵正黑,文泉驛點陣正黑,WenQuanYi Zen Hei Sharp:style=Regular/usr/share/fonts/cjkuni-uming/uming.ttc: AR PL UMing TW MBE:style=Light/usr/share/fonts/wqy-zenhei/wqy-zenhei.ttc: 文泉驿等宽正黑,文泉驛等寬正黑,WenQuanYi Zen Hei Mono:style=Regular/usr/share/fonts/wqy-zenhei/wqy-zenhei.ttc: 文泉驿正黑,文泉驛正黑,WenQuanYi Zen Hei:style=Regular/usr/share/fonts/cjkuni-ukai/ukai.ttc: AR PL UKai TW MBE:style=Book/usr/share/fonts/cjkuni-uming/uming.ttc: AR PL UMing TW:style=Light/usr/share/fonts/cjkuni-uming/uming.ttc: AR PL UMing HK:style=Light/usr/share/fonts/cjkuni-uming/uming.ttc: AR PL UMing CN:style=Light 重新连接终端即可]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Shadowsocks搭建Sock5代理]]></title>
      <url>http://czero000.github.io/2015/12/22/install-shadowsocks.html</url>
      <content type="text"><![CDATA[什么是ShadowSocks Shadowsocks 是一个安全的socks5代理，用于保护网络流量，是一个开源项目。通过客户端以指定的密码、加密方式和端口连接服务器，成功连接到服务器后，客户端在用户的电脑上构建一个本地socks5代理。使用时将流量分到本地socks5代理，客户端将自动加密并转发流量到服务器，服务器以同样的加密方式将流量回传给客户端，以此实现代理上网。其流行起来的一大原因，多亏了国内不科学的防火长城和某些地区的SSH Tunnel连接被禁用。 Shadowsocks优势 如前面所说，使用SSH来创建本地socks5代理的方法容易被发现，某些地区干脆进行了封锁，而Shadowsocks的代理方式更为隐蔽和安全。 无需保持实时连接，不用考虑断线问题。在使用SSH时，总会发生断开连接的情况，如网络不稳定、电脑休眠、切换wifi等，此时SSH连接将断开，浏览网页什么的会提示无法连接到代理服务器。虽然客户端大都支持断线重连，但是反应经常不太灵敏，平均需要30秒左右的时间（而且这个时间是从你点开网页开始算的）。如果你用的是手机的话，鉴于手机网络的多变性，人一旦动起来就几乎不可用了。 更丰富的客户端支持。目前Shadowsocks官网（是shadowsocks.org，不是.com那个，.com那个是售卖账号的，并非官网，有假冒官网的嫌疑）提供几乎全平台支持，包括linux和非越狱iPhone在内。尤其是OS X版的自动代理模式（PAC）非常稳定，胜过GoAgentX，完美支持safari。同时，各个平台上的客户端使用都十分简单，基本上就是填写一下地址端口密码什么的，就能开始使用了，连点击连接都不用。另外，大部分客户端支持扫描屏幕二维码完成配置，这个指导新手不要太爽。shadowsocks软件覆盖 服务端安装ShadowSocks shadowsocks开发语言有Node.JS、go、pthon、c shadowsocks python语言版 http://github.com/clowwindy/shadowsocks shadowsocks go语言版 http://github.com/hugozhu/shadowsocks-go shadowsocks nodejs语言版 http://github.com/clowwindy/shadowsocks-nodejs shadowsocks libev版（使用C语言+libev库+openssl开发） http://github.com/madeye/shadowsocks-libev shadowsocks libuv版（很久没更新了） http://github.com/dndx/shadowsocks-libuv 网上推荐安装python版和Shadowsocks-libev版，这里安装标准python版，系统为CentOS7。 检查服务器python，确保python 版本高于2.6123python --versionPython 2.7.5 安装依赖库1yum -y install m2crypto python-setuptools 安装PIP1234yum -y install python-pip或者wget http://raw.github.com/pypa/pip/master/contrib/get-pip.pypython get-pip.py 安装Shadowsocks1pip install shadowsocks 配置ShadowSocks安装ShadowSocks之后可以在后天直接启动ssserver -p 8000 -k password -m rc4-md5 -d start当然也可以使用配置文件进行配置，创建/etc/shadowsocks/shadowsocks.json文件，如下：12345678&#123; &quot;server&quot;:&quot;my_server_ip&quot;, &quot;server_port&quot;:8388, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;barfoo!&quot;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;table&quot;&#125; 字段解释： server: 服务器ip地址(IPV4/IPV6)，即为端口监听ip server_port： Shadowsocks服务监听端口 local_port： 本地端口 password： 密码 timeout 超时时间 method 加密方法(“bf-cfb”, “aes-256-cfb”, “des-cfb”, “rc4”)、默认为table，但是它并不安全，官方建议”aes-256-cfb” shadowsockv 支持多端口多用户模式12345678910111213141516&#123; &quot;server&quot;:&quot;my_server_ip&quot;, &quot;local_port&quot;:1080, &quot;timeout&quot;:600, &quot;method&quot;: &quot;aes-256-cfb&quot;, &quot;port_password&quot;: &#123; &quot;9123&quot;:&quot;passwd1&quot;, &quot;9124&quot;:&quot;passwd2&quot; &#125; &quot;_comment&quot;: &#123; &quot;9123&quot;:&quot;hanmeimei&quot;, &quot;9124&quot;:&quot;lilei&quot; &#125;&#125; 启动Shadowsocks1234 ssserver -c /etc/shadowsocks/shadowsocks.json -d startINFO: loading config from /etc/shadowsocks/shadowsocks.json2015-10-10 04:40:30 INFO loading libcrypto from libcrypto.so.10started 如果要停止Shadowsocks，将命令中start变更为stop即可 TIPS: 加密方式推荐使用rc4-md5，因为 RC4 比 AES 速度快好几倍，如果用在路由器上会带来显著性能提升。旧的 RC4 加密之所以不安全是因为 Shadowsocks 在每个连接上重复使用 key，没有使用 IV。现在已经重新正确实现，可以放心使用。更多可以看issue。 客户端安装下载客户端Shadowsocks官网下载链接：http://shadowsocks.org/en/download/clients.html如果打不开官方下载地址，可以在这里下载（不能保证为最新版本） Windows Windows 7 or above: 2.5.8.zip Mac OS ShadowsocksX: 2.6.3.dmg 运行客户端客户端都是免安装，打开就可以使用，可以参考这篇文章Shadowsocks快速安装与配置指南 ShadowSocks优化首先将内核升级到3.5或者以上 增加系统文件描述符的最大数量编辑/etc/secritylimits.conf文件增加以下两行12* soft nofile 51200* hard nofile 51200 在启动Shadowsocks服务前，设置1ulimit -n 51200 调整内核参数编辑/etc/sysctl.conf，修改以下内容123456789101112131415161718192021fs.file-max = 51200net.core.rmem_max = 67108864net.core.wmem_max = 67108864net.core.netdev_max_backlog = 250000net.core.somaxconn = 4096net.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 0net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_keepalive_time = 1200net.ipv4.ip_local_port_range = 10000 65000net.ipv4.tcp_max_syn_backlog = 8192net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_fastopen = 3net.ipv4.tcp_mem = 25600 51200 102400net.ipv4.tcp_rmem = 4096 87380 67108864net.ipv4.tcp_wmem = 4096 65536 67108864net.ipv4.tcp_mtu_probing = 1net.ipv4.tcp_congestion_control = hybla 最后执行sysctl -p使配置生效]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[pptpvpn记录登录用户名]]></title>
      <url>http://czero000.github.io/2015/12/22/pptp-username-log.html</url>
      <content type="text"><![CDATA[pptpd的日志主要大部分都在/var/log/messages, /var/log/daemon等文件里面，但是仔细看了发现里面没有用户名，不知道用户是用了哪一个帐号登录上来的。于是就看了一下pppd的man，里面发现了一些环境变量如：IPLOCAL, IPREMOTE等，经过测试发现 PEERNAME就是用户名，这样在/etc/ppp/ip-up和/etc/ppp/ip-down里面记录一下就可以了，另外没有发现用户的ip。后来发现pppd是spawn出一个子进程来控制pptpd连接的，子进程的命令行里面已经带有了用户的ip，经过多次试验，发现ip-up被调用的时候是有命令行参数的，$6就是用户ip，于是在ip-up里面手工用echo命令写了一下，算是pptpd的比较完整日志，里面有时间，有来源ip，有用户名，有被分配的ppp的ip等 在/etc/ppp/ip-up和/etc/ppp/ip-down中加入脚本123456echo &quot;time: `date -d today +%F_%T`&quot; &gt;&gt; /var/log/pptpd.log echo &quot;clientIP: $6&quot; &gt;&gt; /var/log/pptpd.log echo &quot;username: $PEERNAME&quot; &gt;&gt; /var/log/pptpd.log echo &quot;device: $1&quot; &gt;&gt; /var/log/pptpd.log echo &quot;vpnIP: $4&quot; &gt;&gt; /var/log/pptpd.log echo &quot;assignIP: $5&quot; &gt;&gt; /var/log/pptpd.log]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[PPTP VPN安装脚本]]></title>
      <url>http://czero000.github.io/2015/12/22/install-pptpd-by-scripts.html</url>
      <content type="text"><![CDATA[pptp vpn 一键安装脚本，适用 rhel5.x_86-64 系统12345678910111213141516171819202122232425262728293031323334353637383940414243#!/bin/bash########################################################## Description: pptpd Install PPTP VPN For rhel5.x_x64#### Version: 1.0 #### Date: 2015-08-05 #### Author: Charlie.Cui #### Mail: Charlie.cui127@gmail.com ## ## License: General Public License (GPL) #### Copyright© 2015, Charlie.Cui All Rights Reserved ##########################################################yum remove -y pptpd pppiptables --flush POSTROUTING --table natiptables --flush FORWARDrm -rf /etc/pptpd.confrm -rf /etc/pppwget http://poptop.sourceforge.net/yum/stable/packages/kernel_ppp_mppe-1.0.2-3dkms.noarch.rpmwget http://poptop.sourceforge.net/yum/stable/packages/dkms-2.0.17.5-1.noarch.rpmwget http://poptop.sourceforge.net/yum/stable/packages/ppp-2.4.4-14.1.rhel5.x86_64.rpmwget http://poptop.sourceforge.net/yum/stable/packages/pptpd-1.4.0-1.rhel5.x86_64.rpmyum -y install make libpcap iptables gcc-c++ logrotate tar cpio perl pam tcp_wrappersrpm -ivh dkms-2.0.17.5-1.noarch.rpmrpm -ivh kernel_ppp_mppe-1.0.2-3dkms.noarch.rpmrpm -ivh ppp-2.4.4-14.1.rhel5.x86_64.rpmrpm -ivh pptpd-1.4.0-1.rhel5.x86_64.rpmmknod /dev/ppp c 108 0echo 1 &gt; /proc/sys/net/ipv4/ip_forwardecho &quot;mknod /dev/ppp c 108 0&quot; &gt;&gt; /etc/rc.localecho &quot;echo 1 &gt; /proc/sys/net/ipv4/ip_forward&quot; &gt;&gt; /etc/rc.localecho &quot;localip 172.16.6.1&quot; &gt;&gt; /etc/pptpd.confecho &quot;remoteip 172.16.6.2-254&quot; &gt;&gt; /etc/pptpd.confecho &quot;ms-dns 8.8.8.8&quot; &gt;&gt; /etc/ppp/options.pptpdecho &quot;ms-dns 8.8.4.4&quot; &gt;&gt; /etc/ppp/options.pptpdvpnpass=`openssl rand 6 -base64`if [ &quot;$1&quot; != &quot;&quot; ]then vpnpass=$1fiecho &quot;vpnuser pptpd $&#123;vpnpass&#125; *&quot; &gt;&gt; /etc/ppp/chap-secretsiptables -t nat -A POSTROUTING -s 172.16.6.0/24 -j SNAT --to-source `ifconfig | grep &apos;inet addr:&apos;| grep -v &apos;127.0.0.1&apos; | cut -d: -f2 | awk &apos;NR==1 &#123; print $1&#125;&apos;`iptables -t nat -A POSTROUTING -s 192.38.38.0/255.255.255.0 -d 192.168.48.116 -o eth1 -j SNAT --to-source 192.168.39.250 chkconfig pptpd onservice pptpd startecho &quot;VPN service is installed, your VPN username is vpn, VPN password is $&#123;pass&#125;&quot;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[安装ss5代理]]></title>
      <url>http://czero000.github.io/2015/12/22/install-ss5-proxy.html</url>
      <content type="text"><![CDATA[socks5代理服务官网：http://ss5.sourceforge.net/ 安装gcc编译环境和相关依赖包1yum -y install pam-devel openldap-devel cyrus-sasl-devel gcc gcc-c++ automake make openssl openssl-devel 下载ss51wget http://cznic.dl.sourceforge.net/project/ss5/ss5/3.8.9-8/ss5-3.8.9-8.tar.gz 编译安装ss51234tar -zxf ss5-3.8.9-8.tar.gzcd ss5-3.8.9./configure make &amp;&amp; make install 配置ss5编译安装后的配置文件在/etc/opt/ss5下面1ss5.conf ss5.ha ss5.passwd 添加用户和密码ss5.passwd的用法是：用户 密码 配置代理权限ss5.conf 用法123auth 0.0.0.0/0 - -# Auth SHost SPort DHost DPort Fixup Group Band ExpDatepermit - 0.0.0.0/0 - 0.0.0.0/0 - - test - - 修改/etc/init.d/ss5文件自定义端口，默认为10801daemon /usr/sbin/ss5 -t $SS5_OPTS -b 0.0.0.0:1081 在/etc/sysconfig/ss5中，取消注释 1SS5_OPTS=&quot; -u root&quot; 启动ss512/etc/init.d/ss5 startdoneting ss5... [ OK ]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[自建yum仓库同步脚本]]></title>
      <url>http://czero000.github.io/2015/12/22/create-yum-mirrors-by-self.html</url>
      <content type="text"><![CDATA[自建yum仓库自建内部yum仓库，提高软件安装速度和方便性，同时不需要对新服务器开通对公网的访问权限，也提高了安全性。 系统环境安装httpd作为web server，提供文件下载。安装环境请参考cobbler安装。 同步脚本12345678910111213141516171819202122#!/bin/bash######################################################## Title: Rsync CentOS\EPEL Yum Mirrors Script #### Version: 1.0 #### Date: 2015-12-17 #### Author: Charlie.Cui #### Email: charlie.cui127@gmail.com## License: General Public License (GPL) #### Copyright© 2015, Charlie.Cui All Rights Reserved ########################################################Date=`date +%Y%m%d`LogFile=&quot;/tmp/update_mirror.log&quot;_TrunkVer=&quot;epel centos ubuntu ubuntu-releases archlinux&quot;COMMAND=/usr/bin/rsyncOption=&quot;-vazrtopg --progress --delete&quot;YumWebsite=&quot;rsync://mirrors.yun-idc.com&quot;for Class in $_TrunkVer;doecho &quot;----$Date `date +%T` Begin Rsync $Class-------&quot;&gt;&gt; $LogFile_Path=/data/mirrors/$Class/$COMMAND $Option $YumWebsite/$Class/ $_Path &gt;&gt; $LogFileecho &quot;----$Date `date +%T` Complate Rsync $Class--------&quot;&gt;&gt; $LogFiledone]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[编译安装ntp服务]]></title>
      <url>http://czero000.github.io/2015/12/21/sourcecode-install-ntp.html</url>
      <content type="text"><![CDATA[升级背景NTP服务漏洞 “未经过身份验证的攻击者能够迫使网络时间协议守护进程（ntpd）与恶意的时间服务器源进行同步，这样一来，攻击者就可以随意修改目标 系统的系统时间了。网络时间协议守护进程（ntpd）在处理某些经过加密的、没有得到应答的网络数据包时，会发生错误。”总的来说，恶意攻击者能够迫使目标主机的网络时间协议守护进程（ntpd）与恶意的时间同步源进行同步，并且干扰目标系统的系统时钟。除此之外，网络时间协议守护进程（ntpd）也可以与特定类型的同步请求进行响应。根据思科Talos安全情报研究团队的描述：“在大多数的配置文件下，如果网络时间协议守护进程（ntpd）接收到了这样的一个数据包，如果网络时间协议守 护进程（ntpd）能够验证这个数据包的有效性，那么它就会让计算机与请求的发送端建立一个短暂的链接。比如说，当网络时间协议守护进程（ntpd）接收 到一个请求数据包时，ntpd会对数据包的有效性进行一系列的检测。” 在某些操作系统中，恶意地更改系统时间将会带来非常严重的影响，攻击者可以利用这一漏洞来实现： 利用过期的账号和密码进行身份验证； 让TLS客户端接收已经过期作废的证书，并拒绝当前有效的证书； 绕过现代Web安全防御机制，例如证书绑定以及HTTP安全传输机制； 强制刷新缓存系统中的缓存数据，从而导致系统性能显著下降，例如DNS和CDN等； 攻击基于物理的实时网络系统； 谁将受到这些问题的影响？ 这一漏洞将会影响ntp 4.2.8p3，正如Talos团队的专家所述，这一漏洞早在2009年的ntp 4.2.5p186版本中就已经存在了。因此，在所有ntp-4发行版的版本中，4.2.5p186至4.2.8p3版本的ntp都存在这一漏洞。在所有ntp－4开发版的版本中，4.3.0至4.3.76版本的ntp也存在这一漏洞。除此之外，所有整合了上述版本ntpd的产品也将会受到这一漏洞的影响。除此之外，Talos安全情报研究团队的专家们还发现了下列漏洞： 整型溢出将引起守护进程的崩溃； NTP的密码管理器中存在一个用后释放（UAF）漏洞和一个缓冲区溢出漏洞； 一个VMS目录遍历漏洞； NTPQ中的一个漏洞； 远程攻击者可以向目标主机发送一个恶意的配置文件，从而对目标主机发动拒绝服务（DoS）攻击； 守护进程中存在一个缓冲区溢出漏洞； NTP项目小组建议广大用户应当尽快安装ntp-4.2.8p4来修复这一问题，并且采用BCP 38数据包输入输出过滤。 升级步骤系统环境测试主机：CentOS release 6.5 (Final) i386 卸载系统自带软件1234rpm -qa ntpntp-4.2.6p5-1.el6.centos.i686rpm -e ntp-4.2.6p5-1.el6.centos.i686 --nodepswarning: /etc/ntp.conf saved as /etc/ntp.conf.rpmsave 下载软件源码1wget http://www.eecis.udel.edu/~ntp/ntp_spool/ntp4/ntp-4.2/ntp-4.2.8p4.tar.gz 安装NTP1234tar -zxf ntp-4.2.8p4.tar.gz cd ntp-4.2.8p4./configure --enable-all-clocks --enable-parse-clocks --enable-linuxcaps make &amp;&amp; make install 配置NTP12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061cat /etc/ntp.conf # For more information about this file, see the man pages# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).driftfile /var/lib/ntp/drift# Permit time synchronization with our time source, but do not# permit the source to query or modify the service on this system.restrict default kod nomodify notrap nopeer noqueryrestrict -6 default kod nomodify notrap nopeer noquery# Permit all access over the loopback interface. This could# be tightened as well, but to do so would effect some of# the administrative functions.restrict 127.0.0.1 restrict -6 ::1# Hosts on local network are less restricted.restrict 172.16.0.0 mask 255.255.0.0 nomodify notrap# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).server 3.cn.pool.ntp.org perfer server 1.cn.pool.ntp.orgserver 0.asia.pool.ntp.org#broadcast 192.168.1.255 autokey # broadcast server#broadcastclient # broadcast client#broadcast 224.0.1.1 autokey # multicast server#multicastclient 224.0.1.1 # multicast client#manycastserver 239.255.254.254 # manycast server#manycastclient 239.255.254.254 autokey # manycast clientrestrict 3.cn.pool.ntp.org nomodify notrap noqueryrestrict 1.cn.pool.ntp.org nomodify notrap noqueryrestrict 0.asia.pool.ntp.org nomodify notrap noqueryserver 127.127.1.0 # local clockfudge 127.127.1.0 stratum 10# Enable public key cryptography.#cryptoincludefile /etc/ntp/crypto/pw# Key file containing the keys and key identifiers used when operating# with symmetric key cryptography. keys /etc/ntp/keys# Specify the key identifiers which are trusted.#trustedkey 4 8 42# Specify the key identifier to use with the ntpdc utility.#requestkey 8# Specify the key identifier to use with the ntpq utility.#controlkey 8# Enable writing of statistics records.#statistics clockstats cryptostats loopstats peerstats 启动NTP1/usr/local/ntp/bin/ntpd -c /etc/ntp.conf 增加启动脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#!/bin/sh# ntpd This shell script takes care of starting and stopping# ntpd (NTPv4 daemon).## chkconfig: - 58 74# description: ntpd is the NTPv4 daemon. \# The Network Time Protocol (NTP) is used to synchronize the time of \# a computer client or server to another server or reference time source, \# such as a radio or satellite receiver or modem.NTPD=/usr/local/bin/ntpdPIDFILE=/var/run/ntpd.pidUSER=ntpGROUP=ntpNTPD_OPTS=&quot;-g -u ntp:ntp -p $PIDFILE&quot;ntpd_start() &#123; if [ -r $PIDFILE ]; then echo &quot;ntpd seems to be already running under pid `cat $PIDFILE`.&quot; echo &quot;Delete $PIDFILE if this is not the case.&quot;; return 1; fi echo -n &quot;Starting NTP daemon... &quot; $NTPD $NTPD_OPTS # You can&apos;t always rely on the ntpd exit code, see Bug #2420 # case &quot;$?&quot; in # 0) echo &quot;OK!&quot; # return 0;; # *) echo &quot;FAILED!&quot; # return 1;; # esac sleep 1 if ps -Ao args|grep -q &quot;^$NTPD $NTPD_OPTS&quot;; then echo &quot;OK!&quot; return 0 else echo &quot;FAILED!&quot; [ -e $PIDFILE ] &amp;&amp; rm $PIDFILE return 1 fi&#125;ntpd_stop() &#123; if [ ! -r $PIDFILE ]; then echo &quot;ntpd doesn&apos;t seem to be running, cannot read the pid file.&quot; return 1; fi echo -n &quot;Stopping NTP daemon...&quot;; PID=`cat $PIDFILE` if kill -TERM $PID 2&gt; /dev/null;then # Give ntp 15 seconds to exit for i in `seq 1 15`; do if [ -n &quot;`ps -p $PID|grep -v PID`&quot; ]; then echo -n . sleep 1 else echo &quot; OK!&quot; rm $PIDFILE return 0 fi done fi echo &quot; FAILED! ntpd is still running&quot;; return 1&#125;ntpd_status() &#123; if [ -r $PIDFILE ]; then echo &quot;NTP daemon is running as `cat $PIDFILE`&quot; else echo &quot;NTP daemon is not running&quot; fi&#125;case &quot;$1&quot; in &apos;start&apos;) ntpd_start ;; &apos;stop&apos;) ntpd_stop ;; &apos;restart&apos;) ntpd_stop &amp;&amp; ntpd_start ;; &apos;status&apos;) ntpd_status ;; *) echo &quot;Usage: $0 (start|stop|restart|status)&quot;esac]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[初识inotify]]></title>
      <url>http://czero000.github.io/2015/12/21/inotify-command.html</url>
      <content type="text"><![CDATA[在工作中，人们往往需要知道在某些文件、目录上都有那些变化，比如： 通知配置文件的改变 追踪某些关键的系统文件变化 系统崩溃时进行自动清理 自动触发备份进程 向服务器上传文件结束时发出通知 通常使用文件轮询的通知机制，但是这种机制只适用经常改变的文件（因为它可以确保没过x秒就可以得到i/o），其他情况下都非常低效，并且有时候会丢失某些类型的变化，例如文件的修改时间没有改变。像Tripwire这样的数据完整性系统，他们基于时间调度来追踪文件变化，但是如果想实时监控文件的变化，那么时间调度就束手无策了，Inotify就这样应运而生了。 Inorify是什么 在日常的运维过程中，经常需要备份某些文件，或者对系统的某些文件进行监控，比如重大服务的配置文件。如果需要做到实时同步或是监控，就需要使用内核的inotify机制。Linux内核从2.6.13开始引入Inotify，现在几乎所有的主流Linux发行版都已经支持Inotify机制，Inotify是基于inode级别的文件系统监控技术，是一种强大的、细粒度的、异步的机制，他满足各种各样的文件监控需要，不仅限于安全和性能。Inotify不需要对监视的目标打开文件描述符，而且如果被监视目录在可移动介质上，那么在umount该介质的文件系统后，被监视目标的watch将被自动删除，并且会产生一个umount事件。 Inotify既可以监视文件，亦可以监视目录 Inotify使用系统调用而非Sigio来通知文件系统事件 Inotify使用文件描述符作为接口，因而可以使用通常的文件I/O操作select和poll来监视文件系统的变化 如何知道你的Linux内核是否支持Inotify机制呢，执行下面命令：12grep INOTIFY_USER /boot/config-$(uname -r)CONFIG_INOTIFY_USER=y 如果输出CONFIG_INOTIFY_USER=y，那么就可以享受Inotify之旅了。 安装inotify-tools软件下载地址官方地址：[http://github.com/rvoicilas/inotify-tools/wiki]([http://github.com/rvoicilas/inotify-tools/wiki) 下载安装软件包12345wget --no-check-certificate http://github.com/downloads/rvoicilas/inotify-tools/inotify-tools-3.14.tar.gztar -zxf inotify-tools-3.14.tar.gz cd inotify-tools-3.14./configure --prefix=/usr/local/inotifymake &amp;&amp; make install 使用InotifyInotify可监视的文件系统事件 IN_ACCESS： 即文件被访问 IN_MODIFY： 文件被write IN_ATTRIB： 文件属性被修改，如chmod、chown、touch等 IN_CLOSE_WRITE： 可以文件被close IN_CLOSE_NOWRITE： 不可写文件被close IN_OPEN： 文件被打开 IN_MOVED_FROM： 文件被移走，如mv IN_MOVED_TO： 文件被移来，如mv、cp IN_CREATE： 创建新文件 IN_DELETE： 文件被删除，如rm IN__DELETE_SELF： 自删除，挤一个可执行文件在执行时删除自己 IN_MOVE_SELF： 自移动，即一个可执行文件在执行时移动自己 IN_UNMOUNT： 宿主文件系统被umount IN_CLOSE： 文件被关闭，等同于（IN_CLOSE_WRITE|IN_CLOSE_NOWRITE） IN_MOVE： 文件被移动，等同于（IN_MOVED_FROM|IN_MOVED_TO） inotify的默认内核参数 /proc/sys/fs/inotify/max_queued_events 默认值：16384 该文件中的值为调用inotify_init时分配给inotify instatnce中可排队的event的数目最大值，超出这个值的时间被丢弃，但会触发IN_Q_OVERFLOW事件 /proc/sys/fs/inotify/max_user_instances 默认值：128 指定了每个read user ID可创建的inotify instatnces的数量上限 /proc/sys/fs/inotify/max_user_watches 默认值：8192 指定了每个inotify instance相关的watches的上限 PS：max_queued_events是Inotify管理的队列的最大长度，文件系统变化越频繁，这个值就应该越大如果在日志中看到Event Queue Overflow，说明max_queued_events大小需要调整参数后再次使用 使用incron实现重要配置文件监控incron是inotify的cron系统，与本身的cron一样，包含一个后台守护进程（incrond）和一个事件编辑器（incrontab）与系统本身的cron不同的仅仅是触发时间的是os对某个文件或者文件夹的操作而不再是时间，由于系统事件触发的机制，对于应用系统来说，几乎做到实时性。安装incron包1rpm -Uvh http://mirrors.sohu.com/fedora-epel/5Server/i386/incron-0.5.5-2.el5.i386.rpm 查看incron支持的事件类型：incrontab -t，编辑配置文件使用incrontab -e配置文件爱你格式说明：（默认配置在/var/spool/incron/ 目录下）1 选项说明： path ： 需要监控的文件和目录 event ： 系统对监控对象发生的事件，多个事件可以用逗号隔离， command ： command可以是系统命令，也可以是脚本，不能使用系统的重定向，除非重定向写在脚本中 command 还可以使用下面变量： $@ ：代表 ，即监控对象 $#： 发生系统时间的对象（如果监控的是某个文件夹，某个文件发生变化，那么$#就代表了该文件） $%： 代表 ，即发生的事件 event 监控事件如下： IN_ACCESS IN_MODIFY IN_ATTRIB IN_CLOSE_WRITE IN_CLOSE_NOWRITE IN_OPEN IN_MOVED_FROM IN_MOVED_TO IN_CREATE IN_DELETE IN_DELETE_SELF IN_CLOSE IN_MOVE IN_ONESHOT IN_ALL_EVENTS IN_DONT_FOLLOW ： IN_ONLYDIR ：只监控目录 IN_MOVE_SELF ：仅监控一次事件 配置举例：123incrontab -e/opt/test/a.txt IN_MODIFY echo &quot;$@ $#&quot; 表示文件a.txt一旦被修改，就执行echo &quot;$@ $#&quot;/opt/test/ IN_ALL_EVENTS echo &quot;$@ $# $%&quot; 表示目录下文件任何事件触发，就执行echo &quot;$@ $# $%&quot; 启动incrond123456789101112131415161718/etc/init.d/incrond start），然后在/opt/test/ 目录创建a.txt，并修改、删除，查看/var/log/cron，如下输出：Nov 10 18:12:28 ssq-54-100 incrond[11908]: stopping serviceNov 10 18:12:28 ssq-54-100 incrond[12072]: starting service (version 0.5.5, built on Oct 2 2009 12:18:20)Nov 10 18:12:28 ssq-54-100 incrond[12073]: loading system tablesNov 10 18:12:28 ssq-54-100 incrond[12073]: loading user tablesNov 10 18:12:28 ssq-54-100 incrond[12073]: loading table for user rootNov 10 18:12:28 ssq-54-100 incrond[12073]: ready to process filesystem eventsNov 10 18:12:41 ssq-54-100 incrond[12073]: (root) CMD (echo &quot;/opt/test IN_OPEN,IN_ISDIR&quot;)Nov 10 18:12:41 ssq-54-100 incrond[12073]: (root) CMD (echo &quot;/opt/test IN_CLOSE_NOWRITE,IN_ISDIR&quot;)Nov 10 18:12:41 ssq-54-100 incrond[12073]: (root) CMD (echo &quot;/opt/test/a.txt &quot;)Nov 10 18:12:41 ssq-54-100 incrond[12073]: (root) CMD (echo &quot;/opt/test a.txt IN_MODIFY&quot;)Nov 10 18:12:41 ssq-54-100 incrond[12073]: (root) CMD (echo &quot;/opt/test a.txt IN_OPEN&quot;)Nov 10 18:12:41 ssq-54-100 incrond[12073]: (root) CMD (echo &quot;/opt/test a.txt IN_MODIFY&quot;)Nov 10 18:12:41 ssq-54-100 incrond[12073]: (root) CMD (echo &quot;/opt/test/a.txt &quot;)Nov 10 18:12:41 ssq-54-100 incrond[12073]: (root) CMD (echo &quot;/opt/test a.txt IN_CLOSE_WRITE&quot;)Nov 10 18:12:45 ssq-54-100 incrond[12073]: (root) CMD (echo &quot;/opt/test IN_OPEN,IN_ISDIR&quot;)Nov 10 18:12:45 ssq-54-100 incrond[12073]: (root) CMD (echo &quot;/opt/test IN_CLOSE_NOWRITE,IN_ISDIR&quot;)Nov 10 18:12:53 ssq-54-100 incrond[12073]: (root) CMD (echo &quot;/opt/test a.txt IN_DELETE&quot;) 总体来说，文件和目录的监控还是很有效的 linux下使用inotify/usr/local/inotify/bin/inotifywait仅执行阻塞，等待inotify事件。可以监视任何一组文件和目录，或监控这个目录树（目录、子目录） 脚本示例：1234567891011121314#!/bin/bashinotifywait=&apos;/usr/local/inotify/bin/inotifywait&apos;$inotifywait -mrq --timefmt &apos;%y-%m-%d %H:%M&apos; --format &apos;%T %w%f %e&apos; --event modify,delete,create,attrib /opt/test | while read date time file event do case $event in MODIFY|CREATE|MOVE|MODIFY,ISDIR|CREATE,ISDIR|MODIFY,ISDIR) echo $event&apos;-&apos;$file ;; MOVED_FROM|MOVED_FROM,ISDIR|DELETE|DELETE,ISDIR) echo $event&apos;-&apos;$file ;; esacdone 执行脚本输出如下：touch test.txt、echo &quot;This is a test&quot; &gt; test.txt rm test.txt -f1234sh inotifywaith.sh CREATE-/opt/test/test.txtMODIFY-/opt/test/test.txtDELETE-/opt/test/test.txt inotifywait命令常用选项如下： –exclude 排除某些文件 –excludei 排除某些文件,并忽略大小写 -m|–monitor 持续行的监控 -q|-quiet 打印出监控事件 -d|–daemon -r|–recursive 递归监控指定目录下的所有文件，包括新建的文件或子目录；如果要监控的目录中文件数量巨大，则通常需要修改/proc/sys/fs/inotify/max_users_watchs内核参数 /usr/local/inotify/bin/inotifywatch收集关于被监视的文件系统的统计数据，包括每个inotify时间发生多少次假如想知道某个指定文件夹上有什么操作，可以这么做：12345678910111213#!/bin/bashinotifywatch=&apos;/usr/local/inotify/bin/inotifywatch&apos;$inotifywatch -v -e access,modify,attrib,close_write,close_nowrite,close,open,moved_to,moved_from,move,create,delete,delete_self -t 120 -r /opt/testsh inotifywatch.sh Establishing watches...Setting up watch(es) on /opt/testOK, /opt/test is now being watched.Total of 1 watches.Finished establishing watches, now collecting statistics.Will listen for events for 120 seconds.total modify attrib close_write close_nowrite open moved_from moved_to create delete filename19 2 1 2 4 6 1 1 1 1 /opt/test/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[rsync+inotify实现实时备份]]></title>
      <url>http://czero000.github.io/2015/12/21/rsync-inotify-backup.html</url>
      <content type="text"><![CDATA[rsync的优点和缺点 与传统的cp、tar备份方式相比，rsync具有安全性高、备份迅速、支持赠礼备份等优点，通过rsync可以解决实时性能不高的数据备份需求，例如定期的备份文件到异地服务器，对本地磁盘做数据镜像等。 随着对数据安全性和可靠性的更高要求，rsync也逐渐暴露出不足。首先rsync同步数据时，需要扫描所有文件后进行比对，进行差量传输。如果数据达到百万或者是千万的量级，扫描文件将耗费大量事件，而发生变化的往往是其中极少的一部分，这是非常低效的方式，其次rsync不能实时去监测、同步数据，虽然可以通过守护进程方式或者是crontab等方式进行触发，但是动作会有一定的时间差，这会导致两地数据可能会出现不一致，无法保证数据或者应用的安全性。 inotify简介 Inotify 是一种强大的、细粒度的、异步的文件系统事件监控机制，linux内核从2.6.13起，加入了Inotify支持，通过Inotify可以监控文件系统中添加、删除，修改、移动等各种细微事件，利用这个内核接口，第三方软件就可以监控文件系统下文件的各种变化情况，而inotify-tools就是这样的一个第三方软件。rsync可以实现触发式的文件同步，但是通过crontab守护进程方式进行触发，同步的数据和实际数据会有差异，而inotify可以监控文件系统的各种变化，当文件有任何变动时，就触发rsync同步，这样刚好解决了同步数据的实时性问题。 安装inotfiy工具inotifytools 由于inotofy需要Linux内核的支持，在安装inotify-tools前要先确认系统内核师傅支持，如果Linux内核低于2.6.13版本，就需要重启编译内核加入inotify的支持，如何知道你的Linux内核是否支持Inotify机制呢，执行下面命令：123grep INOTIFY_USER /boot/config-$(uname -r)CONFIG_INOTIFY_USER=y如果输出“CONFIG_INOTIFY_USER=y”，那么就可以享受Inotify之旅了。 软件下载地址官方地址：http://github.com/rvoicilas/inotify-tools/wiki 下载安装软件包12345wget --no-check-certificate http://github.com/downloads/rvoicilas/inotify-tools/inotify-tools-3.14.tar.gztar -zxf inotify-tools-3.14.tar.gz cd inotify-tools-3.14./configure --prefix=/usr/local/inotifymake &amp;&amp; make install 配置rsync、inotify系统环境CentOS_5.4_i386更新服务器：172.16.6.100目标服务器：172.16.6.98 配置目标服务器检查rsync是否安装如果没有安装可以源码安装或者yum -y install rsync，rsync3.0相对与2.0有很多的改进，3.0是边对边边同步，2.0是完全对比之后在同步。12rpm -qa rsyncrsync-2.6.8-3.1 定义rsync配置文件/etc/rsyncd.conf123456789101112131415161718cat &gt;&gt; /etc/rsyncd.conf &lt;uid=nobody gid=nobodyuse chroot = no max connections = 100timeout = 600pid file = /var/run/rsyncd.pidlock file = /var/run/rsyncd.locklog file = /var/log/rsyncd.logsecrets file = /etc/rsyncd.passwdhosts allow = 172.16.6.100[website]path = /data/website/comment = Web Siteread only = noignore errorslist = noauth users = websiteEOF 配置rsync密码文件，修改密码文件权限，是其他用户无权查看1234cat &gt;&gt; /etc/rsyncd.passwd &lt;&lt; EOFwebsite:websiteEOFchmod 600 /etc/rsyncd.passwd 启动服务12345/usr/bin/rsync --daemon --config=/etc/rsyncd.conf lsof -i:873COMMAND PID USER FD TYPE DEVICE SIZE NODE NAMErsync 25469 root 3u IPv6 1038838496 TCP *:rsync (LISTEN)rsync 25469 root 5u IPv4 1038838497 TCP *:rsync (LISTEN) 客户端测试，同步代码123rsync -vzrtopg --progress website@172.16.6.98::website --password-file=/etc/rsync.passwd /data/website/sent 26731 bytes received 6831971 bytes 4572468.00 bytes/sectotal size is 19027624 speedup is 2.77 同步脚本1234567891011121314#!/bin/bashinotifywait=&apos;/usr/local/inotify/bin/inotifywait&apos;LOCAL=172.16.6.98SRC=/data/website/USER=websiteCOMMAND=/usr/bin/rsync Option=&quot;-vzrtopg --progress --delete&quot; Module=websitePASSFILE=/etc/rsync.passwd$inotifywait -mrq --timefmt &apos;%y-%m-%d %H:%M&apos; --format &apos;%T %w%f %e&apos; --event modify,delete,create,attrib $SRC | while read date time filesdo $COMMAND $Option --password-file=$PASSFILE $SRC $USER@$LOCAL::$Module echo &quot;$files was rsyncd&quot; &gt;&gt; /var/log/rsync.log 2&gt;&amp;1done 把脚本使用nohup放入后台执行nohup ./rsync.sh &amp;这样将更新的文件提交到更新源服务器上，就可以通过Inotify和rsync的配合批量的将更新文件同步到所有服务器中。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Openssl升级]]></title>
      <url>http://czero000.github.io/2015/12/21/update-openssl.html</url>
      <content type="text"><![CDATA[查看当前版本信息12openssl versionOpenSSL 0.9.8e-fips-rhel5 01 Jul 2008 安装新版本openssl123456789[root@Charlie ~]# wget http://www.openssl.org/source/openssl-1.0.1g.tar.gz -O /usr/local/src/openssl-1.0.1g.tar.gz[root@Charlie ~]# cd /usr/local/src/[root@Charlie src]# cd openssl-1.0.1g[root@Charlie openssl-1.0.1g]# ./config shared zlib[root@Charlie openssl-1.0.1g]# make &amp;&amp; make install[root@Charlie openssl-1.0.1g]# mv /usr/bin/openssl /usr/bin/openssl.bak[root@Charlie openssl-1.0.1g]# mv /usr/include/openssl /usr/include/openssl.bak[root@Charlie openssl-1.0.1g]# ln -s /usr/local/ssl/bin/openssl /usr/bin/openssl[root@Charlie openssl-1.0.1g]# ln -s /usr/local/ssl/include/openssl /usr/include/openssl 配置库文件搜索路径12[root@Charlie openssl-1.0.1g]# echo &quot;/usr/local/ssl/lib&quot; &gt;&gt; /etc/ld.so.conf[root@Charlie openssl-1.0.1g]# ldconfig -v 验证升级1234567[root@Charlie openssl-1.0.1g]# openssl version -aOpenSSL 1.0.1g 7 Apr 2014built on: Tue Apr 15 15:47:31 CST 2014platform: linux-elfoptions: bn(64,32) rc4(8x,mmx) des(ptr,risc1,16,long) idea(int) blowfish(idx)compiler: gcc -fPIC -DOPENSSL_PIC -DZLIB -DOPENSSL_THREADS -D_REENTRANT -DDSO_DLFCN -DHAVE_DLFCN_H -Wa,--noexecstack -DL_ENDIAN -DTERMIO -O3 -fomit-frame-pointer -Wall -DOPENSSL_BN_ASM_PART_WORDS -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DMD5_ASM -DRMD160_ASM -DAES_ASM -DVPAES_ASM -DWHIRLPOOL_ASM -DGHASH_ASMOPENSSLDIR: &quot;/usr/local/ssl&quot; 在升级了openssl后，我们还要升级一下SSH12[root@Charlie openssl-1.0.1g]# ssh -VOpenSSH_4.3p2, OpenSSL 0.9.8e-fips-rhel5 01 Jul 2008 安装openssh1234567[root@Charlie src]# wget http://ftp.jaist.ac.jp/pub/OpenBSD/OpenSSH/portable/openssh-6.6p1.tar.gz[root@Charlie src]# tar -zxf openssh-6.6p1.tar.gz[root@Charlie src]# cd openssh-6.6p1[root@Charlie openssh-6.6p1]# ./configure --prefix=/usr --sysconfdir=/etc/ssh --with-zlib --with-pam --with-ssl-dir=/usr/local/ssl --with-md5-passwords --mandir=/usr/share/man[root@Charlie openssh-6.6p1]# make &amp;&amp; make install [root@Charlie openssh-6.6p1]# ssh -VOpenSSH_6.6p1, OpenSSL 1.0.1g 7 Apr 2014 TroubleShooting报错：configure: error: PAM headers not found解决：yum install -y pam-devel]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Megacli命令指南]]></title>
      <url>http://czero000.github.io/2015/12/21/introduce-megacli-command.html</url>
      <content type="text"><![CDATA[MegaCli 是一款管理维护硬件RAID软件，可以通过它来了解当前 raid 卡的所有信息，包括 raid卡的型号，raid 的阵列类型，raid 上各磁盘状态，等等。通常，我们对硬盘当前的状态不太好确定，一般通过机房人员巡检来完成，有没有通过软件的方式来检查确定这个问题呢。MegaCli就可以做到，一般通过 MegaCli 的 Media Error Count: 1 Other Error Count: 0 这两个数值来确定阵列中磁盘是否有问题；Medai Error Count 表示磁盘可能错误，可能是磁盘有坏道，这个值不为0值得注意，数值越大，危险系数越高，Other Error Count 表示磁盘可能存在松动，可能需要重新再插入。MegaCli 可以对阵列中所有的磁盘进行检测，我们可以通过脚本的方式来检测相关参数，从而通知管理人员。 下载 MegCli,目前针对公司DB数据库是IBM的服务器，直接从IBM官方下载，如果其它服务器的，使用各官方下载或者 LSI 网站上进行相关下载。一般来说，是通用的。这个包适用 32 /64 位操作系统平台 下载地址：ftp://download2.boulder.ibm.com/ecc/sar/CMA/XSA/ibm_utl_sraidmr_megacli-8.00.48_linux_32-64.zip 安装123unzip ibm_utl_sraidmr_megacli-8.00.48_linux_32-64.zipcd linuxrpm -ivh Lib_Utils-1.00-09.noarch.rpm MegaCli-8.00.48-1.i386.rpm 使用命令及参数常用命令使用12345678910111213141516171819202122/opt/MegaRAID/MegaCli/MegaCli64 -LDInfo -Lall -aALL [查raid级别]/opt/MegaRAID/MegaCli/MegaCli64 -AdpAllInfo -aALL [查raid卡信息]/opt/MegaRAID/MegaCli/MegaCli64 -PDList -aALL [查看硬盘信息]/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -aAll [查看电池信息]/opt/MegaRAID/MegaCli/MegaCli64 -FwTermLog -Dsply -aALL [查看raid卡日志]/opt/MegaRAID/MegaCli/MegaCli64 -adpCount [显示适配器个数]/opt/MegaRAID/MegaCli/MegaCli64 -AdpGetTime –aALL [显示适配器时间]/opt/MegaRAID/MegaCli/MegaCli64 -AdpAllInfo -aAll [显示所有适配器信息]/opt/MegaRAID/MegaCli/MegaCli64 -LDInfo -LALL -aAll [显示所有逻辑磁盘组信息]/opt/MegaRAID/MegaCli/MegaCli64 -PDList -aAll [显示所有的物理信息]、/opt/MegaRAID/MegaCli/MegaCli64 -PdLocate -start -physdrv[252:2] -a0 [点亮指定硬盘（定位）]/opt/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Clear -a0 [清除Foreign状态]/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuStatus -aALL |grep &apos;ChargerStatus&apos; [查看充电状态]/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuStatus -aALL[显示BBU状态信息]/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuCapacityInfo -aALL[显示BBU容量信息]/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuDesignInfo -aALL [显示BBU设计参数]/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuProperties -aALL [显示当前BBU属性]/opt/MegaRAID/MegaCli/MegaCli64 -cfgdsply -aALL [显示Raid卡型号，Raid设置，Disk相关信息]/opt/MegaRAID/MegaCli/MegaCli64 -PDList -aAll -NoLog [查看所有硬盘的状态]/opt/MegaRAID/MegaCli/MegaCli64 -LdPdInfo -aAll -NoLog [查看所有Virtual Disk的状态] 磁带状态的变化，从拔盘，到插盘的过程中。123Device |Normal|Damage|Rebuild|NormalVirtual Drive |Optimal|Degraded|Degraded|OptimalPhysical Drive |Online|Failed –&gt; Unconfigured|Rebuild|Online 查看磁盘缓存策略12345/opt/MegaRAID/MegaCli/MegaCli64 -LDGetProp -Cache -L0 -a0/opt/MegaRAID/MegaCli/MegaCli64 -LDGetProp -Cache -L1 -a0/opt/MegaRAID/MegaCli/MegaCli64 -LDGetProp -Cache -LALL -a0/opt/MegaRAID/MegaCli/MegaCli64 -LDGetProp -Cache -LALL -aALL/opt/MegaRAID/MegaCli/MegaCli64 -LDGetProp -DskCache -LALL -aALL 设置磁盘缓存策略缓存策略解释 WT (Write through WB (Write back) NORA (No read ahead) RA (Read ahead) ADRA (Adaptive read ahead) Cached Direct 123/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp WT|WB|NORA|RA|ADRA -L0 -a0/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp -Cached|-Direct -L0 -a0 enable / disable disk cache/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp -EnDskCache|-DisDskCache -L0 -a0 Raid 管理RAID Level对应关系 Raid信息 Raid级别 RAID Level : Primary-1, Secondary-0, RAID Level Qualifier-0 RAID 1 RAID Level : Primary-0, Secondary-0, RAID Level Qualifier-0 RAID 0 RAID Level : Primary-5, Secondary-0, RAID Level Qualifier-3 RAID 5 RAID Level : Primary-1, Secondary-3, RAID Level Qualifier-0 RAID 10 创建一个 raid5 阵列，由物理盘 2,3,4 构成，该阵列的热备盘是物理盘 51/opt/MegaRAID/MegaCli/MegaCli64 -CfgLdAdd -r5 [1:2,1:3,1:4] WB Direct -Hsp[1:5] -a0 创建阵列，不指定热备1/opt/MegaRAID/MegaCli/MegaCli64 -CfgLdAdd -r5 [1:2,1:3,1:4] WB Direct -a0 查看RAID阵列中掉线的盘1/opt/MegaRAID/MegaCli/MegaCli64 -pdgetmissing -a0 删除阵列1/opt/MegaRAID/MegaCli/MegaCli64 -CfgLdDel -L1 -a0 替换坏掉的模块1/opt/MegaRAID/MegaCli/MegaCli64 -pdreplacemissing -physdrv[12:10] -Array5 -row0 -a0 在线添加磁盘1/opt/MegaRAID/MegaCli/MegaCli64 -LDRecon -Start -r5 -Add -PhysDrv[1:4] -L1 -a0 阵列创建完后，会有一个初始化同步块的过程，可以看看其进度。12/opt/MegaRAID/MegaCli/MegaCli64 -LDInit -ShowProg -LALL -aALL 或者以动态可视化文字界面显示/opt/MegaRAID/MegaCli/MegaCli64 -LDInit -ProgDsply -LALL -aALL 查看阵列后台初始化进度1/opt/MegaRAID/MegaCli/MegaCli64 -LDBI -ShowProg -LALL -aALL 或者以动态可视化文字界面显示1/opt/MegaRAID/MegaCli/MegaCli64 -LDBI -ProgDsply -LALL -aALL 指定第 5 块盘作为全局热备1/opt/MegaRAID/MegaCli/MegaCli64 -PDHSP -Set [-EnclAffinity] [-nonRevertible] -PhysDrv[1:5] -a0 指定为某个阵列的专用热备1/opt/MegaRAID/MegaCli/MegaCli64 -PDHSP -Set [-Dedicated [-Array1]] [-EnclAffinity] [-nonRevertible] -PhysDrv[1:5] -a0 删除全局热备1/opt/MegaRAID/MegaCli/MegaCli64 -PDHSP -Rmv -PhysDrv[1:5] -a0 将某块物理盘下线/上线12/opt/MegaRAID/MegaCli/MegaCli64 -PDOffline -PhysDrv [1:4] -a0/opt/MegaRAID/MegaCli/MegaCli64 -PDOnline -PhysDrv [1:4] -a0 手动开启 rebuid1/opt/MegaRAID/MegaCli/MegaCli64 -pdrbld -start -physdrv[12:10] -a0 关闭 rebuild1/opt/MegaRAID/MegaCli/MegaCli64 -AdpAutoRbld -Dsbl -a0 设置rebuild的速率1/opt/MegaRAID/MegaCli/MegaCli64 -AdpSetProp RebuildRate -30 -a0 查看物理磁盘重建进度 Rebuild1/opt/MegaRAID/MegaCli/MegaCli64 -PDRbld -ShowProg -PhysDrv [1:5] -a0 或者以动态可视化文字界面显示1/opt/MegaRAID/MegaCli/MegaCli64 -PDRbld -ProgDsply -PhysDrv [1:5] -a0 查看 ES1/opt/MegaRAID/MegaCli/MegaCli64 -PDList -aAll -NoLog | grep -Ei &quot;(enclosure|slot)&quot; raid 电池设置相关查看电池状态信息(Display BBU Status Information) 12MegaCli -AdpBbuCmd -GetBbuStatus -aN|-a0,1,2|-aALLMegaCli -AdpBbuCmd -GetBbuStatus -aALL 查看电池容量（Display BBU Capacity Information） 12MegaCli -AdpBbuCmd -GetBbuCapacityInfo -aN|-a0,1,2|-aALLMegaCli -AdpBbuCmd -GetBbuCapacityInfo –aALL 查看电池设计参数(Display BBU Design Parameters) 12MegaCli -AdpBbuCmd -GetBbuDesignInfo -aN|-a0,1,2|-aALLMegaCli -AdpBbuCmd -GetBbuDesignInfo –aALL 查看电池属性（Display Current BBU Properties） 12MegaCli -AdpBbuCmd -GetBbuProperties -aN|-a0,1,2|-aALLMegaCli -AdpBbuCmd -GetBbuProperties –aALL 设置电池为学习模式为循环模式（Start BBU Learning Cycle） 123Description Starts the learning cycle on the BBU.No parameter is needed for this option.MegaCli -AdpBbuCmd -BbuLearn -aN|-a0,1,2|-aALL 设置磁盘的缓存模式和访问方式 （Change Virtual Disk Cache and Access Parameters） 12345678910111213Description Allows you to change the following virtual disk parameters:-WT (Write through), WB (Write back): Selects write policy.-NORA (No read ahead), RA (Read ahead), ADRA (Adaptive read ahead): Selects read policy.-Cached, -Direct: Selects cache policy.-RW, -RO, Blocked: Selects access policy.-EnDskCache: Enables disk cache.-DisDskCache: Disables disk cache.MegaCli -LDSetProp &#123; WT | WB|NORA |RA | ADRA|-Cached|Direct&#125; |&#123;-RW|RO|Blocked&#125; |&#123;-Name[string]&#125; |&#123;-EnDskCache|DisDskCache&#125; –Lx |-L0,1,2|-Lall -aN|-a0,1,2|-aALLMegaCli -LDSetProp WT -L0 -a0 显示磁盘缓存和访问方式（Display Virtual Disk Cache and Access Parameters） 12345678MegaCli -LDGetProp -Cache | -Access | -Name | -DskCache -Lx|-L0,1,2|-Lall -aN|-a0,1,2|-aALLDisplays the cache and access policies of the virtual disk(s):-WT (Write through), WB (Write back): Selects write policy.-NORA (No read ahead), RA (Read ahead), ADRA (Adaptive read ahead): Selects read policy.-Cache, -Cached, Direct: Displays cache policy.-Access, -RW, -RO, Blocked: Displays access policy.-DskCache: Displays physical disk cache policy. Megaraid 必知必会 使用 LSI 的 megaraid 可以对 raid 进行有效监控。别的厂商比如 HP,IBM 也有自己的 raid API 1234567MegaCli -ldinfo -lall -aall 查询raid级别，磁盘数量，容量，条带大小。MegaCli -cfgdsply -aALL |grep Policy 查询控制器cache策略MegaCli -LDSetProp WB -L0 -a0 设置write back功能MegaCli -LDSetProp CachedBadBBU -L0 -a0 设置即使电池坏了还是保持WB功能MegaCli -AdpBbuCmd -BbuLearn a0 手动充电MegaCli -FwTermLog -Dsply -aALL 查询日志MegaCli -adpCount 显示适配器个数 显示所有适配器信息 123MegaCli -AdpAllInfo -aAllCritical Disks : 0Failed Disks : 0 显示所有逻辑磁盘组信息 1MegaCli -LDInfo -LALL -aAll 显示所有的物理信息 123MegaCli -PDList -aAllMedia Error Count: 0Other Error Count: 0 查看充电状态 123MegaCli -AdpBbuCmd -GetBbuStatus -aALLLearn Cycle Requested : NoFully Charged : Yes 显示BBU(后备电池)状态信息： MegaCli -AdpBbuCmd -GetBbuStatus -aALL显示BBU容量信息： MegaCli -AdpBbuCmd -GetBbuCapacityInfo -aALL显示BBU设计参数： MegaCli -AdpBbuCmd -GetBbuDesignInfo -aALL显示当前BBU属性： MegaCli -AdpBbuCmd -GetBbuProperties -aALL显示Raid卡型号，Raid设置，Disk相关信息： MegaCli -cfgdsply -aALL查看Cache 策略设置： MegaCli -cfgdsply -aALL |grep -i Policy Current Cache Policy: WriteBack, ReadAheadNone, Direct, Write Cache OK if Bad BBU查看充电进度百分比： MegaCli -AdpBbuCmd -GetBbuStatus -aALL 通过脚本检测RAID 磁盘状态Linux下脚本1234567891011121314151617#!/bin/bash#check raid disk statusMEGACLI=&quot;/opt/MegaRAID/MegaCli/MegaCli64 &quot;$MEGACLI -pdlist -aALL | grep &quot;Firmware state&quot; | awk -F : &apos;&#123;print $2&#125;&apos; | awk -F , &apos;&#123;print $1&#125;&apos; &gt;/tmp/fireware.log$MEGACLI -pdlist -aALL | grep -E &quot;Media Error|Other Error&quot; | awk -F : &apos;&#123;print $2&#125;&apos; &gt;/tmp/disk.logfor i in `cat doif [ $i -ne 0 ] thencurl &quot;http://xxxxxxB&amp;state=ALARM&amp;description=raid_disk_error&quot;fidonefor i in `cat doif [ $i != Online ] thencurl &quot;http://xxxxxxstate=ALARM&amp;description=raid_disk_offline&quot;fidone Windows 下脚本Windows下脚本用的工具是gnu for windows平台的一些软件，如 bash grep awk cat通过bash直接调用脚本如：G:\raid_check\unixtools&gt;bash.exe G:\disk.sh 123456789101112131415161718192021#check raid disk statusMEGACLI=&quot;//G/raid_check/MegaCli.exe&quot;GREP=&quot;//G/raid_check/unixtools/grep.exe&quot;AWK=&quot;//G/raid_check/unixtools/awk.exe&quot;CAT=&quot;//G/raid_check/unixtools/cat.exe&quot;CURL=&quot;//G/raid_check/unixtools/curl.exe&quot;$MEGACLI -pdlist -aALL | $GREP &quot;Firmware state&quot; |$AWK -F: &apos;&#123;print $2&#125;&apos; |$AWK -F , &apos;&#123;print $1&#125;&apos; &gt;//c/fireware.log$MEGACLI -pdlist -aALL | $GREP -E &quot;Media Error|Other Error&quot; | $AWK -F : &apos;&#123;print $2&#125;&apos; &gt; //c/disk.logfor i in `$CAT c:/disk.log`doif [ $i -ne 0 ] then$CURL &quot;http://xxxxxx&amp;description=raid_disk_error&quot;fidonefor i in `$CAT c:/fireware.log`doif [ $i != Online ] then$CURL &quot;http://xxxxx&amp;state=ALARM&amp;description=raid_disk_offline&quot;fi]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[passwd修改密码失败]]></title>
      <url>http://czero000.github.io/2015/12/21/passwd-command-failed.html</url>
      <content type="text"><![CDATA[问题今天增加一用户时，出现以下情况12345[root@ssq-54-104 ~]# passwd rootChanging password for user root.New UNIX password:/usr/share/cracklib/pw_dict: error reading headerPWOpen: Success 解决方法1yum reinstall -y cracklib-dicts CrackLib是一个可用于类UNIX系统下的函数库, 一般来说, 通常只使用其中的一个函数.它可以用于编写和passwd有关的程序中, 其基本思想是很简单的, 就是防止用户使用过于简单, 容易被猜测出来或容易被一些工具搜索到的密码.CrackLib并不是一个可以直接运行使用的程序, 它是一个函数库, 你可以利用其中的函数写自己的程序, 或是加入其它程序中, 用来提高安全性. 比如, 你可以重写passwd,使用户在选择密码时受到限制CrackLib使用一个字典, 它查找字典以判断所选用密码是否是不安全的密码, 所以你也可以加入其它信息, 使用自己的字典.比如, 加入公司的名称, 实验室墙上的单词等等潜在的不安全密码.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python2.4升级]]></title>
      <url>http://czero000.github.io/2015/12/21/update-python.html</url>
      <content type="text"><![CDATA[RHEL5.4系统中自带的Python版本是2.4，但是目前许多基于Python的应用要求的Python版本都要高于2.4，在升级Python版本时不要卸载Python2.4在安装Python2.7，这样会有很多的问题，保守的方法是直接安装Python2.7的源码包（系统中有很多程序依赖Python） 系统版本123456lsb_release -aLSB Version: :core-3.1-ia32:core-3.1-noarch:graphics-3.1-ia32:graphics-3.1-noarchDistributor ID: RedHatEnterpriseServerDescription: Red Hat Enterprise Linux Server release 5.4 (Tikanga)Release: 5.4Codename: Tikanga Python版本12python -VPython 2.4.3 下载并安装Python2.7123456cd /usr/local/srcwget www.python.org/ftp/python/2.7.2/Python-2.7.2.tar.bz2tar -jxf Python-2.7.2.tar.bz2 cd Python-2.7.2./configuremake &amp;&amp; make install Python2.7安装后路径默认是/usr/local/lib/python2.7，查看Python版本 12/usr/local/bin/python2.7 -VPython 2.7.2 建立软连接，使系统默认的Python指向Python2.7正常情况下，即使Python2.7安装成功后，系统默认的Python版本仍然是2.412python -VPython 2.4.3 将系统默认的Python指到2.712mv /usr/bin/python /usr/bin/python.bakln -s /usr/local/bin/python2.7 /usr/bin/python 测试是否成功12python -VPython 2.7.2 yum工具是基于Python2.4才能运行12edit /usr/bin/yum#!/usr/bin/python =&gt; #!/usr/bin/python2.4 这样yum工具就可以正常使]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS6.5安装VNC]]></title>
      <url>http://czero000.github.io/2015/12/21/centos6.5-install-vncserver.html</url>
      <content type="text"><![CDATA[安装图形支持1yum groupinstall -y &apos;X Window System&apos; &apos;Desktop&apos; &apos;Desktop Platform&apos; 安装VNC1yum install -y tigervnc-server 配置VNC编辑vnc服务配置文件123vim /etc/sysconfig/vncserversVNCSERVERS=&quot;1:root&quot;VNCSERVERARGS[1]=&quot;-geometry 1024x768 -nolisten tcp &quot; 配置vnc密码1vncpasswd 启动vnc服务12345678910/etc/init.d/vncserver startStarting VNC server: 1:root xauth: creating new authority file /root/.XauthorityNew &apos;localhost.localdomain:1 (root)&apos; desktop is localhost.localdomain:1Creating default startup script /root/.vnc/xstartupStarting applications specified in /root/.vnc/xstartupLog file is /root/.vnc/localhost.localdomain:1.log [ OK ] 设置vnc自动启动1chkconfig vncserver on 注：~/.vnc/xstartup在CentOS 6下无需增加gnome-session &amp; 多用户设置123456789101112\\ vnc配置文件vim /etc/sysconfig/vncserversVNCSERVERS=”1:userA 2:userB”VNCSERVERARGS[1]=&quot;-geometry 1024x768 -nolisten tcp &quot;VNCSERVERARGS[2]=&quot;-geometry 1024x768 -nolisten tcp &quot;\\ vnc密码su - userAvncpasswdsu - userBvncpasswd 实用命令1234567891011121314usage: vncserver [:] [-name ] [-depth ] [-geometry x] [-pixelformat rgbNNN|bgrNNN] [-fp ] [-fg] ... vncserver -kill vncserver -listvncserver[:n] \\开启服务vncserver -list \\查看运行列表vncserver -kill :n \\杀掉第几个x-displayvncpasswd \\修改密码]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[NFS详解]]></title>
      <url>http://czero000.github.io/2015/12/21/nfs-detail.html</url>
      <content type="text"><![CDATA[NFS服务简介NFS简介 NFS 是Network File System的缩写，即网络文件系统。一种使用于分散式文件系统的协议，由Sun公司开发，于1984年向外公布。功能是通过网络让不同的机器、不同的操作系统能够彼此分享彼此的数据，让应用程序在客户端通过网络访问位于服务器磁盘中的数据，是在类Unix系统间实现磁盘文件共享的一种方法。 NFS 的基本原则是“允许不同的客户端及服务端通过一组RPC分享相同的文件系统”，它是独立于操作系统，允许不同硬件及操作系统的系统共同进行文件的分享。 NFS在文件传送或信息传送过程中依赖于RPC协议。RPC，远程过程调用 (Remote Procedure Call) 是能使客户端执行其他系统中程序的一种机制。NFS本身是没有提供信息传输的协议和功能的，但NFS却能让我们通过网络进行资料的分享，这是因为NFS使用了一些其它的传输协议。而这些传输协议用到这个RPC功能的。可以说NFS本身就是使用RPC的一个程序。或者说NFS也是一个RPC SERVER。所以只要用到 NFS的地方都要启动RPC服务，不论是NFS SERVER或者NFS CLIENT。这样SERVER和CLIENT才能通过RPC来实现PROGRAM PORT的对应。可以这么理解RPC和NFS的关系：NFS是一个文件系统，而RPC是负责负责信息的传输。 NFS协议从诞生到现在为止，已经有多个版本，如NFS V2（rfc1094）,NFS V3（rfc1813）（最新的版本是V4（rfc3010）。 各NFS协议版本的主要区别V3相对V2的主要区别： 文件尺寸 V2最大只支持32BIT的文件大小(4G),而NFS V3新增加了支持64BIT文件大小的技术。 文件传输尺寸 V3没有限定传输尺寸，V2最多只能设定为8k，可以使用-rsize and -wsize 来进行设定。 完整的信息返回 V3增加和完善了许多错误和成功信息的返回，对于服务器的设置和管理能带来很大好处。 增加了对TCP传输协议的支持 V2只提供了对UDP协议的支持，在一些高要求的网络环境中有很大限制，V3增加了对TCP协议的支持 异步写入特性 改进了SERVER的mount性能 有更好的I/O WRITES 性能。 更强网络运行效能，使得网络运作更为有效 更强的灾难恢复功能。 异步写入特性（v3新增加）介绍： NFS V3 能否使用异步写入，这是可选择的一种特性。NFS V3客户端发发送一个异步写入请求到服务器，在给客户端答复之前服务器并不是必须要将数据写入到存储器中（稳定的）。服务器能确定何时去写入数据或者将多个写入请求聚合到一起并加以处理，然后写入。客户端能保持一个数据的copy以防万一服务器不能完整的将数据写入。当客户端希望释放这个copy的时候，它会向服务器通过这个操作过程，以确保每个操作步骤的完整。异步写入能够使服务器去确定最好的同步数据的策略。使数据能尽可能的同步的提交何到达。与V2比较来看，这样的机制能更好的实现数据缓冲和更多的平行（平衡）。而NFS V2的SERVER在将数据写入存储器之前不能再相应任何的写入请求。 V4相对V3的改进： 改进了INTERNET上的存取和执行效能 在协议中增强了安全方面的特性 增强的跨平台特性 安装部署NFS系统环境系统平台：Red Hat Enterprise Linux Server release 5.4 (Tikanga)12NFS Server IP：172.16.7.56NFS Client IP：172.16.7.57 安装NFS服务 NFS服务的安装非常简单，只需要两个软件包即可，在通常情况下，作为系统的默认软件包安装。 nfs-utils-* :包括基本的NFS命令与监控程序 portmap-* ：支持安全NFS RPC服务的连接 查看系统是否安装NFS1234rpm -qa nfs-utils nfs-utils-1.0.9-42.el5rpm -qa portmap portmap-4.0-65.2.2.1 系统已经默认安装了nfs-utils、portmap 两个软件包，如果没有安装，可以通过rpm和yum命令安装 NFS系统守护进程 RPC（Remote Procedure Call） NFS本身是没有提供信息传输的协议和功能的，但NFS却能让我们通过网络进行资料的分享，这是因为NFS使用了一些其它的传输协议。而这些传输协议勇士用到这个RPC功能的。可以说NFS本身就是使用RPC的一个程序。或者说NFS也是一个RPC SERVER.所以只要用到NFS的地方都要启动RPC服务，不论是NFS SERVER或者NFS CLIENT。这样SERVER和CLIENT才能通过RPC来实现PROGRAM PORT的对应。可以这么理解RPC和NFS的关系：NFS是一个文件系统，而RPC是负责负责信息的传输。 NFS需要启动的Daemons： pc.nfsd: 基本的NFS守护进程，主要负责Clinet登录权限检查。 rpm.mountd: RPC安装守护进程，负责NFS的文件系统，当Client端通过rpc.nfsd登录NFS Server后，对Client存取Server的文件前，还必须通过文件使用权限的验证，他会读取NFS的配置文件/etc/exports来对比Client权限。 NFS Server 在Red Hat平台下需要两个NFS Daemons套件 nfs-utils： 提供rpc.nfsd及rpc.mountd这两个NFS Daemons的套件 portmap： NFS其实可以看作一个RPC Server Program，主要功能是进行端口映射。当Client尝试连接并使用RPC服务提供的服务（NFS）时，portmap会将所管理的服务对应的端口提供给客户点，从而是Client可以通过该端口请求服务。 配置NFS服务NFS服务的配置相对简单，只需要在对应文件中进行配置，然后启动NFS服务即可。NFS常用文件： /etc/exports NFS服务的主要配置文件 /usr/sbin/exportfs NFS服务的管理命令 /usr/sbin/showmount 客户端的查看命令 /var/lib/nfs/etab 记录NFS分享出来的目录的完整权限设定值 /var/lib/nfs/xtab 记录曾经登录过的Clinent 信息 NFS服务的配置文件是/ext/exports，这个文件是NFS的主要配置文件，不过系统并没有默认值，所以这个文件不一定存在，可能要自己手动创建，写入相应配置内容。 /etc/exports文件内容格式： [客户端1 选项（访问权限,用户映射,其他）] [客户端2 选项（访问权限,用户映射,其他）] 输出目录： 输出目录是指NFS系统中需要共享给客户端使用的目录 客户端： 客户端是指网络中可以访问这个NFS Server的主机，客户端常用的指定方式如下： 指定IP地址：172.16.7.57 指定子网中的主机：172.16.7.0/24 指定域名的主机：ssq-54-57.zerounix.com 指定域中的所有主机：*.zerounix.com 所有主机：* 选项： 选项用来设置输出目录的访问权限、用户映射等。NFS主要有3类选项： 访问权限选项： 设置输出目录只读：ro 设置输出目录读写：rw 用户映射选项： all_squash： 将远程访问的所有普通用户及属组都映射为匿名用户或用户组(nfsnobody)； no_all_squash： 与all_squash相反（default）； root_squash： 将root用户及属组都映射问匿名用户或用户组（default）； no_root_squash： anonuid=xxx： 将远程访问的所有用户都映射为匿名用户，并指定用户问本地用户（UID=xxx）； anongid=xxx： 将远程访问的所有用户都映射为匿名用户组，并指定用户问本地用户组（GID=xxx）； 其他选项： secure： 限制客户端只能从小于1024的tcp端口连接NFS Server（default）； insecure： 允许客户端从大于1024的tcp端口连接NFS Server； sync： 将数据同步下乳内存缓冲区与磁盘中，效率低，但是可以保证数据的一致性； async： 将数据先保存在内存缓冲区中，必要时才写入磁盘； wdelay： 检查是否有相关的写操作，如果有则见这些写操作一起执行，可以提高效率（default）； no_wdelay： 若有写操作立即执行，应与sync配合使用； subtree： 若输出目录是一个子目录，则NFS Server将检查其父目录权限（default）； no_subtree： 若输出目录是一个子目录，则NFS Server将不检查其父目录权限； 例如：编辑/etc/exports 为：/tmp *(rw,no_root_squash)/home/public 172.16.7.57(rw) 172.16.7.0/24(ro) NFS Server的启动与停止在对exports文件进行了正确的配置后，就可以启动NFS Server了。 启动NFS Server为了使NFS 服务可以正常工作，需要启动portmap和nfs两个服务，并且portmap要先于nfs启动。12service portmap startservice nfs start 停止NFS Server要停止NFS时，要先停止NFS服务在停止portmap，对于系统中有其他服务（如NIS）需要使用时，不要停止portmap。12345678service portmap startStarting portmap:service nfs startStarting NFS services:Starting NFS quotas:Starting NFS daemon:Starting NFS mountd: 实例将NFS Server的/data/charlie/ 共享给172.16.7.57，权限读写 修改配置文件exports12cat /etc/exports/data/charlie 172.16.7.57(rw,no_root_squash) 重启NFS12service portmap startservice nfs start 查看是否应用配置12exportfs/data/charlie 172.16.7.57 Client挂载目录命令格式：12mount options NFS_IP:共享目录 本地挂载点mount -t nfs -o nolock 172.16.7.56:/data/zerounix /mnt 查看NFS挂载状态Server 端：显示已经被Client挂载的目录信息123showmount -aAll mount points on ssq-54.56.zerounix.com:172.16.7.57:/data/zerounix Client端：查看NFS共享状态123showmount -aExport list for 172.16.7.56/data/zerounix 172.16.7.57 查看文件是否统一 NFS有很多默认的参数，打开/var/lib/nfs/etab 查看分享出来的/home/david/ 完整权限设定值。12cat /var/lib/nfs/etab/data/zerounix 172.16.7.57(rw,sync,wdelay,hide,nocrossmnt,secure,no_root_squash,no_all_squash,no_subtree_check,secure_locks,acl,mapping=identity,anonuid=65534,anongid=65534)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[创建大于2TB分区]]></title>
      <url>http://czero000.github.io/2015/12/21/create-2t-partition.html</url>
      <content type="text"><![CDATA[parted命令介绍parted命令可以划分单个分区大于2T的GPT格式的分区，也可以划分普通的MBR分区，fdisk命令对于大于2T的分区无法划分，所以用fdisk无法看到parted划分的GPT格式的分区。 Parted 命令分为两种模式：命令行模式和交互模式。 命令行模式： parted [option] device [command] ,该模式可以直接在命令行下对磁盘进行分区操作，比较适合编程应用。 交互模式：parted [option] device 类似于使用fdisk /dev/xxx MBR：MBR分区表(即主引导记录)大家都很熟悉。所支持的最大卷：2T，而且对分区有限制：最多4个主分区或3个主分区加一个扩展分区 GPT： GPT（即GUID分区表）。是源自EFI标准的一种较新的磁盘分区表结构的标准，是未来磁盘分区的主要形式。与MBR分区方式相比，具有如下优点。突破MBR 4个主分区限制，每个磁盘最多支持128个分区。支持大于2T的分区，最大卷可达18EB。 parted是一个可以分区并进行分区调整的工具，他可以创建，破坏，移动，复制，调整ext2 linux-swap fat fat32 reiserfs类型的分区，可以创建，调整，移动Macintosh的HFS分区，检测jfs，ntfs，ufs，xfs分区。 使用方法：parted [options] [device [command [options...]...]] 12345678910111213141516171819202122232425262728options-h 显示帮助信息-l 显示所有块设备上的分区device 对哪个块设备进行操作，如果没有指定则使用第一个块设备command [options...]check partition 对分区做一个简单的检测cp [source-device] source dest 复制source-device设备上的source分区到当前设备的dest分区mklabel label-type 创建新分区表类型，label-type可以是：&quot;bsd&quot;, &quot;dvh&quot;, &quot;gpt&quot;, &quot;loop&quot;,&quot;mac&quot;, &quot;msdos&quot;, &quot;pc98&quot;, or &quot;sun&quot; 一般的pc机都是msdos格式，如果分区大于2T则需要选用gpt格式的分区表。mkfs partition fs-type 在partition分区上创建一个fs-type文件系统，fs-type可以是：&quot;fat16&quot;, &quot;fat32&quot;, &quot;ext2&quot;, &quot;linux-swap&quot;,&quot;reiserfs&quot; 注意不支持ext3格式的文件系统，只能先分区然后用专有命令进行格式化。mkpart part-type [fs-type] start end 创建一个part-type类型的分区，part-type可以是：&quot;primary&quot;, &quot;logical&quot;, or &quot;extended&quot; 如果指定fs-type则在创建分区的同时进行格式化。start和end指的是分区的起始位置，单位默认是M。eg：mkpart primary 0 -1 0表示分区的开始 -1表示分区的结尾 意思是划分整个硬盘空间为主分区mkpartfs part-type fs-type start end 创建一个fs-type类型的part-type分区，不推荐使用，最好是使用mkpart分区完成后使用mke2fs进行格式化。name partition name 给分区设置一个名字，这种设置只能用在Mac, PC98, and GPT类型的分区表，设置时名字用引号括起来select device 在机器上有多个硬盘时，选择操作那个硬盘resize partition start end 调整分区大小rm partition 删除一个分区rescue start end 拯救一个位于stat和end之间的分区unit unit 在前面分区时，默认分区时数值的单位是M，这个参数卡伊改变默认单位，&quot;kB&quot;, &quot;MB&quot;, &quot;GB&quot;, &quot;TB&quot;move partition start end 移动partition分区print 显示分区表信息 quit 退出parted 实战演练初始磁盘信息服务器新增3块4TB硬盘1234567891011121314151617181920212223242526272829303132333435363738394041fdisk -l Disk /dev/sdd: 4000.8 GB, 4000787030016 bytes255 heads, 63 sectors/track, 486401 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sdb: 4000.8 GB, 4000787030016 bytes255 heads, 63 sectors/track, 486401 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sdc: 4000.8 GB, 4000787030016 bytes255 heads, 63 sectors/track, 486401 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sda: 146.8 GB, 146815733760 bytes255 heads, 63 sectors/track, 17849 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000081Device Boot Start End Blocks Id System/dev/sda1 * 1 26 204800 83 LinuxPartition 1 does not end on cylinder boundary./dev/sda2 26 548 4194304 82 Linux swap / SolarisPartition 2 does not end on cylinder boundary./dev/sda3 548 1070 4194304 83 Linux/dev/sda4 1070 17850 134780308 5 Extended/dev/sda5 1071 17850 134778880 83 Linux 尝试通过fdisk命令进行分区1234567891011121314151617fdisk /dev/sdb Device contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabelBuilding a new DOS disklabel with disk identifier 0x6001e0a2.Changes will remain in memory only, until you decide to write them.After that, of course, the previous content won&apos;t be recoverable.Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)WARNING: The size of this disk is 4.0 TB (4000787030016 bytes).DOS partition table format can not be used on drives for volumeslarger than (2199023255040 bytes) for 512-byte sectors. Use parted(1) and GUID partition table format (GPT).WARNING: DOS-compatible mode is deprecated. It&apos;s strongly recommended to switch off the mode (command &apos;c&apos;) and change display units to sectors (command &apos;u&apos;) fdisk 命令无法对大于2TB以上的硬盘进行分区 通过parted命令进行分区更改分区表类型123parted -s /dev/sdb mklabel gptparted -s /dev/sdc mklabel gptparted -s /dev/sdd mklabel gpt 磁盘分区123parted /dev/sdb &apos;mkpart primary 0 -1&apos;parted /dev/sdc &apos;mkpart primary 0 -1&apos;parted /dev/sdd &apos;mkpart primary 0 -1&apos; 格式化分区123mkfs.ext4 -q /dev/sdb1mkfs.ext4 -q /dev/sdc1mkfs.ext4 -q /dev/sdd1 挂载目录123mkdir /MFS_DATA1; mount /dev/sdb1 /MFS_DATA1;echo &quot;mount /dev/sdb1 /MFS_DATA1&quot; &gt;&gt; /etc/rc.localmkdir /MFS_DATA2; mount /dev/sdc1 /MFS_DATA2;echo &quot;mount /dev/sdc1 /MFS_DATA2&quot; &gt;&gt; /etc/rc.localmkdir /MFS_DATA3; mount /dev/sdd1 /MFS_DATA3;echo &quot;mount /dev/sdd1 /MFS_DATA3&quot; &gt;&gt; /etc/rc.local 查看磁盘挂载123456789df -hFilesystem Size Used Avail Use% Mounted on/dev/sda5 127G 1.1G 120G 1% /tmpfs 7.8G 12K 7.8G 1% /dev/shm/dev/sda1 194M 29M 155M 16% /boot/dev/sda3 4.0G 254M 3.5G 7% /var/dev/sdb1 3.6T 196M 3.4T 1% /MFS_DATA1/dev/sdc1 3.6T 196M 3.4T 1% /MFS_DATA2/dev/sdd1 3.6T 196M 3.4T 1% /MFS_DATA3]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Smokeping-主辅]]></title>
      <url>http://czero000.github.io/2015/12/20/smokeping-master-slave.html</url>
      <content type="text"><![CDATA[smokeping Master/Slave分布式模式在使用smokeping过程中，很容易发现，如果从单个节点去探测网络性能，并不能充分检测到整个网络的一个状态。smokeping提供了基于多节点的分布式模式，可以从多个节点去探测到网络的状态，这样我们才能全面客观的监控真个网络。smokeping的分布式为主从模式，M/S模式配置起来很简单，slave的配置基本与master的配置相同，只是slave不需要config文件，而是在启动过程中请求master上面的config文件，这样只需要维护master上面的config文件即可。 smokeping分布式的检测方式为被动方式，由slave节点在启动时从master上获取config文件，然后进行探测，探测后的数据在通过cgi提交给master。slave可为多个，M/S直接通信认证是通过--shared-secret=filename来和master进行密码认证。12345678[slave 1] [slave 2] [slave 3] | | | +-------+ | +--------+ | | | v v v +---------------+ | master | +---------------+ Smokeping主从通信认证smokeping主从验证通过Master和和Slave的/usr/local/smokeping/etc/smokeping_secrets文件进行的，但是Master和Slave的验证文件书写方式是有所不同。 Master验证文件格式1SlaveName:Password SlaveName是在Master配置文件中定义slave是指定的名称，这个名称要唯一。 注:/usr/local/smokeping/etc/smokeping_secrets 文件属性必须是600 Slave验证文件格式1Password Slave的secrets文件在启动时要指定，Master和Slave的密码要保持一致。 注: /usr/local/smokeping/etc/smokeping_secrets 文件属性必须是600 配置Slave修改配置文件配置主从主要有两步，一是修改smokeping_secrets文件，添加SlaveName和Password。二是修改Master上面的config文件 在配置文件中添加如下内容 1234567891011121314151617181920212223242526*** Slaves *** secrets=/usr/local/smokeping/etc/smokeping_secrets // 验证文件+boomer // SlaveName，要和smokeping_secrets保持一致，slave启动时也是这个名字display_name=boomer // 页面显示的名字color=0000ff // 绘图颜色，要小写``` slave可以配置多个，名字要唯一，颜色也要不同，配置完slave后，还要在监控节点上面添加slave #### 部署slave ### 部署slave和Master步骤相同，可以参考Master 的部署过程。 #### 启动Slaveslave并不需要config配置文件，在启动时要指定master地址等相关信息，格式如下``` /usr/local/smokeping/bin/smokeping --master-url=http://masterip/ping/smokeping.cgi --cache-dir=/var/smokeping --shared-secret=/usr/local/smokeping/etc/secrets --slave-name=SlaveName]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Centos7安装smokeping]]></title>
      <url>http://czero000.github.io/2015/12/20/centos7-install-smokeping.html</url>
      <content type="text"><![CDATA[I am using Centos7 + smokeping-2.6.9 lets start up by install needed package before that, we will need to enable Epel repo You can install EPEL by running yum install epel-release. The package is included in the CentOS Extras repository, enabled by default. install epel1yum install epel-release Then follow up by the package for: mod_fcgid httpd httpd-devel rrdtool perl-CGI-SpeedyCGI fping rrdtool-perl perl perl-Sys-Syslog 1yum install mod_fcgid httpd httpd-devel rrdtool perl-CGI-SpeedyCGI fping rrdtool-perl perl perl-Sys-Syslog install perl modulesThen we will needed some package for Cpan to install perl stuff1yum install perl-CPAN perl-local-lib perl-Time-HiRes The last one is the package to create installation for smokeping1# yum groupinstall &quot;Development tools&quot; install smokeping1234567891011121314151617181920\\ Now lets download the latest smokeping at http://oss.oetiker.ch/smokeping/pub currently the latest i saw is 2.6.9, so i just download thatwget http://oss.oetiker.ch/smokeping/pub/smokeping-2.6.9.tar.gz\\ then extract ittar -zxvf smokeping-2.6.9.tar.gz\\ Install the smokeping perl stuffcd smokeping-2.6.9/setup./build-perl-modules.sh\\ it will auto install needed perl\\ Once done, back to smokeping-2.6.9 folder and you will notice a folder name thirdparty is created\\ we will need to move it to /usr/local/smokeping folder, but before that, lets create smokeping folder at /usr/local/smokeping first\\ then copy the thirdparty folder into itmkdir /urs/local/smokepingcp -r thirdparty /usr/lcoal/smokeping/./configure --prefix=/usr/local/smokeping PERL5LIB=/usr/lib64/perl5/makemake install Note: if you encounter problem, please try make install againthis is because for my situation when i first make install, it pop some error but when i try make install again, the error gone Now you can go to /usr/local/smokeping/etc and prepare the config file install httpdNow is time to prepare for the interface make sure you had install apache else please install it using yum install httpd1yum install httpd -y smokeping config123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171cd /usr/local/smokeping/etcfor foo in *.dist; do cp $foo `basename $foo .dist`; donemv /usr/local/smokeping/htdocs/smokeping.fcgi.dist /usr/local/smokeping/htdocs/smokeping.fcgi\\edit smokeping.confvim /etc/httpd/conf.d/smokeping.confAlias /ping /usr/local/smokeping/htdocs/ DirectoryIndex index.html smokeping.fcgi Options +ExecCGI #AllowOverride None AddHandler cgi-script .cgi .fcgi Order allow,deny Allow from all AuthName &quot;Smokeping Access&quot; AuthType Basic AuthUserFile /usr/local/smokeping/htdocs/htpasswd.user Require valid-userchmod 600 /usr/local/smokeping/etc/smokeping_secretsmkdir -p /usr/local/smokeping/htdocs/cachemkdir /usr/local/smokeping/datamkdir /usr/local/smokeping/varchown nobody:nobody /usr/local/smokeping/varchown nobody:nobody /usr/local/smokeping/datachown nobody:nobody /usr/local/smokeping/htdocs/cache\\Before we start smokeping, please edit your configuration first edit the smokeping config to your need (change the part in Red color wordvim /usr/local/smokeping/etc/config*** General ***owner = Charlie.cuicontact = some@address.nowheremailhost = my.mail.host (Ignore if you do not have smtp server)sendmail = /usr/sbin/sendmail# NOTE: do not put the Image Cache below cgi-bin# since all files under cgi-bin will be executed ... this is not# good for images.imgcache = /usr/local/smokeping/cacheimgurl = cachedatadir = /usr/local/smokeping/datapiddir = /usr/lcoal/smokeping/varcgiurl = http://some.url/smokeping.cgismokemail = /usr/local/smokeping/etc/smokemail.disttmail = /usr/local/smokeping/etc/tmail.dist# specify this to get syslog loggingsyslogfacility = local0# each probe is now run in its own process# disable this to revert to the old behaviour# concurrentprobes = no*** Alerts ***to = alertee@address.somewherefrom = smokealert@company.xy+somelosstype = loss# in percentpattern = &gt;0%,*12*,&gt;0%,*12*,&gt;0%comment = loss 3 times in a row*** Database ***step = 300pings = 20# consfn mrhb steps totalAVERAGE 0.5 1 1008AVERAGE 0.5 12 4320 MIN 0.5 12 4320 MAX 0.5 12 4320AVERAGE 0.5 144 720 MAX 0.5 144 720 MIN 0.5 144 720*** Presentation ***template = /usr/local/smokeping/etc/basepage.html.dist+ chartsmenu = Chartstitle = The most interesting destinations++ stddevsorter = StdDev(entries=&gt;4)title = Top Standard Deviationmenu = Std Deviationformat = Standard Deviation %f++ maxsorter = Max(entries=&gt;5)title = Top Max Roundtrip Timemenu = by Maxformat = Max Roundtrip Time %f seconds++ losssorter = Loss(entries=&gt;5)title = Top Packet Lossmenu = Lossformat = Packets Lost %f++ mediansorter = Median(entries=&gt;5)title = Top Median Roundtrip Timemenu = by Medianformat = Median RTT %f seconds+ overviewwidth = 600height = 50range = 10h+ detailwidth = 600height = 200unison_tolerance = 2&quot;Last 3 Hours&quot; 3h&quot;Last 30 Hours&quot; 30h&quot;Last 10 Days&quot; 10d&quot;Last 400 Days&quot; 400d#+ hierarchies#++ owner#title = Host Owner#++ location#title = Location*** Probes ***+ FPingbinary = /usr/sbin/fping*** Slaves ***secrets=/usr/local/smokeping/etc/smokeping_secrets.dist+boomerdisplay_name=boomercolor=0000ff+slave2display_name=anothercolor=00ff00*** Targets ***probe = FPingmenu = Toptitle = Network Latency Grapherremark = Welcome to the SmokePing website of xxx Company. \ Here you will learn all about the latency of our network.+ Servermenu= Targets++ googlemenu = google.comtitle = google.comalerts = somelosshost = www.google.com Start the apache service1systemctl start httpd start the smokeping services1/usr/local/smokeping/bin/smokeping --config=/usr/local/smokeping/etc/config --logfile=/var/log/smokeing.log For startup scriptyou can get it from here123wget http://oss.oetiker.ch/smokeping/pub/contrib/smokeping-start-script\\ just edit the smokeping path then put at /etc/init.d/chmod 755 /etc/init.d/smokeping]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Smokeping页面支持中文]]></title>
      <url>http://czero000.github.io/2015/12/20/smokeping-support-chinese.html</url>
      <content type="text"><![CDATA[smokeping页面和rrdtool图片支持中文smokeping默认不支持中文，只需要修改如下便可： 页面支持中文在配置文件的*** Presentation ***下面添加1charset = utf-8 rrd图片支持中文安装中文支持1yum groupinstall &quot;chinese support&quot; 查看中文字体支持：123fc-list :lang=zhAR PL ZenKai Uni,文鼎PL中楷Uni:style=MediumAR PL ShanHeiSun Uni,文鼎PL細上海宋Uni,文鼎PL细上海宋Uni:style=Regular 修改配置文件编辑 /usr/local/smokeping/lib/Smokeping/Graphs.pm 插入 &quot;&apos;--font TITLE:20:AR PL ShanHeiSun Uni&apos;，&quot; if ($mode =~ /[anc]/){ my $val = 0; for my $host (@hosts){ my ($graphret,$xs,$ys) = RRDs::graph (&quot;dummy&quot;, &apos;--start&apos;, $tasks[0][1], &apos;--end&apos;, $tasks[0][2], &apos;--font TITLE:20:AR PL ShanHeiSun Uni&apos;, &quot;DEF:maxping=$cfg-&gt;{General}{datadir}${host}.rrd:median:AVERAGE&quot;, &apos;PRINT:maxping:MAX:%le&apos; ); my $ERROR = RRDs::error(); return &quot; RRDtool did not understand your input: $ERROR. &quot; if $ERROR; $val = $graphret-&gt;[0] if $val [0]; } $val = 1e-6 if $val =~ /nan/i; $max = { $tasks[0][1] =&gt; $val * 1.5 }; }]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Smokeping-安装]]></title>
      <url>http://czero000.github.io/2015/12/20/install-smokeping.html</url>
      <content type="text"><![CDATA[Smokeping 监控网络质量什么是SmokepingSmokeping是 rrdtool 的作者 Tobi Oetiker 的作品，所以它在图形显示方面有很大优势，也是一个很有特点的 opensource 工具： 多种探测方式，包括 fping、echoping、dig、curl 等； 易用可扩展的插件；master/slave 的工作方式，可以在多个节点收集同一个监测点的数据； 很有特色的 alert 设置，不只是简单的设置一个阀值。 Smokeping架构组件smokeping 是一个用 perl 写的程序，所以不需要安装，但是他需要使用一些工具。Smokeping 有以下组件组成：RRDtool、Fping、Echoping、Curl、Dig、SSh、Perl 模块，Perl、FCGI、Apache 等。 Smokeping 相关资源 Smokeping官方网站：http://oss.oetiker.ch/smokeping/ Smokeping官方文档：http://oss.oetiker.ch/smokeping/doc/index.en.html 安装Smokeping安装RRDTOOL RRDTool 是由Tobias Oetiker 开发的开源软件，它使用RRD（Round Rebin Databases）作为存储格式，Round robin 是一种处理定量数据以及当前元素指针的技术，RRDTool 主要用来跟踪对象的变化情况，生成改对象变化的趋势图。 依赖软件包：1yum install cairo-devel libxml2-devel pango-devel pango libpng-devel freetype freetype-devel libart_lgpl-devel libidn libidn-devel httpd httpd-devel apr-util-devel apr-devel -y 如果nginx作为webserver，则要安装perl模块perl-Net-Telnet perl-Net-DNS perl-LDAP perl-CGI-SpeedyCGI perl-libwww-perl perl-RadiusPerl perl-IO-Socket-SSL perl-Socket 执行安装12345wget http://oss.oetiker.ch/rrdtool/pub/rrdtool-1.4.7.tar.gztar -zxf rrdtool-1.4.7.tar.gzcd rrdtool-1.4.7./configure --prefix=/usr/local/rrdtoolmake &amp;&amp; make install 检验安装是否成功：12345678910111213/usr/local/rrdtool/bin/rrdtoolRRDtool 1.4.7 Copyright 1997-2012 by Tobias Oetiker Compiled May 21 2013 13:42:05 Usage: rrdtool [options] command command_optionsValid commands: create, update, updatev, graph, graphv, dump, restore, last, lastupdate, first, info, fetch, tune, resize, xport, flushcached RRDtool is distributed under the Terms of the GNU GeneralPublic License Version 2. (www.gnu.org/copyleft/gpl.html) For more information read the RRD manpages 执行命令如果出现以上输出，表示安装成功，并列出了使用该命令的帮助信息。 安装fping12345wget http://oss.oetiker.ch/smokeping/pub/fping-2.4b2_to3-ipv6.tar.gztar -zxf fping-2.4b2_to3-ipv6.tar.gzcd fping-2.4b2_to3-ipv6./configuremake &amp;&amp; make install 安装echoping12345wget http://sourceforge.net/projects/echoping/files/latest/downloadtar -zxf echoping-6.0.2.tar.gzcd echoping-6.0.2./configuremake &amp;&amp; make install 安装fcgi12345wget http://cpan.communilink.net/authors/id/F/FL/FLORA/FCGI-0.74.tar.gztar -zxf FCGI-0.74.tar.gzcd FCGI-0.74perl Makefile.PLmake &amp;&amp; make install 安装mod_fastcgi1234567wget http://www.fastcgi.com/dist/mod_fastcgi-2.4.6.tar.gztar zxf mod_fastcgi-2.4.6.tar.gzcd mod_fastcgi-2.4.6 apxs -o mod_fastcgi.so -c *.capxs -i -a -n fastcgi .libs/mod_fastcgi.so确保httpd.conf有如下配置：LoadModule fastcgi_module /usr/lib/httpd/modules/mod_fastcgi.so 如果apache为源码安装123456wget http://www.fastcgi.com/dist/mod_fastcgi-2.4.6.tar.gztar -zxf mod_fastcgi-2.4.6.tar.gzcd mod_fastcgi-2.4.6cp Makefile.AP2 Makefilemake top_dir=/usr/local/apachemake install top_dir=/usr/local/apache 安装smokeping1234wget http://oss.oetiker.ch/smokeping/pub/smokeping-2.6.9.tar.gztar -zxf smokeping-2.6.9.tar.gzcd smokeping-2.6.9./configure --prefix=/usr/local/smokeping PERL5LIB=/usr/lib/perl5/ 报错12345678checking checking for gnu make availablility... /usr/bin/gmake is GNU makechecking checking for perl module &apos;RRDs&apos;... Failedchecking checking for perl module &apos;FCGI&apos;... Okchecking checking for perl module &apos;CGI&apos;... Okchecking checking for perl module &apos;CGI::Fast&apos;... Okchecking checking for perl module &apos;Config::Grammar&apos;... Failedchecking checking for perl module &apos;Digest::HMAC_MD5&apos;... Okchecking checking for perl module &apos;LWP&apos;... Ok 解决1 ./setup/build-perl-modules.sh /usr/local/smokeping/thirdparty 或者yum –y install perl-[FAIL-MOUDLES] 报错1checking checking for perl module &apos;RRDs&apos;... Failed 解决12345632位：ln -s /usr/local/rrdtool/lib/perl/5.10.1/i386-linux-thread-multi/RRDs.pm /usr/lib/perl5/ln -s /usr/local/rrdtool/lib/perl/5.10.1/i386-linux-thread-multi/auto/RRDs/RRDs.so /usr/lib/perl5/ 64位：ln -s /usr/local/rrdtool/lib/perl/5.10.1/x86_64-linux-thread-multi/RRDs.pm /usr/lib64/perl5/ln -s /usr/local/rrdtool/lib/perl/5.10.1/x86_64-linux-thread-multi/auto/RRDs/RRDs.so /usr/lib64//perl5/ 在执行下面操作，完成安装123make clean./configure –prefix=/usr/local/smokeping/usr/bin/gmake install 配置smokeping修改相关文件1234567891011121314/usr/local/smokeping/bin/smokeping/usr/local/smokeping/bin/smokeping_cgi将第八行 use lib qw(); # PERL5LIB修改为： use lib qw(/usr/local/rrdtool/lib/perl); # PERL5LIB /usr/local/smokeping/htdocs/smokeping.fcgi.dist：mv /usr/local/smokeping/htdocs/smokeping.fcgi.dist /usr/local/smokeping/htdocs/smokeping.fcgi 进入 /usr/local/smokeping/etcmv config.dist configmv basepage.html.dist basepage.htmlmv smokemail.dist smokemailmv tmail.dist tmailmv smokeping_secrets.dist smokeping_secrets 修改主配置config123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172*** General *** ##全局配置owner = charlie.cui@zerounix.com ##联系人（显示在网页上）contact = charlie.cui@zerounix.com ##联系人邮箱mailhost = mail.zerounix.com ##邮件服务主机sendmail = /usr/sbin/sendmail ##发送邮件件的二进制可执行程序# NOTE: do not put the Image Cache below cgi-bin# since all files under cgi-bin will be executed ... this is not# good for images.imgcache = /usr/local/smokeping/cache ##生成图片的缓存imgurl = cache ##cache 定义cgi程序显示图片的url目录datadir = /usr/local/smokeping/data ##rrd文件的位置piddir = /usr/local/smokeping/varcgiurl = http://some.url/smokeping.cgi ##smokeping访问地址smokemail = /usr/local/smokeping/etc/smokemail ##发送邮件的邮件内容模板tmail = /usr/local/smokeping/etc/tmail ##HTML邮件模板的路径# specify this to get syslog loggingsyslogfacility = local0 ##syslog日志记录的设备编号# each probe is now run in its own process# disable this to revert to the old behaviour# concurrentprobes = no *** Alerts *** ##报警配置to = monitor@zerounix.com from = mon@zerounix.com +网络中断type = rttpattern = !=U,==Ucomment = 网络中断priority = 1 +中断恢复type = rttpattern = ==U,!=U,!=Ucomment = 中断恢复priority = 2 +严重丢包type = losspattern = &gt;50%comment = 丢包大于50%priority = 3 +丢包报警type = losspattern = &gt;10%,&gt;10%,&gt;10%comment = 连续3次丢包10%以上priority = 4 +网络延迟type = rttpattern = &gt;180,&gt;180,&gt;180comment = 连续3次延时180以上priority = 5 *** Database *** step = 60pings = 10 # consfn mrhb steps total AVERAGE 0.5 1 1008AVERAGE 0.5 12 4320 MIN 0.5 12 4320 MAX 0.5 12 4320AVERAGE 0.5 144 720 MAX 0.5 144 720 MIN 0.5 144 720 *** Presentation *** template = /usr/local/smokeping/etc/basepage.html + charts menu = Chartstitle = The most interesting destinations ++ stddevsorter = StdDev(entries=&gt;4)title = Top Standard Deviationmenu = Std Deviationformat = Standard Deviation %f ++ maxsorter = Max(entries=&gt;5)title = Top Max Roundtrip Timemenu = by Maxformat = Max Roundtrip Time %f seconds ++ losssorter = Loss(entries=&gt;5)title = Top Packet Lossmenu = Lossformat = Packets Lost %f ++ mediansorter = Median(entries=&gt;5)title = Top Median Roundtrip Timemenu = by Medianformat = Median RTT %f seconds + overview width = 600height = 50range = 10h + detail width = 600height = 200unison_tolerance = 2 &quot;Last 3 Hours&quot; 3h&quot;Last 30 Hours&quot; 30h&quot;Last 10 Days&quot; 10d&quot;Last 400 Days&quot; 400d #+ hierarchies#++ owner#title = Host Owner#++ location#title = Location *** Probes *** + FPing binary = /usr/local/sbin/fping + DNSbinary = /usr/bin/diglookup = name.example*** Slaves ***secrets=/usr/local/smokeping/etc/smokeping_secrets+boomerdisplay_name=boomercolor=0000ff +slave2display_name=anothercolor=00ff00 *** Targets *** probe = FPing menu = Toptitle = Network Latency Grapherremark = Welcome to the SmokePing website of xxx Company. \ Here you will learn all about the latency of our network. + Testmenu= Targets#parents = owner:/Test/James location:/ ++ James menu = Jamestitle =Jamesalerts = somelossslaves = boomer slave2host = james.address ++ MultiHost menu = Multihosttitle = James and James as seen from Boomerhost = /Test/James /Test/James~boomer 监控主机是分层结构，用+表示例如第一层“+”，第二层“++”一次类推 master/slave的方式，后面会介绍。 修改其他配置根据配置文件所写的，创建数据文件目录：1mkdir /usr/local/smokeping/&#123;htdocs/var,cache,data&#125; 修改数据文件目录的属主及属组1chown nobody:nobody /usr/local/smokeping/&#123;htdocs/var,cache,data&#125; /usr/local/smokeping/etc/smokeping_secrets这个文件存放的是master/slave之间的验证密码，现在暂时不用 启动smokeping1sudo -u nobody /usr/local/smokeping/bin/smokeping --logfile=/var/log/smokeping.log --restart 报错：ERROR: FPing must be installed setuid root or it will not work at (eval 29) line 1解决123whereis fpingfping: /usr/local/sbin/fpingchmod +s /usr/local/sbin/fping 配置apache的配置文件12345678910111213Alias /ping /usr/local/smokeping/htdocs/&lt;Directory &quot;/usr/local/smokeping/htdocs&quot;&gt; DirectoryIndex index.html smokeping.fcgi Options FollowSymLinks ExecCGI AllowOverride None AddHandler cgi-script .cgi .fcgi Order allow,deny Allow from all AuthName &quot;Smokeping Access&quot; AuthType Basic AuthUserFile /usr/local/smokeping/htdocs/htpasswd.user Require valid-user&lt;/Directory&gt; FAQ：不出图解决思路 使用–debug方式启动smokeping，排查错误 查看smokeping的log 查看apache的error.log 查看文件权限，包括数据文件目录及数据文件，apache和smokeping的启动用户，rrd文件是否有数据]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RRDTOOL安装报错解决]]></title>
      <url>http://czero000.github.io/2015/12/20/install-rrdtool-trubleshooting.html</url>
      <content type="text"><![CDATA[在安装rrdtool过程中，出现报错，原来是缺少perl模块 报错信息123456789Can&apos;t locate ExtUtils/MakeMaker.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at Makefile.PL line 1.BEGIN failed--compilation aborted at Makefile.PL line 1.make[3]: *** [perl-piped/Makefile] Error 2make[3]: Leaving directory `/usr/local/src/rrdtool-1.4.9/bindings&apos;make[2]: *** [all-recursive] Error 1make[2]: Leaving directory `/usr/local/src/rrdtool-1.4.9/bindings&apos;make[1]: *** [all-recursive] Error 1make[1]: Leaving directory `/usr/local/src/rrdtool-1.4.9&apos;make: *** [all] Error 2 解决方法1yum install perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Cacti监控交换机不显示端口]]></title>
      <url>http://czero000.github.io/2015/12/20/cacti-monitor-switch-trubleshooting.html</url>
      <content type="text"><![CDATA[Cacti监控cisco设备时图表上的标题显示为GigabitEthernet而并没有指出具体的端口号,一般说来，图片的流量统计描述都是|host_description| - Traffic - |query_ifName|按照这个形式来描述的，对于华为的设备，Gi显示成GigabitEthernet，可能导致后面的模块号，端口好无法显示。原因是Cacti的 ” 最大域 长度(用于显示数据查询区域的最大字符数.) ” 默认为15. 修改方法: 中文版配置 -&gt; 设置 -&gt; 可视化 -&gt; 最大域长度 80 英文版1234567891011Console -&gt; Settings -&gt; Visual -&gt; Maximum Field Length: 默认15,修改成80就OK了。The maximum number of characters to display for a data query field.Maximum Title LengthThe maximum number of characters to display for a graph title.Maximum Field LengthThe maximum number of characters to display for a data query field. 同时修改了以上2个选项，但是还是不行。 发现流量的绘图引用的是Interface - Traffic (bits/sec)这个模板， console-Graph Templates-Interface - Traffic (bits/sec) 在后面的框框里面加上了- |query_ifName|这部分内容，以前这里是没有的！ 最后重新添加图，发现端口已经出来了！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ip_conntrack: table full dropping packet解决方法]]></title>
      <url>http://czero000.github.io/2015/12/20/iptables-table-full-dropping-packet.html</url>
      <content type="text"><![CDATA[问题现象监控报警，发现ping有持续丢包，ifconfig看到网卡dripped:xx 一直在增加，messages日志有以下内容1234kernel: ip_conntrack: table full, dropping packet.kernel: printk: 443 messages suppressed.kernel: ip_conntrack: table full, dropping packet.kernel: printk: 431 messages suppressed. 出现原因是ip_conntrack表满导致的，iptables开启后会加载ip_conntrack模块，来跟踪包。默认情况下ip_conntrack_max大小为65536，nf_conntrack 在CentOS 5 / kernel 解决方法关闭防火墙或者清除防火墙规则，简单粗暴，直接有效增加ip_conntrack表大小优化系统参数查看ip_conntrack最大大小：1cat /proc/sys/net/ipv4/ip_conntrack_max 查看当前ip_conntrack大小：1wc -l /proc/net/ip_conntrack 状态跟踪表的最大行数的设定，理论最大值 CONNTRACK_MAX = RAMSIZE (in bytes) / 16384 / (ARCH / 32) 以64G的64位操作系统为例，CONNTRACK_MAX = 64*1024*1024*1024/16384/2 = 20971521sysctl –w net.netfilter.nf_conntrack_max = 2097152 相关系统参数调优123456cat /etc/sysctl.conf net.netfilter.nf_conntrack_max = 1048576 net.netfilter.ip_conntrack_tcp_timeout_established = 3600 net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60 net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120 net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120 sysctl -p 使其生效这种解决方案，需要在每次iptables重启后，都要执行一遍sysctl -p， 也可以将sysctl -p写入到iptables启动脚本中。 不过ip_conntrack满的隐患还是存在的。 不加载ip_conntrack模块防火墙不加载任何额外模块 编辑/etc/sysconfig/iptables-config配置文件12345678IPTABLES_MODULES=&quot;&quot; # 不需要任何附加模块IPTABLES_MODULES_UNLOAD=&quot;no&quot; # 避免iptables重启后sysctl中对应的参数被重置为系统默认值IPTABLES_SAVE_ON_STOP=&quot;no&quot;IPTABLES_SAVE_ON_RESTART=&quot;no&quot;IPTABLES_SAVE_COUNTER=&quot;no&quot;IPTABLES_STATUS_NUMERIC=&quot;yes&quot;IPTABLES_STATUS_VERBOSE=&quot;no&quot;IPTABLES_STATUS_LINENUMBERS=&quot;no&quot; 删除nf_conntrack和相关的依赖模块123456789rmmod nf_conntrack_ipv4 rmmod nf_conntrack_ipv6 rmmod xt_state rmmod xt_CT rmmod xt_conntrack rmmod iptable_nat rmmod ipt_REDIRECT rmmod nf_nat rmmod nf_conntrack 禁用追踪模块，把它加入黑名单/etc/modprobe.d/blacklist.conf12345678910# 禁用 nf_conntrack 模块 blacklist nf_conntrack blacklist nf_conntrack_ipv6 blacklist xt_conntrack blacklist nf_conntrack_ftp blacklist xt_state blacklist iptable_nat blacklist ipt_REDIRECT blacklist nf_nat blacklist nf_conntrack_ipv4 /etc/sysconfig/iptables 不要配置状态的规则1-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT 优化conntrack模块，请参考下面文章http://wiki.khnet.info/index.php/Conntrack_tuninghttp://blog.yorkgu.me/wp-content/uploads/2012/02/netfilter_conntrack_perf-0.8.txt]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[安装Bind问题解析]]></title>
      <url>http://czero000.github.io/2015/12/20/bind-trubleshooting.html</url>
      <content type="text"><![CDATA[安装Bind过程中发现的问题，本文是解决过程 问题 ipv6问题报错信息如下： 1&quot;0-Nov-2015 16:40:55.395 lame-servers: info: error (network unreachable) resolving &apos;./NS/IN&apos;: 2001:500:2f::f#53&quot; 解决 ipv6问题 方法一： 直接编辑配置文件/etc/sysconfig/named，去掉IPv6的解析，只解析IPv4 OPTIONS=&quot;whatever&quot;变更为OPTIONS=&quot;-4&quot; 方法二： 禁掉IPv6功能，编辑/etc/sysconfig/network,将NETWORKING_IPV6=YES变更为NETWORKING_IPV6=no]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux流量监控工具iftop]]></title>
      <url>http://czero000.github.io/2015/12/20/liunix-traffic-monitor-iftop.html</url>
      <content type="text"><![CDATA[在类unix系统中，大家熟悉的top命令可以查看系统资源、进程、内存占用等信息，且动态实时显示。要查看网络状态可以使用netstat、nmap等工具。若要查看实时的网络流量，监控TCP/IP连接等，则可以使用iftop。 iftop简介类似于top的实时监控系统资源和进程等，iftop是一个实时流量监控工具。iftop可以用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等。 安装iftop12Debian系统 运行：apt-get install iftopCentOS系统 运行：yum install iftop 详解123456789界面上面显示的是类似刻度尺的刻度范围，为显示流量图形的长条作标尺用的。中间的 这两个左右箭头，表示的是流量的方向。TX：发送流量RX：接收流量TOTAL：总流量Cumm：运行iftop到目前时间的总流量peak：流量峰值rates：分别表示过去 2s 10s 40s 的平均流量 参数12345678910111213141516171819202122232425262728-h display this message -n don&apos;t do hostname lookups -N don&apos;t convert port numbers to services -p run in promiscuous mode (show traffic between other hosts on the same network segment)-b don&apos;t display a bar graph of traffic-B Display bandwidth in bytes-i interface listen on named interface-f filter code use filter code to select packets to count (default: none, but only IP packets are counted)-F net/mask show traffic flows in/out of IPv4 network-G net6/mask6 show traffic flows in/out of IPv6 network-l display and count link-local IPv6 traffic (default: off)-P show ports as well as hosts-m limit sets the upper limit for the bandwidth scale-c config file specifies an alternative configuration file-t use text interface without ncursesSorting orders:-o 2s Sort by first column (2s traffic average)-o 10s Sort by second column (10s traffic average) [default]-o 40s Sort by third column (40s traffic average)-o source Sort by source address-o destination Sort by destination addressThe following options are only available in combination with -t-s num print one single text output afer num seconds, then quit-L num number of lines to print```]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Curl命令获取http状态码]]></title>
      <url>http://czero000.github.io/2015/12/20/curl-get-http-status-code.html</url>
      <content type="text"><![CDATA[通过curl的-w参数我们可以自定义curl的输出，%{http_code}代表http状态码1curl -I -m 10 -o /dev/null -s -w %&#123;http_code&#125; www.letuknowit.com 上面的输出是不含换行的，如果需要换行的话，加上\n123curl -I -m 10 -o /dev/null -s -w %&#123;http_code&#125; www.letuknowit.com200# curl -I -m 10 -o /dev/null -s -w %&#123;http_code&#125;&quot;\n&quot; www.letuknowit.com200]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Bash状态码]]></title>
      <url>http://czero000.github.io/2015/12/20/bash-status.html</url>
      <content type="text"><![CDATA[Linux Shell退出状态代码 描述 0 命令执行成功 1 未知错误 2 误用Shell命令 126 命令无法执行 127 没有找到命令 128 无效的退出参数 128+x 使用Linux 信号x 的致命错误 130 使用Ctrl-C终止命令 255 规范外的退出状态]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Fishshell]]></title>
      <url>http://czero000.github.io/2015/12/20/fishshell.html</url>
      <content type="text"><![CDATA[什么是Fish ShellFISH（friendly interactive shell）是一个用户友好的命令行 shell，主要是用来进行交互式使用。shell 就是一个用来执行其他程序的程序。 Fish Shell 特性自动建议fish 会根据你的历史输入和补完来提供命令建议，就像一个网络浏览器一样。注意了，就是Netscape Navigator 4.0!) 漂亮的 VGA 色彩fish 原生支持 term256， 它就是一个终端技术的艺术国度。 你将可以拥有一个难以置信的、256 色的shell 来使用。 理智的脚本fish 是完全可以通过脚本控制的，而且它的语法又是那么的简单、干净，而且一致。你甚至不需要去重写。 基于 web 的配置对于少数能使用图形计算机的幸运儿， 你们可以在网页上配置你们自己的色彩方案，以及查看函数、变量和历史记录。 帮助手册补全其它的 shell 支持可配置的补全， 但是只有 fish 可以通过自动转换你安装好的 man 手册来实现补全功能。 开箱即用fish 将会通过 tab 补全和语法高亮使你非常愉快的使用shell， 同时不需要太多的学习或者配置。 安装Fish Shell1234567891011121314对于 CentOS 7，请以 根用户 root 运行下面命令：cd /etc/yum.repos.d/wget http://download.opensuse.org/repositories/shells:fish:release:2/CentOS_7/shells:fish:release:2.repoyum install fish对于 CentOS 6，请以 根用户 root 运行下面命令：cd /etc/yum.repos.d/wget http://download.opensuse.org/repositories/shells:fish:release:2/CentOS_6/shells:fish:release:2.repoyum install fish对于 CentOS 5，请以 根用户 root 运行下面命令：cd /etc/yum.repos.d/wget http://download.opensuse.org/repositories/shells:fish:release:2/CentOS_5/shells:fish:release:2.repoyum install fish 附: 主流类 UNIX 系统安装方法介绍]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[awk内置函数的使用(split/substr/length)]]></title>
      <url>http://czero000.github.io/2015/12/20/awk-split-substr-length.html</url>
      <content type="text"><![CDATA[split 初始化和类型强制awk的内建函数split允许你把一个字符串分隔为单词并存储在数组中。你可以自己定义域分隔符或者使用现在FS(域分隔符)的值。 格式： 12split (string, array, field separator)split (string, array) --&gt;如果第三个参数没有提供，awk就默认使用当前FS值。 替换分隔符 123time=&quot;12:34:56&quot;out=`echo $time | awk &apos;&#123;split($0,a,&quot;:&quot;);print a[1],a[2],a[3]&#125;&apos;`echo $out 123456789101112// 计算指定范围内的和(计算每个人1月份的工资之和)cat test.txtTom 2012-12-11 car 53000John 2013-01-13 bike 41000vivi 2013-01-18 car 42800Tom 2013-01-20 car 32500John 2013-01-28 bike 63500awk &apos;&#123;split($2,a,&quot;-&quot;);if(a[2]==01)&#123;b[$1]+=$4&#125;&#125;END&#123;for(i in b)print i,b[i]&#125;&apos; test.txt vivi 2800Tom2500John4500 substr 截取字符串返回从起始位置起，指定长度之子字符串；若未指定长度，则返回从起始位置到字符串末尾的子字符串。 格式：substr(s,p) 返回字符串s中从p开始的后缀部分substr(s,p,n) 返回字符串s中从p开始长度为n的后缀部分 1234echo &quot;123&quot; | awk &apos;&#123;print substr($0,1,1)&#125;&apos;\\ awk -F &apos;,&apos; &apos;&#123;print substr($3,6)&#125;&apos; ---&gt; 表示是从第3个字段里的第6个字符开始，一直到设定的分隔符&quot;,&quot;结束.\\ substr($3,10,8) ---&gt; 表示是从第3个字段里的第10个字符开始，截取8个字符结束.\\ substr($3,6) ---&gt; 表示是从第3个字段里的第6个字符开始，一直到结尾 length 字符串长度length函数返回没有参数的字符串的长度。length函数返回整个记录中的字符数。1echo &quot;123&quot; | awk &apos;&#123;print length&#125;&apos; gsub函数gsub函数则使得在所有正则表达式被匹配的时候都发生替换。gsub(regular expression, subsitution string, target string);简称gsub（r,s,t) 举例：把一个文件里面所有包含 abc 的行里面的 abc 替换成 def，然后输出第一列和第三列 1awk &apos;$0 ~ /abc/ &#123;gsub(&quot;abc&quot;, &quot;def&quot;, $0); print $1, $3&#125;&apos; abc.txt]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS6.5部署Cobbler(使用)]]></title>
      <url>http://czero000.github.io/2015/11/11/use-cobbler-centos6.5.html</url>
      <content type="text"><![CDATA[本篇接上篇文章，继续介绍 cobbler 的使用方法。 RedHat/CentOS导入CentOS6.5 ISO 镜像1mount -t auto -o loop CentOS-6.5-x86_64-bin-DVD1.iso /mnt/ 导入 ISO 镜像由于 CentOS 镜像信息较多，所以导入的时候，会同时创建 distro，profile，并且还会设置 repo，不过这个 repo只包含 DVD1，如果想要包含 DVD2，还需要做设置。12345678910111213141516171819cobbler import --path=/mnt --name=CentOS6.5 --arch=x86_64task started: 2014-11-19_175649_importtask started (id=Media import, time=Wed Nov 19 17:56:49 2014)Found a candidate signature: breed=redhat, version=rhel6Found a matching signature: breed=redhat, version=rhel6Adding distros from path /var/www/cobbler/ks_mirror/CenOS6.5-x86_64:creating new distro: CenOS6.5-x86_64trying symlink: /var/www/cobbler/ks_mirror/CenOS6.5-x86_64 -&gt; /var/www/cobbler/links/CenOS6.5-x86_64creating new profile: CenOS6.5-x86_64associating reposchecking for rsync repo(s)checking for rhn repo(s)checking for yum repo(s)starting descent into /var/www/cobbler/ks_mirror/CenOS6.5-x86_64 for CenOS6.5-x86_64processing repo at : /var/www/cobbler/ks_mirror/CenOS6.5-x86_64need to process repo/comps: /var/www/cobbler/ks_mirror/CenOS6.5-x86_64looking for /var/www/cobbler/ks_mirror/CenOS6.5-x86_64/repodata/*comps*.xmlKeeping repodata as-is :/var/www/cobbler/ks_mirror/CenOS6.5-x86_64/repodata*** TASK COMPLETE *** 在profile文件中设置Kickstart文件profile文件中默认采用/var/lib/cobbler/kickstarts/sample.ks作为ks文件。可以指定自己之前的ks文件也可以改这个文件来用修改profile文件中ks可以用几种方法： 直接修改profile文件 1vim /var/lib/cobbler/config/profiles.d/CentOS6.5-x86_64.json 通过命令行修改profile文件 1cobbler profile edit --name=CentOS6.5-x86_64 --kickstart=/data/htdocs/kscfg/ks.cfg-CentOS6.5-x86_64 通过Web界面修改profile文件 修改之后，可以通过下面命令来查看自己修改的信息123456789101112131415161718192021222324252627282930313233cobbler profile report Name : CentOS6.5-x86_64TFTP Boot Files : &#123;&#125;Comment : DHCP Tag : defaultDistribution : CentOS6.5-x86_64Enable gPXE? : 0Enable PXE Menu? : 1Fetchable Files : &#123;&#125;Kernel Options : &#123;&#125;Kernel Options (Post Install) : &#123;&#125;Kickstart : /data/htdocs/kscfg/ks.cfg-CentOS6.5-x86_64Kickstart Metadata : &#123;&#125;Management Classes : []Management Parameters : &lt;&gt;Name Servers : []Name Servers Search Path : []Owners : [&apos;admin&apos;]Parent Profile : Proxy : Red Hat Management Key : &lt;&gt;Red Hat Management Server : &lt;&gt;Repos : []Server Override : &lt;&gt;Template Files : &#123;&#125;Virt Auto Boot : 1Virt Bridge : xenbr0Virt CPUs : 1Virt Disk Driver Type : rawVirt File Size(GB) : 5Virt Path : Virt RAM (MB) : 512Virt Type : kvm 添加一个SystemIPMI地址为10.10.3.157 user：root pass：superuser 1234567891011121314cobbler system add \&gt; --name=ssq-54-157 \&gt; --hostname=ssq-54-157 \&gt; --dns-name=ssq-54-157 \&gt; --profile=CentOS6.5-x86_64 \&gt; --interface=eth1 \&gt; --mac=00:E0:81:B9:5A:B6 \&gt; --ip-address=172.16.6.157 \&gt; --netmask=255.255.255.0 \&gt; --static=1 \&gt; --power-type=ipmilan \&gt; --power-user=root \&gt; --power-pass=superuser \&gt; --power-address=10.10.3.157 由于Cobbler不能支持同时配置两块网卡，所以要分为两步。 1cobbler system edit --name=ssq-54-157 --interface=eth0 --mac=00:e0:81:b9:5a:b5 --ip-address=10.10.54.157 --netmask=255.255.255.0 --static=1 --gateway=10.10.54.1 这些都可以在Web中完成，只不过比较繁琐，还是命令行更加方便Cobbler所有设置和修改，都需要通过cobbler sync 来生效，让我们查看以下刚才添加的System1cobbler system report --name=ssq-54-157 需要留意的一个参数是：netboot-enabled，当Cobbler安装完OS后，这个参数就换自动变为0，如果希望重新安装，就需要变成11cobbler system edit --name=ssq-54-157 --netboot-enabled=ture 安装客户端：设置远程机器有pxe启动：1ipmitool -H 10.10.3.157 -Uroot -Psuperuser chassis bootdev pxe 重启远程服务器，可以有两种方法：12345678910111213141516171819202122ipmitool -H 10.10.3.157 -Uroot -Psuperuser power resetcobbler system reboot --name=ssq-54-157 task started: 2014-11-20_142114_powertask started (id=Power management (reboot), time=Thu Nov 20 14:21:14 2014)cobbler power configuration is: type : ipmilan address: 10.10.3.157 user : root id : running: /usr/sbin/fence_ipmilanreceived on stdout: Powering off machine @ IPMI:10.10.3.157...Donereceived on stderr: cobbler power configuration is: type : ipmilan address: 10.10.3.157 user : root id : running: /usr/sbin/fence_ipmilanreceived on stdout: Powering on machine @ IPMI:10.10.3.157...Donereceived on stderr: *** TASK COMPLETE *** 添加epel源到Cobbler命令行如下操作，添加epel和epel-test的repo源123cobbler repo add --mirror=http://mirrors.yun-idc.com/epel/6Server/x86_64/ --name=epel6-x86_64 --breed=yumcobbler repo add --mirror=http://mirrors.sohu.com/fedora-epel/testing/6/x86_64/ --name=epel6-x86_64-testing --breed=yumcobbler repo add --mirror=http://172.16.8.32/centos/6/os/x86_64/Packages/ --name=Local_CentOS6.5_x86_64 --breed=yum 这个只对CentOS有效，如果把repo加到profile中，他会自动添加到节点的repo上，指向内网非常方便1cobbler profile edit --name=CentOS6.5-x86_64 --repos=&quot;epel6-x86_64 epel6-x86_64-testing&quot; 通过koan重装系统重新安装节点的系统，可以在Cobbler上设置，无论是在Web还是命令行，其实还有一种选择，就是直接在节点上进行 koan：Kickstart Over A Network。就可以实现这个 1yum install -y koan koan命令的使用方法，非常简单可以查看man文档123koan --server=10.10.3.64 --list=systems- looking for Cobbler at http://10.10.3.64/cobbler_apissq-54-157 当然还可以看其他信息，Systems、Profiles12345678910111213141516171819koan --server=10.10.3.64 --display --system=ssq-54-157- looking for Cobbler at http://10.10.3.64/cobbler_api- reading URL: http://10.10.3.64/cblr/svc/op/ks/system/ssq-54-157install_tree: http://10.10.3.64/cblr/links/CentOS6.5-x86_64 name : ssq-54-157 distro : CentOS6.5-x86_64 profile : CentOS6.5-x86_64 kickstart : http://10.10.3.64/cblr/svc/op/ks/system/ssq-54-157 ks_meta : tree=http://@@http_server@@/cblr/links/CentOS6.5-x86_64 install_tree : http://10.10.3.64/cblr/links/CentOS6.5-x86_64 kernel : /var/www/cobbler/ks_mirror/CentOS6.5-x86_64/images/pxeboot/vmlinuz initrd : /var/www/cobbler/ks_mirror/CentOS6.5-x86_64/images/pxeboot/initrd.img netboot_enabled : False kernel_options : ks=http://10.10.3.64/cblr/svc/op/ks/system/ssq-54-157 ksdevice=eth1 kssendmac lang= text repos : epel6-x86_64 virt_ram : 512 virt_type : xenpv virt_path : virt_auto_boot : 0 重装系统就可以使用下面命令，当然也可以指定Profil1koan --server=10.10.3.64 --system=ssq-54-157 --replace-self 这个时候，重启系统，不需要指定PXE启动，他就会自动安装系统。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS6.5部署Cobbler(安装)]]></title>
      <url>http://czero000.github.io/2015/11/11/centos6.5-install-cobbler.html</url>
      <content type="text"><![CDATA[Cobbler 介绍Cobbler 是一个快速网络安装 linux 的服务，而且在经过调整也可以支持安装 windows。该工具使用 python 开发，小巧轻便，使用简单的命令即可完成 PXE 网络安装环境的配置，同时还可以管理 DHCP、DNS，以及 yum 包镜像。Cobbler 支持命令行管理、web 界面管理，还提供了 API 接口，方便二次开发。和 kickstart 不同的是，使用Cobbler不会因为在局域网中启用 DHCP 而导致有些机器因为默认从 PXE 启动在重启服务器后加载 tftp 内容导致启动终止. 系统环境准备系统环境CentOS release 6.5 (Final) x86_64 软件包软件包采用 yum 安装方式，yum 源采用自建的 yum 源 安装 Cobbler安装 cobbler 相关软件包1yum install -y cobbler cobbler-web pykickstart fence-agents 安装 debmirror（需要用 debmirror 来下载 ubuntu 源，用于本地安装）1yum install -y debmirror 配置 Cobbler设置 tftp 服务和 rsync 服务1234sed -i &apos;/disable/c\\tdisable\t\t\t= no&apos; /etc/xinetd.d/tftpsed -i -e &apos;s/\=\ yes/\=\ no/g&apos; /etc/xinetd.d/rsync /etc/init.d/xinetd restartchkconfig --level 3 xinetd on 设置 Web 登录1sed -i &apos;s/authn_denyall/authn_configfile/g&apos; /etc/cobbler/modules.conf 之前版本都是需要更改认证设置，但是2.6版本默认就是这样设置 设置 Cobbler Web 登录用户登录密码1234htdigest /etc/cobbler/users.digest &quot;Cobbler&quot; cobblerChanging password for user cobbler in realm CobblerNew password: Re-type new password: 设置 Cobbler 登录服务器地址1sed -i &apos;/^server: /s/server: 127.0.0.1/server: 10.10.3.64/g&apos; /etc/cobbler/settings ks 脚本关闭 pxe，这样就不会重复安装 pxe_just_once 预防由于服务器设置从网络引导，导致循环安装，激活此设置，机器会告诉 Cobbler 安装也完成。Cobbler 会将对象的 netboot 标志改为 false，这会强制服务器从本地引导。1sed -i &apos;s/pxe_just_once: 0/pxe_just_once: 1/g&apos; /etc/cobbler/settings 设置 TFTP 服务器 IP 地址1sed -i &apos;s/next_server: 127.0.0.1/next_server: 10.10.3.64/g&apos; /etc/cobbler/settings 设置 Cobbler 管理 rsync1sed -i &apos;s/manage_rsync: 0/manage_rsync: 1/g&apos; /etc/cobbler/settings 设置 Cobbler 管理 DHCP1sed -i &apos;s/manage_dhcp: 0/manage_dhcp: 1/g&apos; /etc/cobbler/settings DHCP 服务由 Cobbler 来管理， /etc/cobbler/dhcp.template.1234567891011121314151617181920212223242526272829303132ddns-update-style interim;allow booting;allow bootp;ignore client-updates;set vendorclass = option vendor-class-identifier;option pxe-system-type code 93 = unsigned integer 16;subnet 10.10.3.0 netmask 255.255.255.0 &#123; option routers 10.10.3.64; option domain-name-servers 10.10.3.64; option subnet-mask 255.255.255.0; range dynamic-bootp 10.10.3.168 10.10.3.191; default-lease-time 21600; max-lease-time 43200; next-server $next_server; class &quot;pxeclients&quot; &#123; match if substring (option vendor-class-identifier, 0, 9) = &quot;PXEClient&quot;; if option pxe-system-type = 00:02 &#123; filename &quot;ia64/elilo.efi&quot;; &#125; else if option pxe-system-type = 00:06 &#123; filename &quot;grub/grub-x86.efi&quot;; &#125; else if option pxe-system-type = 00:07 &#123; filename &quot;grub/grub-x86_64.efi&quot;; &#125; else &#123; filename &quot;pxelinux.0&quot;; &#125; &#125;&#125; 设置 Cobbler 管理 DNS（可选）1sed -i &apos;s/manage_dns: 0/manage_dns: 1/g&apos; /etc/cobbler/settings 设置 root 默认密码这个设置只对 CentOS/RHEL 有效1openssl passwd -1 -salt &apos;random-phrase-here&apos; &apos;your-password-here&apos; 修改/etc/cobbler/settings1default_password_crypted: &quot;$1$mF86/UHC$WvcIcX2t6crBz2onWxyac.&quot; 启动相关服务1234/etc/init.d/cobblerd start/etc/init.d/httpd startchkconfig httpd onchkconfig cobblerd on 设置 debmirror12sed -i -e &apos;s/@dists=/#@dists=/g&apos; /etc/debmirror.confsed -i -e &apos;s/@arches=/#@arches=/g&apos; /etc/debmirror.conf 开启动态更新1sed -i &apos;s/allow_dynamic_settings: 0/allow_dynamic_settings: 1/g&apos; /etc/cobbler/settings 下载启动菜单1cobbler get-loaders 检查 Cobbler “cobbler check”Cobbler 提供了一个检查工具，检查你的设置，有问题会提示给你。按照提示去修复问题12cobbler check No configuration problems found. All systems go. 命令行查看、修改 setting 文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106cobbler setting report allow_duplicate_hostnames : 0allow_duplicate_ips : 0allow_duplicate_macs : 0allow_dynamic_settings : 1always_write_dhcp_entries : 0anamon_enabled : 0auth_token_expiration : 3600authn_pam_service : loginbind_chroot_path : bind_master : 127.0.0.1build_reporting_email : [&apos;root@localhost&apos;]build_reporting_enabled : 0build_reporting_ignorelist : [&apos;&apos;]build_reporting_sender : build_reporting_smtp_server : localhostbuild_reporting_subject : build_reporting_to_address : buildisodir : /var/cache/cobbler/buildisocheetah_import_whitelist : [&apos;random&apos;, &apos;re&apos;, &apos;time&apos;]client_use_https : 0client_use_localhost : 0cobbler_master : consoles : /var/consolescreaterepo_flags : -c cache -s shadefault_deployment_method : sshdefault_kickstart : /var/lib/cobbler/kickstarts/default.ksdefault_name_servers : []default_name_servers_search : []default_ownership : [&apos;admin&apos;]default_password_crypted : $1$7NQM/hse$Uh9IBVPme4E1E3dTo3kH/1default_template_type : cheetahdefault_virt_bridge : xenbr0default_virt_disk_driver : rawdefault_virt_file_size : 5default_virt_ram : 512default_virt_type : xenpvenable_gpxe : 0enable_menu : 1func_auto_setup : 0func_master : overlord.example.orghttp_port : 80isc_set_host_name : 0iso_template_dir : /etc/cobbler/isokerberos_realm : EXAMPLE.COMkernel_options : &#123;&apos;ksdevice&apos;: &apos;eth1&apos;, &apos;lang&apos;: &apos; &apos;, &apos;text&apos;: &apos;~&apos;&#125;kernel_options_s390x : &#123;&apos;vnc&apos;: &apos;~&apos;, &apos;ip&apos;: False, &apos;RUNKS&apos;: 1, &apos;ramdisk_size&apos;: 40000, &apos;ro&apos;: &apos;~&apos;, &apos;root&apos;: &apos;/dev/ram0&apos;&#125;ldap_anonymous_bind : 1ldap_base_dn : DC=example,DC=comldap_management_default_type : authconfigldap_port : 389ldap_search_bind_dn : ldap_search_passwd : ldap_search_prefix : uid=ldap_server : ldap.example.comldap_tls : 1ldap_tls_cacertfile : ldap_tls_certfile : ldap_tls_keyfile : manage_dhcp : 1manage_dns : 0manage_forward_zones : []manage_reverse_zones : []manage_rsync : 1manage_tftp : 1manage_tftpd : 1mgmt_classes : []mgmt_parameters : &#123;&apos;from_cobbler&apos;: 1&#125;next_server : 10.10.3.64power_management_default_type : ipmitoolpower_template_dir : /etc/cobbler/powerpuppet_auto_setup : 0puppet_parameterized_classes : 1puppet_server : puppetpuppet_version : 2puppetca_path : /usr/bin/puppetpxe_just_once : 1pxe_template_dir : /etc/cobbler/pxeredhat_management_key : redhat_management_permissive : 0redhat_management_server : xmlrpc.rhn.redhat.comredhat_management_type : offregister_new_installs : 0remove_old_puppet_certs_automatically : 0replicate_repo_rsync_options : -avzHreplicate_rsync_options : -avzHreposync_flags : -l -n -drestart_dhcp : 1restart_dns : 1restart_xinetd : 1run_install_triggers : 1scm_track_enabled : 0scm_track_mode : gitserializer_pretty_json : 0server : 10.10.3.64sign_puppet_certs_automatically : 0signature_path : /var/lib/cobbler/distro_signatures.jsonsignature_url : http://www.cobblerd.org/signatures/latest.jsonsnippetsdir : /var/lib/cobbler/snippetstemplate_remote_kickstarts : 0virt_auto_boot : 1webdir : /var/www/cobblerxmlrpc_port : 25151yum_distro_priority : 1yum_post_install_mirror : 1yumdownloader_flags : --resolv 通过命令行编辑setting1cobbler setting edit --name=option --value=value Web 登录访问http://10.10.3.64/cobbler_web用户密码就是上面设置的 Cobbler 的使用，主要集中在 Web 界面的几个菜单里： Distros：这个其实就是发行版，类似 CentOS、Ubuntu、SUSE。CenOS6.2 和Centos6.5，是不同的Distros Porfiles：针对 Distors 设置的，一个 Distros 可以对应多个 Profiles，包括不同的 kickstart 文件。 Systems：针对每个节点，可以指定节点IP地址，DNS、还有就是ipmi的用户和密码，实现远程开机关机。这个是个重点，对机器的操作可以全部在System的菜单里实现。System可以指定节点使用那个Profile Repos：针对 Redhat和CentOS，可以管理源，并且这些源可以在profile里面添加。对ubuntu的源，只能在kickstart脚本里指定 Images：针对不能pxe的服务器，采用ISO启动 Kickstart Templates：Cobbler内置了几个KS文件模版，导入一个Distros，Cobbler 会默认关联一个KS文件。不需要任何设置，就可以把os自动安装完毕 Snippets：这个是Cobbler的精华。一些常用的设置，写成一个模块，让ks文件来调用，方便灵活。例如CentOS网络固定IP地址的设置，就是通过这里来实现 设置Apache根目录访问希望直接访问ip地址，就可以看到源的目录，尤其对与ubuntu来说，这样这样看起来更加规范12345678910111213cat /etc/httpd/conf.d/welcome.conf # # This configuration file enables the default &quot;Welcome&quot;# page if there is no default index page present for# the root URL. To disable the Welcome page, comment# out all the lines below.# &lt;LocationMatch &quot;^/+$&quot;&gt; Options Indexes FollowSymLinks Order allow,deny Allow from all &lt;/LocationMatch&gt; 重启apache，登录http://10.10.3.64看到的目录，实际就是/var/www/html 安装常见问题校验cobbler check出错12345678910111213141516171819cobbler checkTraceback (most recent call last): File &quot;/usr/bin/cobbler&quot;, line 36, in sys.exit(app.main()) File &quot;/usr/lib/python2.6/site-packages/cobbler/cli.py&quot;, line 655, in main rc = cli.run(sys.argv) File &quot;/usr/lib/python2.6/site-packages/cobbler/cli.py&quot;, line 270, in run self.token = self.remote.login(&quot;&quot;, self.shared_secret) File &quot;/usr/lib/python2.6/xmlrpclib.py&quot;, line 1199, in __call__ return self.__send(self.__name, args) File &quot;/usr/lib/python2.6/xmlrpclib.py&quot;, line 1489, in __request verbose=self.__verbose File &quot;/usr/lib/python2.6/xmlrpclib.py&quot;, line 1253, in request return self._parse_response(h.getfile(), sock) File &quot;/usr/lib/python2.6/xmlrpclib.py&quot;, line 1392, in _parse_response return u.close() File &quot;/usr/lib/python2.6/xmlrpclib.py&quot;, line 838, in close raise Fault(**self._stack[0])xmlrpclib.Fault: :&apos;login failed&apos;&quot;&gt; 解决方法：此为BUG，按照下面方法即可12etc/init.d/cobblerd restartcobbler get-loaders]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[通过Logstash-Forwarder传输数据]]></title>
      <url>http://czero000.github.io/2015/10/22/logstash-forwarder-transmission.html</url>
      <content type="text"><![CDATA[logstash 作为无状态的软件，配合消息队列系统，可以很轻松的做到线性扩,Redis 已经帮我们解决了很多的问题，而且也很轻量，为什么我们还需要 logstash-forwarder 呢? 简而言之它很好，但是它不安全。下面开始配置Logstash-forwarder Redis provides simple authentication but no transport-layer encryption or authorization. This is perfectly fine in trusted environments. However, if you’re connecting to Redis between datacenters you will probably want to use encryption. 简而言之它很好，但是它不安全。下面开始配置Logstash-forwarder indexer端配置在logstash作为index server角色这端，首先要生成证书：12cd /etc/pki/tls/openssl req -subj &apos;/CN=elk.mydomain.com/&apos; -x509 -days 3650 -batch -nodes -newkey rsa:2048 -keyout private/logstash-forwarder.key -out certs/logstash-forwarder.crt 如果按照官方文档操作，logstsh-forwarder会报错:Failure connecting to 172.16.11.230: dial tcp elk.mydomain.com:5000: connection refused，为了避免报错，这里比官方的增加了 “ -subj ‘/CN=elk.mydomain.com/‘“。 然后把证书发送到logstash-forwarder的shipper端服务器上：12scp private/logstash-forwarder.key 172.16.11.175:/etc/pki/tls/private scp certs/logstash-forwarder.crt 172.16.11.175:/etc/pki/tls/certs 创建logstash的配置文件： I’m a lumberjack and I’m ok! I sleep when idle, then I ship logs all day! I parse your logs, I eat the JVM agent for lunch! ♫ 1234567891011121314151617181920212223242526input &#123; lumberjack &#123; port =&gt; 5000 type =&gt; &quot;syslog&quot; ssl_certificate =&gt; &quot;/etc/pki/tls/certs/logstash-forwarder.crt&quot; ssl_key =&gt; &quot;/etc/pki/tls/private/logstash-forwarder.key&quot; &#125;&#125;filter &#123; if [type] == &quot;syslog&quot; &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;SYSLOGTIMESTAMP:syslog_timestamp&#125; %&#123;SYSLOGHOST:syslog_hostname&#125; %&#123;DATA:syslog_program&#125;(?:\[%&#123;POSINT:syslog_pid&#125;\])?: %&#123;GREEDYDATA:syslog_message&#125;&quot; &#125; add_field =&gt; [ &quot;received_at&quot;, &quot;%&#123;@timestamp&#125;&quot; ] add_field =&gt; [ &quot;received_from&quot;, &quot;%&#123;host&#125;&quot; ] &#125; syslog_pri &#123; &#125; date &#123; match =&gt; [ &quot;syslog_timestamp&quot;, &quot;MMM d HH:mm:ss&quot;, &quot;MMM dd HH:mm:ss&quot; ] &#125; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125; 这样，logstash index端已经配置完 lumberjack 是 logstash-forwarder 还没用 Golang 重写之前的名字 默认安装的logstash会报错：&quot;The error reported is: uninitialized constant Concurrent::D elay::Executor&quot;，需要更新logstash-input-lumberjack这个插件（国内需要变更更gem 安装的源为http://ruby.taobao.org） shipper端安装先安装logstash-forwarder软件。12wget http://download.elastic.co/logstash-forwarder/binaries/logstash-forwarder-0.4.0-1.x86_64.rpmrpm -ivh logstash-forwarder-0.4.0-1.x86_64.rpm 配置logstash-forwarderlogstash-frowarder的配置文件是纯JSON格式。配置如下：123456789101112131415161718cat /etc/logstash-forwarder.conf&#123; &quot;network&quot;: &#123; &quot;servers&quot;: [ &quot;elk.mydomain.com:5000&quot; ], &quot;timeout&quot;: 15, &quot;ssl ca&quot; : &quot;/etc/pki/tls/certs/logstash-forwarder.crt&quot;, &quot;ssl key&quot;: &quot;/etc/pki/tls/private/logstash-forwarder.key&quot; &#125;, &quot;files&quot;: [ &#123; &quot;paths&quot;: [ &quot;/var/log/message&quot;, &quot;/var/log/secure&quot; ], &quot;fields&quot;: &#123; &quot;type&quot;: &quot;syslog&quot; &#125; &#125; ]&#125; 这样就可以在index端接受到数据，在通过kibana将数据可视化]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx--日志轮滚]]></title>
      <url>http://czero000.github.io/2015/10/21/nginx-logrotate.html</url>
      <content type="text"><![CDATA[Nginx 默认不支持日志轮滚，通过下面方法解决 脚本方式12345678910#!/bin/bash log_dir=&apos;/usr/local/nginx/logs&apos; nginx_pid=&apos;/usr/local/nginx/logs/nginx.pid&apos;date_yesterday=`date -d &quot;yesterday&quot; +%Y%m%d`for logfile in `ls $log_dir/*.log | awk -F&apos;/&apos; &apos;&#123;print $6&#125;&apos;` do mv $log_dir/$logfile $log_dir/$&#123;logfile&#125;_$&#123;date_yesterday&#125; donefind $log_dir -ctime +15 | xargs rm -fkill -USR1 `ps axu | grep &quot;nginx: master process&quot; | grep -v grep | awk &apos;&#123;print $2&#125;&apos;` 系统 logrotate12345678910111213141516171819cat /etc/logrotate.d/nginx/usr/local/nginx/logs/*.log &#123; daily missingok rotate 99 compress delaycompress notifempty create 640 nobody nobody sharedscripts prerotate sleep 59 endscript postrotate if [ -f /usr/local/nginx/logs/nginx.pid ]; then kill -USR1 `cat /usr/local/nginx/logs/nginx.pid` fi endscript&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx代码高亮]]></title>
      <url>http://czero000.github.io/2015/10/21/vim-nginx-hight-light.html</url>
      <content type="text"><![CDATA[配置Vim 支持Nginx 配置文件高亮显示 下载 Nginx 配置文件的 Vim 语法高亮：http://www.vim.org/scripts/script.php?script_id=1886 将下载的nginx.vim复制到~/.vim/syntax/文件夹下，并且在~/.vim/filetype.vim文件中 echo &quot;au BufRead,BufNewFile /usr/local/nginx/* set ft=nginx&quot; &gt;&gt; /root/.vim/filetype.vim 配置Vim的Nginx配置文件语法高亮的脚本，写成脚本，免得每次都手动配置。1234#!/bin/bash[[ -d ~/.vim/syntax ]] || mkdir -p ~/.vim/syntaxwget http://www.vim.org/scripts/download_script.php?src_id=19394 -O ~/.vim/syntaxnginx.vim/echo &quot;au BufRead,BufNewFile /usr/local/nginx/* set ft=nginx&quot; &gt;&gt; ~/.vim/filetype.vim nginx.vim文件下载链接]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx INIT启动脚本]]></title>
      <url>http://czero000.github.io/2015/10/21/nginx-init-scripts.html</url>
      <content type="text"><![CDATA[nginx服务自启动脚本 CentOS/RHEL 5、6系列 脚本内容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#!/bin/bash## nginx - this script starts and stops the nginx daemin## chkconfig: - 85 15# description: Nginx is an HTTP(S) server, HTTP(S) reverse# proxy and IMAP/POP3 proxy server# processname: nginx# config: /usr/local/nginx/conf/nginx.conf# pidfile: /usr/local/nginx/logs/nginx.pid# Source function library.. /etc/rc.d/init.d/functions# Source networking configuration.. /etc/sysconfig/network# Check that networking is up.[ &quot;$NETWORKING&quot; = &quot;no&quot; ] &amp;&amp; exit 0nginx=&quot;/usr/local/nginx/sbin/nginx&quot;prog=$(basename $nginx)NGINX_CONF_FILE=&quot;/usr/local/nginx/conf/nginx.conf&quot;lockfile=/var/lock/subsys/nginxstart() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 echo -n $&quot;Starting $prog: &quot; daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125;stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125;restart() &#123; configtest || return $? stop start&#125;reload() &#123; configtest || return $? echo -n $&quot;Reloading $prog: &quot; killproc $nginx -HUP RETVAL=$? echo&#125;force_reload() &#123; restart&#125;configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125;rh_status() &#123; status $prog&#125;rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125;case &quot;$1&quot; in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;&quot; exit 2esac 在Centos7 或者 相应的Ubuntu版本中添加如下内容1234567891011121314vim /lib/systemd/system/nginx.service [Unit] Description=nginx After=network.target [Service] Type=forking ExecStart=/etc/init.d/nginx start ExecReload=/etc/init.d/nginx restart ExecStop=/etc/init.d/nginx stop PrivateTmp=true [Install] WantedBy=multi-user.target 12345678910111213141516171819202122232425262728# Stop dance for nginx# =======================## ExecStop sends SIGSTOP (graceful stop) to the nginx process.# If, after 5s (--retry QUIT/5) nginx is still running, systemd takes control# and sends SIGTERM (fast shutdown) to the main process.# After another 5s (TimeoutStopSec=5), and if nginx is alive, systemd sends# SIGKILL to all the remaining processes in the process group (KillMode=mixed).## nginx signals reference doc:# http://nginx.org/en/docs/control.html#[Unit]Description=A high performance web server and a reverse proxy serverAfter=network.target[Service]Type=forkingPIDFile=/usr/local/nginx/logs/nginx.pidExecStartPre=/usr/local/nginx/sbin/nginx -t -q -g &apos;daemon on; master_process on;&apos;ExecStart=/usr/local/nginx/sbin/nginx -g &apos;daemon on; master_process on;&apos;ExecReload=/usr/local/nginx/sbin/nginx -g &apos;daemon on; master_process on;&apos; -s reloadExecStop=-/sbin/start-stop-daemon --quiet --stop --retry QUIT/5 --pidfile /usr/local/nginx/logs/nginx.pidTimeoutStopSec=5KillMode=mixed[Install]WantedBy=multi-user.target Ubuntu 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365#! /bin/sh### BEGIN INIT INFO# Provides: nginx# Required-Start: $remote_fs $syslog# Required-Stop: $remote_fs $syslog# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: nginx init.d dash script for Ubuntu or other *nix.# Description: nginx init.d dash script for Ubuntu or other *nix.### END INIT INFO #------------------------------------------------------------------------------# nginx - this Debian Almquist shell (dash) script, starts and stops the nginx# daemon for Ubuntu and other *nix releases.## description: Nginx is an HTTP(S) server, HTTP(S) reverse \# proxy and IMAP/POP3 proxy server. This \# script will manage the initiation of the \# server and it&apos;s process state.## processname: nginx# config: /usr/local/nginx/conf/nginx.conf# pidfile: /usr/local/nginx/logs/nginx.pid# Provides: nginx## Author: Jason Giedymin# &lt;jason.giedymin AT gmail.com&gt;.## Version: 3.5.1 11-NOV-2013 jason.giedymin AT gmail.com# Notes: nginx init.d dash script for Ubuntu.# Tested with: Ubuntu 13.10, nginx-1.4.3## This script&apos;s project home is:# [url]http://github.com/JasonGiedymin/nginx-init-ubuntu[/url]##------------------------------------------------------------------------------# MIT X11 License#------------------------------------------------------------------------------## Copyright (c) 2008-2013 Jason Giedymin, [url]http://jasongiedymin.com[/url]## Permission is hereby granted, free of charge, to any person obtaining# a copy of this software and associated documentation files (the# &quot;Software&quot;), to deal in the Software without restriction, including# without limitation the rights to use, copy, modify, merge, publish,# distribute, sublicense, and/or sell copies of the Software, and to# permit persons to whom the Software is furnished to do so, subject to# the following conditions:## The above copyright notice and this permission notice shall be# included in all copies or substantial portions of the Software.## THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND,# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE# LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.#------------------------------------------------------------------------------#------------------------------------------------------------------------------# Functions#------------------------------------------------------------------------------LSB_FUNC=/lib/lsb/init-functions# Test that init functions existstest -r $LSB_FUNC || &#123; echo &quot;$0: Cannot find $LSB_FUNC! Script exiting.&quot; 1&gt;&amp;2 exit 5&#125;. $LSB_FUNC#------------------------------------------------------------------------------# Consts#------------------------------------------------------------------------------PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/binDAEMON=/usr/local/nginx/sbin/nginxPS=&quot;nginx&quot;PIDNAME=&quot;nginx&quot; #lets you do $PS-slavePIDFILE=$PIDNAME.pid #pid filePIDSPATH=/usr/local/nginx/logs #default pid location, you should change itDESCRIPTION=&quot;Nginx Server...&quot;RUNAS=root #user to run asSCRIPT_OK=0 #ala error codesSCRIPT_ERROR=1 #ala error codesTRUE=1 #booleanFALSE=0 #booleanlockfile=/var/lock/subsys/nginxNGINX_CONF_FILE=&quot;/usr/local/nginx/conf/nginx.conf&quot;#------------------------------------------------------------------------------# Simple Tests#------------------------------------------------------------------------------# Test if nginx is a file and executabletest -x $DAEMON || &#123; echo &quot;$0: You don&apos;t have permissions to execute nginx.&quot; 1&gt;&amp;2 exit 4&#125;# Include nginx defaults if availableif [ -f /etc/default/nginx ]; then . /etc/default/nginxfi#set exit condition#set -e#------------------------------------------------------------------------------# Functions#------------------------------------------------------------------------------setFilePerms()&#123; if [ -f $PIDSPATH/$PIDFILE ]; then chmod 400 $PIDSPATH/$PIDFILE fi&#125;configtest() &#123; $DAEMON -t -c $NGINX_CONF_FILE&#125;getPSCount() &#123; return `pgrep -f $PS | wc -l`&#125;isRunning() &#123; if [ $1 ]; then pidof_daemon $1 PID=$? if [ $PID -gt 0 ]; then return 1 else return 0 fi else pidof_daemon PID=$? if [ $PID -gt 0 ]; then return 1 else return 0 fi fi&#125; #courtesy of php-fpmwait_for_pid () &#123; try=0 while test $try -lt 35 ; do case &quot;$1&quot; in &apos;created&apos;) if [ -f &quot;$2&quot; ]; then try=&apos;&apos; break fi ;; &apos;removed&apos;) if [ ! -f &quot;$2&quot; ]; then try=&apos;&apos; break fi ;; esac try=`expr $try + 1` sleep 1 done&#125;status()&#123; isRunning isAlive=$? if [ &quot;$&#123;isAlive&#125;&quot; -eq $TRUE ]; then log_warning_msg &quot;$DESCRIPTION found running with processes: `pidof $PS`&quot; rc=0 else log_warning_msg &quot;$DESCRIPTION is NOT running.&quot; rc=3 fi return&#125;removePIDFile()&#123; if [ $1 ]; then if [ -f $1 ]; then rm -f $1 fi else #Do default removal if [ -f $PIDSPATH/$PIDFILE ]; then rm -f $PIDSPATH/$PIDFILE fi fi&#125;start() &#123; log_daemon_msg &quot;Starting $DESCRIPTION&quot; isRunning isAlive=$? if [ &quot;$&#123;isAlive&#125;&quot; -eq $TRUE ]; then log_end_msg $SCRIPT_ERROR rc=0 else start-stop-daemon --start --quiet --chuid \ $RUNAS --pidfile $PIDSPATH/$PIDFILE --exec $DAEMON \ -- -c $NGINX_CONF_FILE setFilePerms log_end_msg $SCRIPT_OK rc=0 fi return&#125;stop() &#123; log_daemon_msg &quot;Stopping $DESCRIPTION&quot; isRunning isAlive=$? if [ &quot;$&#123;isAlive&#125;&quot; -eq $TRUE ]; then start-stop-daemon --stop --quiet --pidfile $PIDSPATH/$PIDFILE wait_for_pid &apos;removed&apos; $PIDSPATH/$PIDFILE if [ -n &quot;$try&quot; ]; then log_end_msg $SCRIPT_ERROR rc=0 # lsb states 1, but under status it is 2 (which is more prescriptive). Deferring to standard. else removePIDFile log_end_msg $SCRIPT_OK rc=0 fi else log_end_msg $SCRIPT_ERROR rc=7 fi return&#125;reload() &#123; configtest || return $? log_daemon_msg &quot;Reloading (via HUP) $DESCRIPTION&quot; isRunning if [ $? -eq $TRUE ]; then kill -HUP `cat $PIDSPATH/$PIDFILE` log_end_msg $SCRIPT_OK rc=0 else log_end_msg $SCRIPT_ERROR rc=7 fi return&#125;quietupgrade() &#123; log_daemon_msg &quot;Peforming Quiet Upgrade $DESCRIPTION&quot; isRunning isAlive=$? if [ &quot;$&#123;isAlive&#125;&quot; -eq $TRUE ]; then kill -USR2 `cat $PIDSPATH/$PIDFILE` kill -WINCH `cat $PIDSPATH/$PIDFILE.oldbin` isRunning isAlive=$? if [ &quot;$&#123;isAlive&#125;&quot; -eq $TRUE ]; then kill -QUIT `cat $PIDSPATH/$PIDFILE.oldbin` wait_for_pid &apos;removed&apos; $PIDSPATH/$PIDFILE.oldbin removePIDFile $PIDSPATH/$PIDFILE.oldbin log_end_msg $SCRIPT_OK rc=0 else log_end_msg $SCRIPT_ERROR log_daemon_msg &quot;ERROR! Reverting back to original $DESCRIPTION&quot; kill -HUP `cat $PIDSPATH/$PIDFILE` kill -TERM `cat $PIDSPATH/$PIDFILE.oldbin` kill -QUIT `cat $PIDSPATH/$PIDFILE.oldbin` wait_for_pid &apos;removed&apos; $PIDSPATH/$PIDFILE.oldbin removePIDFile $PIDSPATH/$PIDFILE.oldbin log_end_msg $SCRIPT_OK rc=0 fi else log_end_msg $SCRIPT_ERROR rc=7 fi return&#125;terminate() &#123; log_daemon_msg &quot;Force terminating (via KILL) $DESCRIPTION&quot; PIDS=`pidof $PS` || true [ -e $PIDSPATH/$PIDFILE ] &amp;&amp; PIDS2=`cat $PIDSPATH/$PIDFILE` for i in $PIDS; do if [ &quot;$i&quot; = &quot;$PIDS2&quot; ]; then kill $i wait_for_pid &apos;removed&apos; $PIDSPATH/$PIDFILE removePIDFile fi done log_end_msg $SCRIPT_OK rc=0&#125;destroy() &#123; log_daemon_msg &quot;Force terminating and may include self (via KILLALL) $DESCRIPTION&quot; killall $PS -q &gt;&gt; /dev/null 2&gt;&amp;1 log_end_msg $SCRIPT_OK rc=0&#125;pidof_daemon() &#123; PIDS=`pidof $PS` || true [ -e $PIDSPATH/$PIDFILE ] &amp;&amp; PIDS2=`cat $PIDSPATH/$PIDFILE` for i in $PIDS; do if [ &quot;$i&quot; = &quot;$PIDS2&quot; ]; then return 1 fi done return 0&#125;action=&quot;$1&quot;case &quot;$1&quot; in start) start ;; stop) stop ;; restart|force-reload) stop # if [ $rc -ne 0 ]; then # script_exit # fi sleep 1 start ;; reload) $1 ;; status) status ;; configtest) $1 ;; quietupgrade) $1 ;; terminate) $1 ;; destroy) $1 ;; *) FULLPATH=/etc/init.d/$PS echo &quot;Usage: $FULLPATH &#123;start|stop|restart|force-reload|status|configtest|quietupgrade|terminate|destroy&#125;&quot; echo &quot; The &apos;destroy&apos; command should only be used as a last resort.&quot; exit 3 ;;esacexit $rc]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Centos6配置主辅DNS]]></title>
      <url>http://czero000.github.io/2015/10/19/install-bind-ms.html</url>
      <content type="text"><![CDATA[主辅DN数据同步，首先master修改完成并重启服务后，将传送notify给slave。slave将查询master的SOA记录，master收到请求后将SOA记录发送给Slave，Slave收到后同时对比查询结果中的serial值，如果serial值不大于本机的话将结束数据同步过程；但是如果serial值大于本机的话，slave将发送zone transfer请求要求（AXFR/IXFR）。Master响应zone transfer请求并传送结果，直到整个slave更新完成。 安装软件包(主从服务器)1yum install bind bind-chroot bind-utils bind-libs 配置Master服务器编辑bind主配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455cat /var/named/chroot/etc/named.conf//// named.conf//// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS// server as a caching only nameserver (as a localhost DNS resolver only).//// See /usr/share/doc/bind*/sample/ for example named configuration files.//options &#123; listen-on port 53 &#123; 162.243.134.106; &#125;; \\监听ip及端口 directory &quot;/var/named&quot;; \\dns工作目录 dump-file &quot;/var/named/data/cache_dump.db&quot;; \\ 缓存转存文件 statistics-file &quot;/var/named/data/named_stats.txt&quot;; \\内存使用统计信息 allow-query &#123; any; &#125;; \\ 允许查询的主机，默认是localhost recursion no; \\是否递归查询 allow-transfer &#123; 162.243.134.107; &#125;; \\允许同步ip&#125;;logging &#123; \\定义bind服务日志 channel &quot;named_log&quot; &#123; file &quot;logs/named.log&quot; versions 10 size 5m; severity dynamic; print-category yes; print-severity yes; print-time yes;&#125;;channel &quot;query_log&quot; &#123; \\定义查询日志 file &quot;logs/query.log&quot; versions 10 size 5m; severity debug; print-severity yes; print-time yes;&#125;;category default &#123; named_log; &#125;;category queries &#123; query_log; &#125;;&#125;;zone &quot;.&quot; IN &#123; type hint; \\定义根区域 file &quot;named.ca&quot;; \\区域文件 &#125;;include &quot;/etc/rndc.key&quot;; zone &quot;zerounix.com&quot; IN &#123; \\用户区域文件 type master; masters &#123; 162.243.134.106; &#125;; file &quot;zerounix.com.db&quot;;&#125;;rm -f /etc/named.confls -s /var/named/chroot/etc/named.conf /etc/named.conf 增加zerounix.com区域文件12345678910111213141516cat /var/named/chroot/var/named/zerounix.com.db $TTL 60@ IN SOA ns1.zerounix.com. hostmaster.zerounix.com. ( 2015101702 3600 300 604800 600 ) IN NS ns1.zerounix.com. IN NS ns2.zerounix.com. IN MX 5 mail.zerounix.com. IN A 162.243.134.106www IN CNAME web.zerounix.comweb IN A 162.243.134.106 启动bind服务1/etc/init.d/named start 测试解析是否正常12345678910111213141516171819dig www.zerounix.com @162.243.134.106; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.37.rc1.el6_7.4 &lt;&lt;&gt;&gt; www.zerounix.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 20243;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;www.zerounix.com. IN A;; ANSWER SECTION:www.zerounix.com. 9 IN CNAME web.zerounix.com.web.zerounix.com. 9 IN A 162.243.134.106;; Query time: 362 msec;; SERVER: 162.243.134.106#53(162.243.134.106);; WHEN: Mon Oct 19 17:22:21 2015;; MSG SIZE rcvd: 68 配置Slave服务器编辑bind配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 cat /var/named/chroot/etc/named.conf//// named.conf//// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS// server as a caching only nameserver (as a localhost DNS resolver only).//// See /usr/share/doc/bind*/sample/ for example named configuration files.//options &#123; listen-on port 53 &#123; 162.243.134.107; &#125;; directory &quot;/var/named&quot;; dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; allow-query &#123; any; &#125;; recursion no; allow-transfer &#123; 162.243.134.106; 162.243.134.107;&#125;;&#125;;logging &#123; channel &quot;named_log&quot; &#123; file &quot;logs/named.log&quot; versions 10 size 5m; severity dynamic; print-category yes; print-severity yes; print-time yes;&#125;;channel &quot;query_log&quot; &#123; file &quot;logs/query.log&quot; versions 10 size 5m; severity debug; print-severity yes; print-time yes;&#125;;category default &#123; named_log; &#125;;category queries &#123; query_log; &#125;;&#125;;zone &quot;.&quot; IN &#123; type hint; file &quot;named.ca&quot;;&#125;;include &quot;/etc/rndc.key&quot;;zone &quot;zerounix.com&quot; IN &#123; type slave; masters &#123; 162.243.134.106; &#125;; file &quot;zerounix.com.db&quot;; transfer-source 162.243.134.107;&#125;;rm -f /etc/named.confls -s /var/named/chroot/etc/named.conf /etc/named.conf 启动bind服务1/etc/init.d/named start 验证主辅同步查看日志1234567tail -f /var/named/chroot/var/named/logs/named.log19-Oct-2015 17:39:42.825 notify: info: client 162.243.134.106#3133: received notify for zone &apos;zerounix.com&apos;19-Oct-2015 17:39:42.827 general: info: zone zerounix.com/IN: Transfer started.19-Oct-2015 17:39:42.828 xfer-in: info: transfer of &apos;zerounix.com/IN&apos; from 162.243.134.106#53: connected using 162.243.134.107#5091919-Oct-2015 17:39:42.830 general: info: zone zerounix.com/IN: transferred serial 201510170119-Oct-2015 17:39:42.830 xfer-in: info: transfer of &apos;zerounix.com&apos; from 162.243.134.106#53: Transfer completed: 1 messages, 7 records, 222 bytes, 0.001 secs (222000 bytes/sec) 查看zone文件123456789101112131415161718cat /var/named/chroot/var/named/zerounix.com.db $ORIGIN .$ORIGIN .$TTL 60 ; 1 minutezerounix.com IN SOA ns1.zerounix.com. hostmaster.zerounix.com. ( 2015101702 ; serial 3600 ; refresh (1 hour) 300 ; retry (5 minutes) 604800 ; expire (1 week) 600 ; minimum (10 minutes) ) NS ns1.zerounix.com. NS ns2.zerounix.com. A 162.243.134.106 MX 5 mail.zerounix.com.$ORIGIN zerounix.com.www CNAME web.zerounix.com.web A 162.243.134.106 测试解析12345678910111213141516171819dig www.zerounix.com @162.243.134.107; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.37.rc1.el6_7.4 &lt;&lt;&gt;&gt; www.zerounix.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 20272;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;www.zerounix.com. IN A;; ANSWER SECTION:www.zerounix.com. 9 IN CNAME web.zerounix.com.web.zerounix.com. 9 IN A 162.243.134.106;; Query time: 379 msec;; SERVER: 162.243.134.107#53(162.243.134.107);; WHEN: Mon Oct 19 17:35:21 2015;; MSG SIZE rcvd: 68]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[安装Redis]]></title>
      <url>http://czero000.github.io/2015/10/14/install-redis.html</url>
      <content type="text"><![CDATA[Redis 是一个开源的使用 ANSI C 语言编写、支持网络、可基于内存亦可持久化的日志型、 Key-Value 数据库，并提供多种语言的 API 下载安装 redis12345wget http://download.redis.io/releases/redis-3.0.2.tar.gz tar -zxf redis-3.0.2.tar.gzcd redis-3.0.2make &amp;&amp; make install cp redis.conf /etc/ 参数介绍：make install 命令执行完成后，会在 /usr/local/bin 目录下生成本个可执行文件，分别是 redis-server、redis-cli、redis-benchmark、redis-check-aof 、redis-check-dump，它们的作用如下： redis-server：Redis 服务器的 daemon启动程序 redis-cli：Redis 命令行操作工具。也可以用 telnet 根据其纯文本协议来操作 redis-benchmark：Redis 性能测试工具，测试 Redis 在当前系统下的读写性能 redis-check-aof：数据修复 redis-check-dump：检查导出工具 修改系统配置12echo vm.overcommit_memory=1 &gt;&gt; /etc/sysctl.confsysctl vm.overcommit_memory=1 或执行 echo vm.overcommit_memory=1 &gt;&gt;/proc/sys/vm/overcommit_memory 使用数字含义： 0，表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。 1，表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 2，表示内核允许分配超过所有物理内存和交换空间总和的内存 修改配置文件：edit /etc/redis.confdaemonize yes参数说明：参数介绍： daemonize：是否以后台 daemon 方式运行 pidfile：pid 文件位置 port：监听的端口号 timeout：请求超时时间 loglevel：log 信息级别 logfile：log 文件位置 databases：开启数据库的数量 save ：保存快照的频率，第一个\表示多长时间，第三个*表示执行多少次写操作。在一定时间内执行一定数量的写操作时，自动保存快照。可设置多个条件。 rdbcompression：是否使用压缩 dbfilename：数据快照文件名（只是文件名，不包括目录） dir：数据快照的保存目录（这个是目录） appendonly：是否开启 appendonlylog，开启的话每次写操作会记一条 log，这会提高数据抗风险能力，但影响效率。 appendfsync：appendonlylog 如何同步到磁盘（三个选项，分别是每次写都强制调用 fsync、每秒启用一次 fsync、不调用 fsync等待系统自己同步） 启动redis1/usr/local/bin/redis-server /etc/redis.conf]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Elasticsearch配置文件详解]]></title>
      <url>http://czero000.github.io/2015/10/13/elasticsearch-config-file-explain-in-detail.html</url>
      <content type="text"><![CDATA[elasticsearch的config文件夹里面有两个配置文件：elasticsearch.yml和logging.yml，第一个是es的基本配置文件，第二个是日志配置文件，es也是使用log4j来记录日志的，所以logging.yml里的设置按普通log4j配置文件来设置就行了。下面主要讲解下elasticsearch.yml这个文件中可配置的东西。 cluster.name: elasticsearch 配置es的集群名称，默认是elasticsearch，es会自动发现在同一网段下的es，如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。 node.name: “Franz Kafka” 节点名，默认随机指定一个name列表中名字，该列表在es的jar包中config文件夹里name.txt文件中，其中有很多作者添加的有趣名字。 node.master: true 指定该节点是否有资格被选举成为node，默认是true，es是默认集群中的第一台机器为master，如果这台机挂了就会重新选举master。 node.data: true 指定该节点是否存储索引数据，默认为true。 index.number_of_shards: 6 设置默认索引分片个数，默认为5片。 index.number_of_replicas: 1 设置默认索引副本个数，默认为1个副本。 path.conf: /path/to/conf 设置配置文件的存储路径，默认是es根目录下的config文件夹。 path.data: /path/to/data 设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开，例：path.data: /path/to/data1,/path/to/data2 path.work: /path/to/work 设置临时文件的存储路径，默认是es根目录下的work文件夹。 path.logs: /path/to/logs 设置日志文件的存储路径，默认是es根目录下的logs文件夹 path.plugins: /path/to/plugins 设置插件的存放路径，默认是es根目录下的plugins文件夹 bootstrap.mlockall: true 设置为true来锁住内存。因为当jvm开始swapping时es的效率会降低，所以要保证它不swap，可以把ES_MIN_MEM和ES_MAX_MEM两个环境变量设置成同一个值，并且保证机器有足够的内存分配给es。同时也要允许elasticsearch的进程可以锁住内存，linux下可以通过ulimit -l unlimited命令。 network.bind_host: 192.168.0.1 设置绑定的ip地址，可以是ipv4或ipv6的，默认为0.0.0.0。 network.publish_host: 192.168.0.1 设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。 network.host: 192.168.0.1 这个参数是用来同时设置bind_host和publish_host上面两个参数。 vtransport.tcp.port: 9300 设置节点间交互的tcp端口，默认是9300。 transport.tcp.compress: true 设置是否压缩tcp传输时的数据，默认为false，不压缩。 http.port: 9200 设置对外服务的http端口，默认为9200。 http.max_content_length: 100mb 设置内容的最大容量，默认100mb http.enabled: false 是否使用http协议对外提供服务，默认为true，开启。 gateway.type: local gateway的类型，默认为local即为本地文件系统，可以设置为本地文件系统，分布式文件系统，hadoop的HDFS，和amazon的s3服务器，其它文件系统的设置方法下次再详细说。 gateway.recover_after_nodes: 1 设置集群中N个节点启动时进行数据恢复，默认为1。 gateway.recover_after_time: 5m 设置初始化数据恢复进程的超时时间，默认是5分钟。 gateway.expected_nodes: 2 设置这个集群中节点的数量，默认为2，一旦这N个节点启动，就会立即进行数据恢复。 cluster.routing.allocation.node_initial_primaries_recoveries: 4 初始化数据恢复时，并发恢复线程的个数，默认为4。 cluster.routing.allocation.node_concurrent_recoveries: 2 添加删除节点或负载均衡时并发恢复线程的个数，默认为4。 indices.recovery.max_size_per_sec: 0 设置数据恢复时限制的带宽，如入100mb，默认为0，即无限制。 indices.recovery.concurrent_streams: 5 设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数，默认为5。 discovery.zen.minimum_master_nodes: 1 设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值（2-4） discovery.zen.ping.timeout: 3s 设置集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。 discovery.zen.ping.multicast.enabled: false 设置是否打开多播发现节点，默认是true。 discovery.zen.ping.unicast.hosts: [“host1”, “host2:port”, “host3[portX-portY]”] 设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点。下面是一些查询时的慢日志参数设置123456789index.search.slowlog.level: TRACEindex.search.slowlog.threshold.query.warn: 10sindex.search.slowlog.threshold.query.info: 5sindex.search.slowlog.threshold.query.debug: 2sindex.search.slowlog.threshold.query.trace: 500msindex.search.slowlog.threshold.fetch.warn: 1sindex.search.slowlog.threshold.fetch.info: 800msindex.search.slowlog.threshold.fetch.debug:500msindex.search.slowlog.threshold.fetch.trace: 200ms]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ElasticSearch 安装service wrapper插件]]></title>
      <url>http://czero000.github.io/2015/10/13/elasticsearch-install-service-wrapper.html</url>
      <content type="text"><![CDATA[使用elasticsearch-servicewrapper这个es插件，它支持通过参数，指定是在后台或前台运行es，并且支持启动，停止，重启es服务（默认es脚本只能通过ctrl+c关闭es） 下载软件包：1wget http://github.com/elasticsearch/elasticsearch-servicewrapper/archive/master.zip -O elasticsearch-servicewrapper.zip 解压、拷贝：12unzip elasticsearch-servicewrapper.zip mv elasticsearch-servicewrapper-master/service/ /usr/local/elasticsearch/bin/ 执行：123456bin/service/elasticsearch +console 在前台运行esstart 在后台运行esstop 停止esinstall 使es作为服务在服务器启动时自动启动remove 取消启动时自动启动 在service目录下有个elasticsearch.conf配置文件，主要是设置一些java运行环境参数，其中比较重要的是下面的参数：12345678910111213#es的home路径，不用用默认值就可以set.default.ES_HOME=#分配给es的最小内存set.default.ES_MIN_MEM=256#分配给es的最大内存set.default.ES_MAX_MEM=1024# 启动等待超时时间（以秒为单位）wrapper.startup.timeout=300# 关闭等待超时时间（以秒为单位）wrapper.shutdown.timeout=300# ping超时时间(以秒为单位)wrapper.ping.timeout=300]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[安装ELK日志服务]]></title>
      <url>http://czero000.github.io/2015/10/13/install-elk.html</url>
      <content type="text"><![CDATA[什么是ELK ELK是ElasticSearch、Logstash、Kibana三个开源软件的组合，这三个产品可以单独使用，但当他们组合在一起使用时，你会发现一个强大的、可扩展的日志服务，而且都是归于Elastic.co公司名下，所以有此简称。 ELK具有如下几个优点： 处理方式灵活：Elasticsearch是实时全文索引，不需要像storm那样预先编程才能使用； 配置简、易上手：ElasticSearch全部采用JSON接口，Logstash是Ruby DSL设计，都是目前业界最 通用的配置语法设计； 检索性能高效：虽然每次查询都是实时计算，但是优秀的设计和实现基本可以到达百亿级数据查询的秒级响应； 集群线性扩展：不管是ElasticSearch集群还是Logstash集群都是可以线性扩展； 前端操作绚丽：Kibana界面，只需要点击鼠标，就可以完成搜索、聚合、生成绚丽的仪表盘； 软件介绍： ElasticSearch：数据实时检索、分析 Logstash： 收集、分析、存储数据 Kibana： 可视化数据 redis: 日志队列 ELK Stack示意图： 安装准备系统环境查看系统：12cat /etc/redhat-releaseCentOS Linux release 7.1.1503 (Core) 设置selinux状态12getenforceDisabled` 安装EPEL源1yum -y install epel-release 下载软件 ElasticSearch Logstash kabana redis 安装java支持（ELK Stack需要JAVA支持）安装JAVA（ORACLE）123456789101112131415wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/8u40-b25/jre-8u40-linux-x64.tar.gz&quot;tar -zxf jre-8u40-linux-x64.tar.gzchown -R root: jre1.8.0_40mv jre1.8.0_40/ /usr/local/javacat &gt;&gt; /etc/profile export JAVA_HOME=/usr/local/javaexport JAVA_BIN=/usr/local/java/binexport PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport JAVA_HOME JAVA_BIN PATH CLASSPATHEOFsource /etc/profilejava -versionjava version &quot;1.8.0_40&quot;Java(TM) SE Runtime Environment (build 1.8.0_40-b25)Java HotSpot(TM) 64-Bit Server VM (build 25.40-b25, mixed mode) 安装OpenJDK1yum install -y java-1.8.0-openjdk 安装ELK Stack安装Redis1yum -y install redis 安装ElasticSearch安装123tar -zxf elasticsearch-1.7.2.tar.gzmv elasticsearch-1.7.2 /usr/local/elasticsearchsed -i &apos;s/#network.host: 192.168.0.1/network.host: 172.16.11.230/g&apos; /usr/local/elasticsearch/config/elasticsearch.yml 启动1/usr/local/elasticsearch/bin/elasticsearch -d 测试1234567891011121314curl -XGET http://172.16.11.230:9200&#123; &quot;status&quot; : 200, &quot;name&quot; : &quot;Chemistro&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;1.7.2&quot;, &quot;build_hash&quot; : &quot;e43676b1385b8125d647f593f7202acbd816e8ec&quot;, &quot;build_timestamp&quot; : &quot;2015-09-14T09:49:53Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;4.10.4&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 这说明你的ElasticSearch集群已经启动并且正常运行。 安装kibana安装1234tar -zxf kibana-4.1.2-linux-x64.tar.gzmv kibana-4.1.2-linux-x64 /usr/local/kibanased -i &apos;/host/ s/0.0.0.0/172.16.11.230/g&apos; /usr/local/kibana/config/kibana.ymlsed -i &apos;/elasticsearch_url/ s/localhost/172.16.11.230/g&apos; /usr/local/kibana/config/kibana.yml 配置启动（通过Systemctl来控制）12345678910111213cat &gt;&gt; /etc/systemd/system/kibana4.service [Service]ExecStart=/usr/local/kibana/bin/kibanaRestart=alwaysStandardOutput=syslogStandardError=syslogSyslogIdentifier=kibana4User=rootGroup=rootEnvironment=NODE_ENV=production[Install]WantedBy=multi-user.targetEOF 启动kabana123systemctl enable kibana4.service ln -s &apos;/etc/systemd/system/kibana4.service&apos; &apos;/etc/systemd/system/multi-user.target.wants/kibana4.service&apos;systemctl start kibana4 登录172.16.11.230:5601出现下面界面说明安装成功 安装Logstash12tar -zxf logstash-1.5.4.tar.gzmv logstash-1.5.4 /usr/local/logstash 安装nginx服务（反向代理）安装12345yum install openssl-devel pcre-devel -ytar -zxf nginx-1.7.3.tar.gzcd nginx-1.7.3/./configure --prefix=/usr/local/nginx --group=nobody --user=nobody --with-http_stub_status_module --with-http_ssl_module --with-pcremake &amp;&amp; make install 配置1234567891011121314cat kibana.confserver &#123; listen 80; server_name elk.mydomain.com; charset utf-8; index index.html; root /usr/local/nginx/html; access_log logs/elk.mydomain.com_access.log combined; error_log logs/elk.mydomain.com_error.log; location / &#123; proxy_pass http://172.16.11.230:5601$request_uri; proxy_set_header Host $http_host; &#125;&#125; 配置启动脚本123456789101112131415161718cat /etc/systemd/system/nginx.service[Unit]Description=The nginx HTTP and reverse proxy serverAfter=network.target remote-fs.target nss-lookup.target[Service]Type=forkingPIDFile=/usr/local/nginx/logs/nginx.pidExecStartPre=/usr/local/nginx/sbin/nginx -tExecStart=/usr/local/nginx/sbin/nginxExecReload=/bin/kill -s HUP $MAINPIDKillMode=processKillSignal=SIGQUITTimeoutStopSec=5PrivateTmp=true[Install]WantedBy=multi-user.target 启动nginx，访问elk.mydomain.com是不是就跳转到kibana的界面了呢]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Centos7 命令行安装Dropbox]]></title>
      <url>http://czero000.github.io/2015/10/12/install-dropdox-with-cmd.html</url>
      <content type="text"><![CDATA[Dropbox 这货也被Q了，想要使用需要搭梯子，可以参照Shadowsocks安装，搭建一个梯子。 Dropbox 守护程序可在所有 32 位与 64 位 Linux 服务器上正常运行。若要安装，请在 Linux 终端运行下列命令。 下载Dropbox访问官方下载页面根据不同平台，选择下载不同的安装包 安装Dropbox我的操作系统是CentOS，选择下载RPM包来安装12http://linux.dropbox.com/packages/fedora/nautilus-dropbox-2015.02.12-1.fedora.x86_64.rpmyum localinstall nautilus-dropbox-2015.02.12-1.fedora.x86_64.rpm 启动Dropbox1234dropbox startStarting Dropbox...The Dropbox daemon is not installed!Run &quot;dropbox start -i&quot; to install the daemon 执行12345678dropbox start -iStarting Dropbox...Dropbox is the easiest way to share and store your files online. Want to learn more? Head to http://www.dropbox.com/In order to use Dropbox, you must download the proprietary daemon. [y/n] yDownloading Dropbox... 100%Unpacking Dropbox... 100%Done! 启动Dropbox12dropbox startDropbox is already running! 配置Dropbox执行命令1234~/.dropbox-dist/dropboxdThis computer isn&apos;t linked to any Dropbox account...Please visit http://www.dropbox.com/cli_link_nonce?nonce=94f031bb1e619bda13898fd5e9c8a44e to link this device. 用另外一个终端lynx http://www.dropbox.com/cli_link_nonce?nonce=94f031bb1e619bda13898fd5e9c8a44e这样就完成了 下载官方工具123wget &quot;http://www.dropbox.com/download?dl=packages/dropbox.py&quot; chmod 755 dropbox.py ./dropbox.py help (或是 start, stop等指令, 预设位置为~/Dropbox)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[GlusterFS部署详解]]></title>
      <url>http://czero000.github.io/2015/10/09/glusterfs-explain-in-detail.html</url>
      <content type="text"><![CDATA[本文详细介绍gluster fs 安装配置及之后的维护 环境介绍系统版本:CentOS 6.5 x86_64 安装GlusterFS软件包123yum install -y glusterfs glusterfs-fuse glusterfs-server xfsprogs/etc/init.d/glusterd start chkconfig glusterfsd on 配置整个GlusterFS集群123456789101112131415161718192021222324gluster peer probe 172.16.18.241peer probe: success: on localhost not needed gluster peer probe 172.16.18.242peer probe: successgluster peer probe 172.16.18.243peer probe: success gluster peer probe 172.16.18.244peer probe: success gluster peer statusgluster peer statusNumber of Peers: 3Hostname: 172.16.18.242Uuid: beb0aae7-a939-45ec-a273-0c21c2f59546State: Peer in Cluster (Connected)Hostname: 172.16.18.243Uuid: eab486b3-d1a1-4851-b9ec-45aab1ef9a66State: Peer in Cluster (Connected)Hostname: 172.16.18.244Uuid: 3108764d-d6b3-4356-810d-88872d56ceb6State: Peer in Cluster (Connected) 创建数据存放目录12345parted /dev/sdb rm 1mkfs.xfs -i size=512 /dev/sdb -fmkdir -p /export/brick1/bin/mount -t xfs /dev/sdb /export/brick1mkdir /export/brick1/gv0 GlusterFS磁盘1234567891011121314151617181920gluster volume create gv0 replica 2 172.16.18.241:/export/brick1/gv0 172.16.18.242:/export/brick1/gv0 172.16.18.243:/export/brick1/gv0 172.16.18.244:/export/brick1/gv0 forcegluster volume start gv0volume create: gv0: success: please start the volume to access datagluster volume info Volume Name: gv0Type: Distributed-ReplicateVolume ID: e64cb61c-0f18-41b5-bf4d-c45ee085ca3bStatus: StartedNumber of Bricks: 2 x 2 = 4Transport-type: tcpBricks:Brick1: 172.16.18.241:/export/brick1/gv0Brick2: 172.16.18.242:/export/brick1/gv0Brick3: 172.16.18.243:/export/brick1/gv0Brick4: 172.16.18.244:/export/brick1/gv0Options Reconfigured:performance.readdir-ahead: on 安装客户端并mount GlusterFS文件系统12345678910111213141516wget -P /etc/yum.repos.d http://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-epel.repoyum install glusterfs glusterfs-fuse glusterfs-servermkdir -p /opt/vmx/gv0/bin/mount -t glusterfs 172.16.18.241:/gv0 /opt/vmx/gv0df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/centos-root 50G 5.6G 45G 12% /devtmpfs 12G 0 12G 0% /devtmpfs 12G 12K 12G 1% /dev/shmtmpfs 12G 25M 12G 1% /runtmpfs 12G 0 12G 0% /sys/fs/cgroup/dev/mapper/centos-home 217G 33M 217G 1% /home/dev/sda1 497M 102M 395M 21% /boot/dev/sdb 280G 33M 280G 1% /export/brick1172.16.6.60:/gv0 559G 1.6G 558G 1% /opt/vmx/gv0 读写可用性测试在挂载点上写入数据：12echo &quot;172.16.18.245&quot; &gt; /opt/vmx/gv0/test.txtmkdir /opt/vmx/gv0/test 在server数据目录中进行查看12ls /export/brick1/gv0/test test.txt 结果： 数据写入成功 扩容与缩减扩容步骤：系统的扩容与缩减可以通过节点、brick管理达到目的 扩容时，可以先增加系统节点，然后添加新的Brick即可 缩减时，先移除Brick，然后在进行删除达到缩容目的，并保持数据不丢失 在线扩容 查看节点状态1234567891011gluster peer statusNumber of Peers: 3Hostname: 172.16.18.242Uuid: 5f4f3352-6b28-471f-8c1e-a990b49f77c2State: Peer in Cluster (Connected)Hostname: 172.16.18.243Uuid: 3a7e17b5-4407-4ff0-8645-69cc6ace54f9State: Peer in Cluster (Connected)Hostname: 172.16.18.241Uuid: e19a56c0-a060-4bcc-80d8-99de3d85a484State: Peer in Cluster (Connected) 增加节点1234gluster peer probe 172.16.18.245peer probe: success. gluster peer probe 172.16.18.246peer probe: success. 验证节点添加1234567891011121314151617gluster peer statusNumber of Peers: 5Hostname: 172.16.18.242Uuid: 5f4f3352-6b28-471f-8c1e-a990b49f77c2State: Peer in Cluster (Connected)Hostname: 172.16.18.243Uuid: 3a7e17b5-4407-4ff0-8645-69cc6ace54f9State: Peer in Cluster (Connected)Hostname: 172.16.18.241Uuid: e19a56c0-a060-4bcc-80d8-99de3d85a484State: Peer in Cluster (Connected)Hostname: 172.16.18.245Uuid: ce286cd4-6ca2-48cb-8207-d58a99ff37dcState: Peer in Cluster (Connected)Hostname: 172.16.18.246Uuid: d4ecc341-7b45-4374-90a5-2f53449c8c86State: Peer in Cluster (Connected) 查看卷信息1234567891011121314151617gluster volume infoVolume Name: gv0Type: Distributed-ReplicateVolume ID: 8377a30e-6f6e-4dfc-9378-f56c1b3559e1Status: StartedNumber of Bricks: 2 x 2 = 4Transport-type: tcpBricks:Brick1: 172.16.18.241:/export/brick1/gv0Brick2: 172.16.18.242:/export/brick1/gv0Brick3: 172.16.18.243:/export/brick1/gv0Brick4: 172.16.18.244:/export/brick1/gv0Options Reconfigured:diagnostics.count-fop-hits: ondiagnostics.latency-measurement: onperformance.readdir-ahead: on 添加brick12 gluster volume add-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 volume add-brick: success 验证Brick添加12345678910111213141516171819gluster volume info Volume Name: gv0Type: Distributed-ReplicateVolume ID: 8377a30e-6f6e-4dfc-9378-f56c1b3559e1Status: StartedNumber of Bricks: 3 x 2 = 6Transport-type: tcpBricks:Brick1: 172.16.18.241:/export/brick1/gv0Brick2: 172.16.18.242:/export/brick1/gv0Brick3: 172.16.18.243:/export/brick1/gv0Brick4: 172.16.18.244:/export/brick1/gv0Brick5: 172.16.18.245:/export/brick1/gv0Brick6: 172.16.18.246:/export/brick1/gv0Options Reconfigured:diagnostics.count-fop-hits: ondiagnostics.latency-measurement: onperformance.readdir-ahead: on 重新分配数据12345678910111213gluster volume rebalance gv0 startvolume rebalance: gv0: success: Rebalance on gv0 has been started successfully. Use rebalance status command to check status of the rebalance process.ID: 0d7c4099-cde7-4a37-9d3e-2a9ae83e6843gluster volume rebalance gv0 status Node Rebalanced-files size scanned failures skipped status run time in secs --------- ----------- ----------- ----------- ----------- ----------- ------------ -------------- localhost 0 0Bytes 0 0 0 completed 0.00 172.16.18.242 0 0Bytes 0 0 0 completed 0.00 172.16.18.243 0 0Bytes 4 0 0 completed 0.00 172.16.18.241 0 0Bytes 4 0 1 completed 0.00 172.16.18.245 0 0Bytes 1 0 0 completed 0.00 172.16.18.246 0 0Bytes 0 0 0 completed 0.00volume rebalance: gv0: success: 在线缩减 移除Brick若是副本卷，则要溢出的Brick是replica的整数倍，stripe具有同样的要求，一次副本卷要移除一对Brick，数据会移到其他节点。123456789101112131415161718192021222324252627282930313233343536373839404142434445gluster volume remove-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 startvolume remove-brick start: successID: b3600ab0-b103-405a-8458-4edb820c0ca1 gluster volume statusStatus of volume: gv0Gluster process TCP Port RDMA Port Online Pid------------------------------------------------------------------------------Brick 172.16.18.241:/export/brick1/gv0 49152 0 Y 1970 Brick 172.16.18.242:/export/brick1/gv0 49152 0 Y 9547 Brick 172.16.18.243:/export/brick1/gv0 49152 0 Y 9558 Brick 172.16.18.244:/export/brick1/gv0 49152 0 Y 9741 Brick 172.16.18.245:/export/brick1/gv0 49152 0 Y 13266Brick 172.16.18.246:/export/brick1/gv0 49152 0 Y 12484NFS Server on localhost N/A N/A N N/A Self-heal Daemon on localhost N/A N/A Y 15073NFS Server on 172.16.18.243 N/A N/A N N/A Self-heal Daemon on 172.16.18.243 N/A N/A Y 13755NFS Server on 172.16.18.242 N/A N/A N N/A Self-heal Daemon on 172.16.18.242 N/A N/A Y 1424 NFS Server on 172.16.18.241 N/A N/A N N/A Self-heal Daemon on 172.16.18.241 N/A N/A Y 2124 NFS Server on 172.16.18.246 N/A N/A N N/A Self-heal Daemon on 172.16.18.246 N/A N/A Y 12511NFS Server on 172.16.18.245 N/A N/A N N/A Self-heal Daemon on 172.16.18.245 N/A N/A Y 13293 Task Status of Volume gv0------------------------------------------------------------------------------Task : Remove brick ID : b3600ab0-b103-405a-8458-4edb820c0ca1Removed bricks: 172.16.18.245:/export/brick1/gv0172.16.18.246:/export/brick1/gv0Status : completed gluster volume remove-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 status Node Rebalanced-files size scanned failures skipped status run time in secs --------- ----------- ----------- ----------- ----------- ----------- ------------ -------------- 172.16.18.245 1 42Bytes 1 0 0 completed 1.00 172.16.18.246 0 0Bytes 0 0 0 completed 0.00gluster volume remove-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 commitRemoving brick(s) can result in data loss. Do you want to Continue? (y/n) yvolume remove-brick commit: successCheck the removed bricks to ensure all files are migrated.If files with data are found on the brick path, copy them via a gluster mount point before re-purposing the removed brick. 移除节点123456789101112131415161718192021222324gluster peer detach 172.16.18.245peer detach: successgluster peer detach 172.16.18.246peer detach: success gluster volume status Status of volume: gv0Gluster process TCP Port RDMA Port Online Pid------------------------------------------------------------------------------Brick 172.16.18.241:/export/brick1/gv0 49152 0 Y 1970 Brick 172.16.18.242:/export/brick1/gv0 49152 0 Y 9547 Brick 172.16.18.243:/export/brick1/gv0 49152 0 Y 9558 Brick 172.16.18.244:/export/brick1/gv0 49152 0 Y 9741 NFS Server on localhost N/A N/A N N/A Self-heal Daemon on localhost N/A N/A Y 15386NFS Server on 172.16.18.241 N/A N/A N N/A Self-heal Daemon on 172.16.18.241 N/A N/A Y 2605 NFS Server on 172.16.18.242 N/A N/A N N/A Self-heal Daemon on 172.16.18.242 N/A N/A Y 1966 NFS Server on 172.16.18.243 N/A N/A N N/A Self-heal Daemon on 172.16.18.243 N/A N/A Y 14272 Task Status of Volume gv0------------------------------------------------------------------------------There are no active volume tasks 替换某个Brick 增加一个节点12gluster peer probe 172.16.18.245peer probe: success. 将172.16.18.244：/export/brick1/gv0替换为172.16.18.245:/export/brick1/gv0 12gluster volume replace-brick gv0 172.16.18.244:/export/brick1/gv0 172.16.18.245:/export/brick1/gv0 start forcegluster volume replace-brick gv0 172.16.18.244:/export/brick1/gv0 172.16.18.245:/export/brick1/gv0 commit 其它操作笔记删除GlusterFS卷12# gluster volume stop gv0# gluster volume delete gv0 ACL访问控制1# gluster volume set gv0 auth.allow 172.16.18.*,192.168.1.* 添加GlusterFS节点及brick123# gluster peer probe 172.16.18.245# gluster peer probe 172.16.18.246# gluster volume add-brick gv0 172.16.18.245:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 删除GlusterFS节点1gluster peer detach 172.16.18.242 删除GlusterFS brick1# gluster volume remove-brick gv0 172.16.18.245:/export/brick1/gv0 数据重新分配123gluster volume rebalance gv0 startgluster volume rebalance gv0 statusgluster volume rebalance gv0 stop 性能监控 profile123gluster volume profile mamm-vol start gluster volume profile info gluster volume profile mamm-vol stop top1gluster volume top mamm-vol &#123;open|read|write|opendir|readdir&#125; brick node1:/exp1 list-cnt 1 显示当前某个brick或NFS路径读文件或写文件数据的性能1gluster volume top mamm-vol read-perf|write-perf bs 256 count 10 brick node1:/exp1 list-cnt 1 内部计数导出1gluster volume statedump mamm-vol 迁移GlusterFS磁盘数据12345# gluster volume remove-brick gv0 172.16.18.241:/export/brick1/gv0 172.16.18.242:/export/brick1/gv0 start # gluster volume remove-brick gv0 172.16.18.241:/export/brick1/gv0 172.16.18.242:/export/brick1/gv0 pause # gluster volume remove-brick gv0 172.16.18.241:/export/brick1/gv0 172.16.18.242:/export/brick1/gv0 status # gluster volume remove-brick gv0 172.16.18.241:/export/brick1/gv0 172.16.18.242:/export/brick1/gv0 commit # gluster volume remove-brick gv0 172.16.18.241:/export/brick1/gv0 172.16.18.242:/export/brick1/gv0 abort 修复GlusterFS磁盘数据（例如172.16.18.241宕机的情况下）1234# gluster volume replace-brick gv0 172.16.18.241:/export/brick1/gv0 172.16.18.246:/export/brick1/gv0 commit -force # gluster volume heal gv0 # gluster volume heal gv0 full# gluster volume heal gv0 info GlusterFS常用中继介绍 storage/posix #指定一个本地目录给GlusterFS内的一个卷使用； protocol/server #服务器中继，表示此节点在GlusterFS中为服务器模式，可以说明其IP、守护端口、访问权限； protocol/client #客户端中继，用于客户端连接服务器时使用，需要指明服务器IP和定义好的卷； cluster/replicate #复制中继，备份文件时使用，若某子卷掉了，系统仍能正常工作，子卷起来后自动更新（通过客户端）； cluster/distribute #分布式中继，可以把两个卷或子卷组成一个大卷，实现多存储空间的聚合； features/locks #锁中继，只能用于服务器端的posix中继之上，表示给这个卷提供加锁(fcntl locking)的功能； performance/read-ahead #预读中继，属于性能调整中继的一种，用预读的方式提高读取的性能，有利于应用频繁持续性的访问文件，当应用完成当前数据块读取的时候，下一个数据块就已经准备好了，主要是在IB-verbs或10G的以太网上使用； performance/write-behind #回写中继，属于性能调整中继的一种，作用是在写数据时，先写入缓存内，再写入硬盘，以提高写入的性能，适合用于服务器端； performance/io-threads #IO线程中继，属于性能调整中继的一种，由于glusterfs 服务是单线程的，使用IO 线程转换器可以较大的提高性能，这个转换器最好是被用于服务器端； erformance/io-cache #IO缓存中继，属于性能调整中继的一种，作用是缓存住已经被读过的数据，以提高IO 性能，当IO 缓存中继检测到有写操作的时候，它就会把相应的文件从缓存中删除，需要设置文件匹配列表及其设置的优先级等内容； luster/stripe #条带中继，将单个大文件分成多个小文件存于各个服务器中，实现大文件的分块存储。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[中文书写指南]]></title>
      <url>http://czero000.github.io/2015/07/22/chinese-copywriting-guidelines.html</url>
      <content type="text"><![CDATA[中文文案排版指北 统一中文文案、排版的相关用法，降低团队成员之间的沟通成本，增强网站气质。 Other languages: English Chinese Traditional Chinese Simplified 目录 空格 中英文之间需要增加空格 中文与数字之间需要增加空格 数字与单位之间需要增加空格 全角标点与其他字符之间不加空格 -ms-text-autospace to the rescue? 标点符号 不重复使用标点符号 全角和半角 使用全角中文标点 数字使用半角字符 遇到完整的英文整句、特殊名词，其內容使用半角标点 名词 专有名词使用正确的大小写 不要使用不地道的缩写 争议 链接之间增加空格 简体中文使用直角引号 工具 谁在这样做？ 参考文献 空格「有研究显示，打字的时候不喜欢在中文和英文之间加空格的人，感情路都走得很辛苦，有七成的比例会在 34 岁的时候跟自己不爱的人结婚，而其余三成的人最后只能把遗产留给自己的猫。毕竟爱情跟书写都需要适时地留白。 与大家共勉之。」——vinta/paranoid-auto-spacing 中英文之间需要增加空格正确： 在 LeanCloud 上，数据存储是围绕 AVObject 进行的。 错误： 在LeanCloud上，数据存储是围绕AVObject进行的。 在 LeanCloud上，数据存储是围绕AVObject 进行的。 完整的正确用法： 在 LeanCloud 上，数据存储是围绕 AVObject 进行的。每个 AVObject 都包含了与 JSON 兼容的 key-value 对应的数据。数据是 schema-free 的，你不需要在每个 AVObject 上提前指定存在哪些键，只要直接设定对应的 key-value 即可。 例外：「豆瓣FM」等产品名词，按照官方所定义的格式书写。 中文与数字之间需要增加空格正确： 今天出去买菜花了 5000 元。 错误： 今天出去买菜花了 5000元。 今天出去买菜花了5000元。 数字与单位之间需要增加空格正确： 我家的光纤入户宽带有 10 Gbps，SSD 一共有 20 TB。 错误： 我家的光纤入户宽带有 10Gbps，SSD 一共有 10TB。 例外：度／百分比与数字之间不需要增加空格： 正确： 今天是 233° 的高温。 新 MacBook Pro 有 15% 的 CPU 性能提升。 错误： 今天是 233 ° 的高温。 新 MacBook Pro 有 15 % 的 CPU 性能提升。 全角标点与其他字符之间不加空格正确： 刚刚买了一部 iPhone，好开心！ 错误： 刚刚买了一部 iPhone ，好开心！ -ms-text-autospace to the rescue?Microsoft 有个 -ms-text-autospace.aspx) 的 CSS 属性可以实现自动为中英文之间增加空白。不过目前并未普及，另外在其他应用场景，例如 OS X、iOS 的用户界面目前并不存在这个特性，所以请继续保持随手加空格的习惯。 标点符号不重复使用标点符号正确： 德国队竟然战胜了巴西队！ 她竟然对你说「喵」？！ 错误： 德国队竟然战胜了巴西队！！ 德国队竟然战胜了巴西队！！！！！！！！ 她竟然对你说「喵」？？！！ 她竟然对你说「喵」？！？！？？！！ 全角和半角不明白什么是全角（全形）与半角（半形）符号？请查看维基百科词条『全角和半角』。 使用全角中文标点正确： 嗨！你知道嘛？今天前台的小妹跟我说「喵」了哎！ 核磁共振成像（NMRI）是什么原理都不知道？JFGI！ 错误： 嗨! 你知道嘛? 今天前台的小妹跟我说 “喵” 了哎! 嗨!你知道嘛?今天前台的小妹跟我说”喵”了哎! 核磁共振成像 (NMRI) 是什么原理都不知道? JFGI! 核磁共振成像(NMRI)是什么原理都不知道?JFGI! 数字使用半角字符正确： 这件蛋糕只卖 1000 元。 错误： 这件蛋糕只卖 １０００ 元。 例外：在设计稿、宣传海报中如出现极少量数字的情形时，为方便文字对齐，是可以使用全角数字的。 遇到完整的英文整句、特殊名词，其內容使用半角标点正确： 乔布斯那句话是怎么说的？「Stay hungry, stay foolish.」 推荐你阅读《Hackers &amp; Painters: Big Ideas from the Computer Age》，非常的有趣。 错误： 乔布斯那句话是怎么说的？「Stay hungry，stay foolish。」 推荐你阅读《Hackers＆Painters：Big Ideas from the Computer Age》，非常的有趣。 名词专有名词使用正确的大小写大小写相关用法原属于英文书写范畴，不属于本 wiki 讨论內容，在这里只对部分易错用法进行简述。 正确： 使用 GitHub 登录 我们的客户有 GitHub、Foursquare、Microsoft Corporation、Google、Facebook, Inc.。 错误： 使用 github 登录 使用 GITHUB 登录 使用 Github 登录 使用 gitHub 登录 使用 gｲんĤЦ8 登录 我们的客户有 github、foursquare、microsoft corporation、google、facebook, inc.。 我们的客户有 GITHUB、FOURSQUARE、MICROSOFT CORPORATION、GOOGLE、FACEBOOK, INC.。 我们的客户有 Github、FourSquare、MicroSoft Corporation、Google、FaceBook, Inc.。 我们的客户有 gitHub、fourSquare、microSoft Corporation、google、faceBook, Inc.。 我们的客户有 gｲんĤЦ8、ｷouЯƧquﾑгє、๓เςг๏ร๏Ŧt ς๏гק๏гคtเ๏ภn、900913、ƒ4ᄃëв๏๏к, IПᄃ.。 注意：当网页中需要配合整体视觉风格而出现全部大写／小写的情形，HTML 中请使用标准的大小写规范进行书写；并通过 text-transform: uppercase;／text-transform: lowercase; 对表现形式进行定义。 不要使用不地道的缩写正确： 我们需要一位熟悉 JavaScript、HTML5，至少理解一种框架（如 Backbone.js、AngularJS、React 等）的前端开发者。 错误： 我们需要一位熟悉 Js、h5，至少理解一种框架（如 backbone、angular、RJS 等）的 FED。 争议以下用法略带有个人色彩，既：无论是否遵循下述规则，从语法的角度来讲都是正确的。 链接之间增加空格用法： 请 提交一个 issue 并分配给相关同事。 访问我们网站的最新动态，请 点击这里 进行订阅！ 对比用法： 请提交一个 issue 并分配给相关同事。 访问我们网站的最新动态，请点击这里进行订阅！ 简体中文使用直角引号用法： 「老师，『有条不紊』的『紊』是什么意思？」 对比用法： “老师，‘有条不紊’的‘紊’是什么意思？” 工具 仓库 语言 vinta/paranoid-auto-spacing JavaScript huei90/pangu.node Node.js huacnlee/auto-correct Ruby sparanoid/space-lover PHP (WordPress) nauxliu/auto-correct PHP hotoo/pangu.vim Vim sparanoid/grunt-auto-spacing Node.js (Grunt) hjiang/scripts/add-space-between-latin-and-cjk Python 谁在这样做？ 网站 文案 UGC Apple 中国 Yes N/A Apple 香港 Yes N/A Apple 台湾 Yes N/A Microsoft 中国 Yes N/A Microsoft 香港 Yes N/A Microsoft 台湾 Yes N/A LeanCloud Yes N/A 知乎 Yes 部分用户达成 V2EX Yes Yes SegmentFault Yes 部分用户达成 Apple4us Yes N/A 豌豆荚 Yes N/A Ruby China Yes 标题达成 PHPHub Yes 标题达成 参考文献 Guidelines for Using Capital Letters Letter case - Wikipedia Punctuation - Oxford Dictionaries Punctuation - The Purdue OWL How to Use English Punctuation Corrently - wikiHow 格式 - openSUSE 全角和半角 - 维基百科 引号 - 维基百科 疑问惊叹号 - 维基百科]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用 Hexo 搭建静态博客]]></title>
      <url>http://czero000.github.io/2015/06/24/use-hexo-to-build-a-static-blog.html</url>
      <content type="text"><![CDATA[Why之前一直在使用 WordPress，之后我喜欢上了 Markdown，喜欢那种简洁纯粹的写作方式。 由于愈发觉得 WordPress 臃肿，可能也是年龄渐大的缘故，便选择放弃 WordPress，改为静态博客—完美支持 Marddown 的 Hexo HexoHexo 是一款基于 Node.js 的快速的、简洁且高效的博客框架，使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 Hexo不依赖数据库和任何 Web 工具, 所以可以托管到 GitHub 环境准备 系统：Windows 10 64bit 文本编辑器： Atom Node.JS 环境由于 Hexo 是基于 Node.js 的第三方模块，所以不能缺少 Node.js。到 Node.js 官网下载最新版安装即可。我是用的版本为 v4.47 LTS Git 工具Git的客户端有很多，我使用的是 git for windows Github 注册一个 GitHub 帐号 建立与你用户名对应的仓库，仓库名必须为 you_user_name.github.io 配置SSH，请参考SSH配置教程 安装 Hexo 安装 Hexo 程序12345//2.xnpm install hexo -g//3.xnpm install hexo-cli -gnpm install hexo --save 注：NPM 的全称是 Node Package Manager，是一个 Node.js 包管理和分发工具，已经成为了非官方的发布 Node.js 模块（包）的标准。 查看 Hexo 及模块版本 123456789101112$ hexo versionhexo-cli: 1.0.2os: Windows_NT 10.0.10586 win32 x64http_parser: 2.5.2node: 4.4.7v8: 4.5.103.36uv: 1.8.0zlib: 1.2.8ares: 1.10.1-DEVicu: 56.1modules: 46openssl: 1.0.2h 创建项目并初始化 12mkdir hexo_dirhexo init hexo_dir //hexo_dir为自己定义的目录,之后所有的命令都应该在这个目录下面进行 安装相关模块 12345678910111213141516171819// generatorsnpm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --save// deployersnpm install hexo-deployer-git --savenpm install hexo-deployer-heroku --savenpm install hexo-deployer-rsync --savenpm install hexo-deployer-openshift --save// pluginsnpm install hexo-renderer-marked --savenpm install hexo-renderer-stylus --savenpm install hexo-renderer-ejs --savenpm install hexo-generator-feed --savenpm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 启动 Hexo 服务 1hexo server 现在打开http://localhost:4000/ 或者 http://127.0.0.1:4000/ 就可以看到网页了。 使用 Hexo目录结构123456789101112.├── .deploy //需要部署的文件├── db.json //文章数据库 ├── node_modules //Hexo插件├── public //生成的静态网页文件├── scaffolds //模板├── source //博客正文和其他源文件, 404 favicon CNAME 等都应该放在这里| ├── _drafts //草稿| └── _posts //文章├── themes //主题├── _config.yml //全局配置文件└── package.json //软件包信息 网站配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132# Hexo Configuration## Docs: http://hexo.io/docs/configuration.html## Source: http://github.com/hexojs/hexo/# Sitetitle: 点滴分享 多彩生活subtitle: Love Life ♥ Love Pythondescription: Czero000&apos;s Blog. 猴赛雷author: Cclanguage: zh-Hanstimezone: Asia/Shanghaikeywords: Life,Linux,Python# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://czero000.github.ioroot: /#permalink: :year/:month/:day/:title/permalink: :title/permalink_defaults:avatar: http://ofc9x1ccn.bkt.clouddn.com/blog/avatar.png# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace:# Category &amp; Tagdefault_category: 碎碎念category_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page#归档页数index_generator: per_page: 5archive_generator: per_page: 20 yearly: true monthly: truetag_generator: per_page: 10# Extensions## Plugins: http://hexo.io/plugins/## Themes: http://hexo.io/themes/theme: landscape# Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repo: github: git@github.com:Czero000/Czero000.github.io,master#分析baidu_analytics: dbb7c3072bcac827abced73e948b6c39google_analytics: UA-71693959-1google_site_verification: DGaApq5r-Kw2AKAuLvIvkp_PNikUZCPDGyE6z-ouVck#百度分享duoshuoshare: true#建站时间since: 2015#搜索引擎swiftype_key: JiNp1sQGms7eyzbeobBy#Feedfeed: type: atom path: atom.xml limit: 20 hub:#Social linkssocial: weibo: http://weibo.com/yuanlong1207# title,chinese availablelinks_title: Links# linkslinks: MacTalk: http://macshuo.com YumInstall: http://www.yuminstall.com# Creative Commons 4.0 International License.# http://creativecommons.org/# Available: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zerocreative_commons: by-nc-sa#hexo sitemapsitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml 命令行使用介绍常用命令12345678hexo help //查看帮助hexo init //初始化一个目录hexo new &quot;postName&quot; //新建文章hexo new page &quot;pageName&quot; //新建页面hexo generate //生成网页, 可以在 public 目录查看整个网站的文件hexo server //本地预览, &apos;Ctrl+C&apos;关闭hexo deploy //部署.deploy目录hexo clean //清除缓存, **强烈建议每次执行命令前先清理缓存, 每次部署前先删除 .deploy 文件夹** 复合命令12hexo deploy -g //生成加部署hexo server -g //生成加预览 简化命令1234hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy 安装插件123npm install --save //安装npm update //升级npm uninstall //卸载 安装主题&lt;repository&gt; 为主题的 git 仓库, &lt;theme-name&gt; 为要存放在本地的目录名 1git clone &lt;repository&gt; themes/&lt;theme-name&gt; 修改网站配置文件 1theme:&lt;theme-name&gt; 编辑文章新建文章1hexo new &apos;post_name&apos; 在post目录下会生成 post_name.md 文件123456789title: //文章标题date: 2015-09-29 17:11:07 //时间categories: Hexo //分类tags: - Hexo //标签permalink: //固定链接---正文 发布文章编辑全局配置文件 _config.yml 中的 deploy 部分, czero000 为用户名 1234deploy: type: github repo: http://github.com/Czero000/czero000.github.io.git branch: master 部署12hexo deployhexo d -g 如果出现以下提示表示部署成功1INFO Deploy done: git 点击 Github 上项目的 Settings, GitHub Pages, 提示 Your site is published at http://zerocyl.github.io/ 第一次上传网站需要等十分钟左右, 以后每次更新都能马上打开 绑定域名如果不绑定域名只能通过 you_user_name.github.io 访问，我的域名是从 Godaddy 申请，域名解析采用 DNSPod 绑定一级域名 主机记录 @，类型 A ，记录值 192.30.252.154主机记录 www，类型 A，记录值 192.30.252.154 可以参考 Tips for configuring an A record with your DNS provider 这篇文章配置 绑定二级域名(我的域名是 zerounix.com) 主机记录 blog，类型 CNAME，记录值 zerocyl.github.io 主题Hexo 的主题列表 下载安装主题12cd hexo-lcxgit clone http://github.com/iissnan/hexo-theme-next themes/next 也可以手动下载后解压到 themes 目录,全局配置文件 _config.yml 中 theme 改成 next 主题目录结构12345678910111213141516171819.├── languages #国际化| ├── default.yml #默认| └── zh-CN.yml #中文├── layout #布局| ├── _partial #局部的布局| └── _widget #小挂件的布局├── script #js脚本├── source #源代码文件| ├── css #CSS| | ├── _base #基础CSS| | ├── _partial #局部CSS| | ├── fonts #字体| | ├── images #图片| | └── style.styl #style.css| ├── fancybox #fancybox| └── js #js├── _config.yml #主题配置文件└── README.md #主题介绍 主题配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192# when running hexo in a subdirectory (e.g. domain.tld/blog), remove leading slashes ( &quot;/archives&quot; -&gt; &quot;archives&quot; )menu: home: / categories: /categories tags: /tags archives: /archives about: /about #commonweal: /404.html# Place your favicon.ico to /source directory.favicon: /favicon.ico# Set default keywords (Use a comma to separate)keywords: &quot;Hexo,next&quot;# Set rss to false to disable feed link.# Leave rss as empty to use site&apos;s feed link.# Set rss to specific value if you have burned your feed already.rss:# Icon fonts# Place your font into next/source/fonts, specify directory-name and font-name here# Avialable: default | linecons | fifty-shades | feather#icon_font: default#icon_font: fifty-shades#icon_font: feathericon_font: linecons# Code Highlight theme# Available value: normal | night | night eighties | night blue | night bright# http://github.com/chriskempson/tomorrow-themehighlight_theme: normal# MathJax Supportmathjax:# Schemesscheme: Mist# Sidebar, available value:# - post expand on posts automatically. Default.# - always expand for all pages automatically# - hide expand only when click on the sidebar toggle icon.sidebar: post#sidebar: always#sidebar: hide# Automatically scroll page to section which is under &lt;!-- more --&gt; mark.scroll_to_more: true# Automatically add list number to toc.toc_list_number: true# Automatically Excerptauto_excerpt: enable: false length: 150# Use Lato font# Note: this option is avialable only when the language is not `zh-Hans`use_font_lato: true# Make duoshuo show UA# user_id must NOT be null when admin_enable is true!# you can visit http://dev.duoshuo.com get duoshuo user id.duoshuo_info: ua_enable: true admin_enable: false user_id: 0## DO NOT EDIT THE FOLLOWING SETTINGS## UNLESS YOU KNOW WHAT YOU ARE DOING# Use velocity to animate everything.use_motion: true# Fancyboxfancybox: true# Static filesvendors: vendorscss: cssjs: jsimages: images# Theme versionversion: 0.4.4 选择 Scheme1scheme: Mist 添加小图标 favicon.ico将 favicon.ico 文件放在 source 目录下, 修改主题配置文件 1favicon: /favicon.ico 语言设置 English (en) 中文简体 (zh-Hans) French (fr-FR) 中文繁体 (zh-hk/zh-tw) Russian (ru) German (de) 站点配置文件 1language:zh-hk 菜单设置编辑主题配置文件的 menu若站点运行在子目录中, 将链接前缀的 / 去掉 1234567menu: home: / archives: /archives categories: /categories tags: /tags commonweal: /404.html about: /about 分类页面添加一个分类页面，并在菜单中显示页面链接新建 categories 页面1hexo new page &quot;categories&quot; 将页面的类型设置为 categories1234title: categoriesdate: 2015-10-09 16:33:59type: categories--- 关闭评论增加 comments: false 在菜单中添加链接. 编辑主题配置文件, 添加 categories 到 menu 中12menu: tags: /categories 标签页面添加一个标签页面，并在菜单中显示页面链接新建 tags 页面 1hexo new page &quot;tags&quot; 将页面的类型设置为 tags1234title: tagsdate: 2015-10-09 16:33:59type: tags--- 关闭评论增加 comments: false 在菜单中添加链接. 编辑主题配置文件, 添加 tags 到 menu 中12menu: tags: /tags 下插件 123hexo-generator-indexhexo-generator-archivehexo-generator-tag 站点配置文章中设定 12345678index_generator: per_page: 5archive_generator: per_page: 20 yearly: true monthly: truetag_generator: per_page: 10 自定义字体编辑主题 source/css/_variables/custom.styl 文件, 例如12$font-family-headings = Georgia, sans$font-family-base = &quot;Microsoft YaHei&quot;, Verdana, sans-serif 自定义页面内容区域的宽度编辑主题 source/css/_variables/custom.styl 文件 1$content-desktop = 700px 扩展应用多说评论系统登陆多说创建站点, 多说域名 xxx.duoshuo.com 前面的 xxx 即为 duoshuo_shortname, 在站点配置文件中新增 duoshuo_shortname 字段1duoshuo_shotname: xxx 如需取消某个页面/文章的评论, 在 md 文件的 front-matter 中增加1comments: false 多说评论组件提供热评文章功能, 仅在文章页面显示 站点/主题配置文件中设置增加 12# 多说热评文章 true 或者 falseduoshuo_hotartical: true Disqus 在Disqus官网申请 shotname，在站点配置文件中，添加 disqus-shortname1disqus_shortname: xxxxxxxx 网站统计百度统计登录百度统计, 定位到站点的代码获取页面复制 hm.js? 后面那串统计脚本 id 编辑站点配置文件, 新增字段 baidu_analytics 字段1baidu_analytics: xxxxxxxxxxxxxxxx Google Analytics从Google Analytics 获取 ID 站点配置文件新增 google_analytics, 设置成 google 跟踪 ID. 通常是以 UA- 开头1google_analytics: UA-xxxxxxxx-x 分享JiaThis站点/主题配置文件添加字段 jiathis, 值为 true12# JiaThis 分享服务jiathis: true 百度分享站点/主题配置文件添加字段 baidushare, 值为 true12# 百度分享服务baidushare: true 多说分享站点/主题配置文件添加字段 duoshuo_share, 值为 true, 多说分享必须与多说评论同时使用12# 多说分享服务duoshuo_share: true Swiftype 搜索站点配置文件新增 swiftype_key 字段, 值为 swiftype 搜索引擎的 key12swiftype_key: xxxxxxxxxGoogle Webmaster tools Google Webmaster tools设置 Google 站点管理工具的验证字符串, 用于提交 sitemap 获取 google site verification code 登录 Google Webmaster Tools, 导航到验证方法, 并选择 HTML 标签, 将会获取到一段代码 1&lt;meta name=&quot;google-site-verification&quot; content=&quot;XXXXXXXXXXXXXXXXXXXXXXX&quot; /&gt; 将 content 里面的 XXXXXXXXXXXXXXXXXXXXXXX 复制出来, 站点配置文件新增字段google_site_verification1google_site_verification google_site_verification: XXXXXXXXXXXXXXXXXXXXXXX 版权参见知识共享许可协议站点配置文件新增1234# Creative Commons 4.0 International License.# http://creativecommons.org/# Available: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zerocreative_commons: by-nc-sa 图片显示把图片放到 source/images 目录下1![test](images/xxx.jpg) 推荐使用图床, 例如七牛云存储 自定义 404 页面添加 source/404.html 404 页面不需要 Hexo 解析自定义 404 页面添加 source/404.html123456789101112131415layout: false--------&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt; &lt;title&gt;404&lt;/title&gt; &lt;link rel=&quot;icon&quot; href=&quot;/favicon.ico&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;div align=&quot;center&quot;&gt; &lt;p&gt;404 你懂的&lt;/p&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 添加 robots.txtsource 目录下添加 robots.txt12345# robots.txtUser-agent: BaiduspiderDisallow: /User-agent: GooglebotDisallow: 生成 post 时默认生成 categories 配置项在 scaffolds/post.md 中添加1categories: 添加 “fork me on github”官方教程 点击加载评论在 themes\next\layout\_layout.swig 里找到123&lt;div id=&quot;disqus_thread&quot;&gt;&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&quot;//disqus.com/?ref_noscript&quot;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/div&gt; 在上面添加1&lt;button id=&quot;load-disqus&quot; onclick=&quot;disqus.load();&quot; style=&quot;background-color: #ebebeb; color: #646464; font-size: 18px; padding: 8px 12px; border-radius: 5px; border: 1px solid #ebebeb;&quot;&gt;点击查看评论&lt;/button&gt; 修改文件themes\next\layout\_scripts\comments\disqus.swig1234567891011121314151617181920212223242526&lt;script type=&quot;text/javascript&quot;&gt;var disqus = &#123; //添加的内容load : function disqus()&#123; //添加的内容 var disqus_shortname = &apos;&#123;&#123;theme.disqus_shortname&#125;&#125;&apos;; var disqus_identifier = &apos;&#123;&#123; page.path &#125;&#125;&apos;; var disqus_title = &apos;&#123;&#123; page.title &#125;&#125;&apos;; var disqus_url = &apos;&#123;&#123; page.permalink &#125;&#125;&apos;; function run_disqus_script(disqus_script)&#123; var dsq = document.createElement(&apos;script&apos;); dsq.type = &apos;text/javascript&apos;; dsq.async = true; dsq.src = &apos;//&apos; + disqus_shortname + &apos;.disqus.com/&apos; + disqus_script; (document.getElementsByTagName(&apos;head&apos;)[0] || document.getElementsByTagName(&apos;body&apos;)[0]).appendChild(dsq); &#125; run_disqus_script(&apos;count.js&apos;); &#123;% if page.comments %&#125; run_disqus_script(&apos;embed.js&apos;); &#123;% endif %&#125;$(&apos;#load-disqus&apos;).remove(); //添加的内容&#125; //添加的内容&#125; //添加的内容&lt;/script&gt; 给 GitHub 添加 README把 README.MD 文件的后缀名改成 MDOWN, 放到 source 文件夹下, 这样 Hexo 不会将其解析成网页, GitHub 也会作为 MD 文件解析 网站访问量统计使用不蒜子 提供的服务 安装脚本1&lt;script async src=&quot;http://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; 不蒜子可以给任何类型的个人站点使用，如果你是用的 hexo，打开 themes/你的主题/layout/_partial/footer.ejs 添加上述脚本即可，当然你也可以添加到 header 中。 安装标签算法a: pv的方式, 单个用户连续点击n篇文章, 记录n次访问量.123&lt;span id=&quot;busuanzi_container_site_pv&quot;&gt; 本站总访问量&lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;次&lt;/span&gt; 算法b: uv的方式, 单个用户连续点击n篇文章, 只记录1次访客数.123&lt;span id=&quot;busuanzi_container_site_uv&quot;&gt; 本站访客数&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt;人次&lt;/span&gt; 如果你是用的hexo，打开themes/你的主题/layout/_partial/footer.ejs添加即可。 网站运行时间脚本：1234567&lt;script&gt;var birthDay = new Date(&quot;11/20/2014&quot;);var now = new Date();var duration = now.getTime() - birthDay.getTime(); var total= Math.floor(duration / (1000 * 60 * 60 * 24));document.getElementById(&quot;showDays&quot;).innerHTML = &quot;本站已运行 &quot;+total+&quot; 天&quot;;&lt;/script&gt; 标签：1&lt;span id=&quot;showDays&quot;&gt;&lt;/span&gt; 简体中文/繁体中文切换下载js文件 放到主题的js文件夹 添加标签1&lt;a id=&quot;translateLink&quot; href=&quot;javascript:translatePage();&quot;&gt;繁體&lt;/a&gt; 添加脚本12345678910&lt;script type=&quot;text/javascript&quot; src=&quot;/js/tw_cn.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt;var defaultEncoding = 2; //网站编写字体是否繁体，1-繁体，2-简体var translateDelay = 0; //延迟时间,若不在前, 要设定延迟翻译时间, 如100表示100ms,默认为0var cookieDomain = &quot;http://www.arao.me/&quot;; //Cookie地址, 一定要设定, 通常为你的网址var msgToTraditionalChinese = &quot;繁體&quot;; //此处可以更改为你想要显示的文字var msgToSimplifiedChinese = &quot;简体&quot;; //同上，但两处均不建议更改var translateButtonId = &quot;translateLink&quot;; //默认互换idtranslateInitilization();&lt;/script&gt; Kill IE6123&lt;!--[if IE 6]&gt; &lt;script src=&quot;//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js&quot;&gt;&lt;/script&gt;&lt;![endif]--&gt; 迁移参考官方文档Hexo Migration 更多信息更多信息参考官方文档]]></content>
    </entry>

    
  
  
</search>
